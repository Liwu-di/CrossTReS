{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/1/12 9:39\n",
    "# @Author  : 银尘\n",
    "# @FileName: multi_graph_merge_7.py\n",
    "# @Software: PyCharm\n",
    "# @Email   : liwudi@liwudi.fun\n",
    "# @Info    : 3城市生成虚拟城市\n",
    "\n",
    "\n",
    "import argparse\n",
    "import ast\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PaperCrawlerUtil.common_util import *\n",
    "from PaperCrawlerUtil.constant import *\n",
    "from PaperCrawlerUtil.crawler_util import *\n",
    "from dgl.nn import GATConv\n",
    "from dtaidistance import dtw\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import *\n",
    "from funcs import *\n",
    "from params_ipynb import *\n",
    "from utils import *\n",
    "from PaperCrawlerUtil.research_util import *\n",
    "\n",
    "basic_config(logs_style=LOG_STYLE_ALL)\n",
    "p_bar = process_bar(final_prompt=\"初始化准备完成\", unit=\"part\")\n",
    "long_term_save = {}\n",
    "args = params()\n",
    "long_term_save[\"args\"] = args.__str__()\n",
    "if args.c != \"default\":\n",
    "    c = ast.literal_eval(args.c)\n",
    "    record = ResearchRecord(**c)\n",
    "    record_id = record.insert(__file__, get_timestamp(), args.__str__())\n",
    "p_bar.process(0, 1, 5)\n",
    "source_emb_label2, source_t_adj, source_edge_labels2, lag, source_poi, source_data2, \\\n",
    "source_train_y, source_test_x, source_val_x, source_poi_adj, source_poi_adj2, dataname, target_train_x, \\\n",
    "th_mask_source2, th_mask_source, target_test_loader, target_poi, target_od_adj, \\\n",
    "source_dataset, mask_source, target_graphs, target_val_dataset, max_val, scity2, smin2, \\\n",
    "target_emb_label, tcity, source_road_adj2, gpu_available, source_edges2, \\\n",
    "mask_source2, source_poi_cos, source_data, source_graphs, lng_source, source_road_adj, target_d_adj, \\\n",
    "target_val_x, source_poi2, scity, target_t_adj, lat_source, lat_target, target_test_x, \\\n",
    "source_x, target_val_y, lng_source2, num_tuine_epochs, source_d_adj, source_edge_labels, source_prox_adj, \\\n",
    "source_loader, source_graphs2, transform, source_t_adj2, smax2, target_train_loader, \\\n",
    "source_test_dataset2, source_poi_cos2, source_od_adj2, target_s_adj, target_test_dataset, \\\n",
    "source_test_y2, source_y, source_dataset2, target_road_adj, source_test_loader, target_poi_adj, \\\n",
    "smax, start_time, target_test_y, lng_target, source_test_loader2, \\\n",
    "source_prox_adj2, target_data, source_x2, target_train_dataset, source_test_dataset, source_test_x2, source_od_adj, target_val_loader, smin, target_poi_cos, target_edge_labels, \\\n",
    "source_edges, source_train_x2, source_s_adj, source_y2, source_val_x2, source_emb_label, \\\n",
    "target_norm_poi, source_norm_poi, source_train_x, datatype, source_val_y, mask_target, \\\n",
    "source_train_y2, source_norm_poi2, source_s_adj2, num_epochs, lat_source2, min_val, target_edges, \\\n",
    "source_val_y2, target_prox_adj, source_loader2, source_test_y, source_d_adj, \\\n",
    "target_train_y, th_mask_target, device, p_bar = load_process_data(args, p_bar)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "this_use_data = target_data[-((args.data_amount + 90) * 24): , :, :]\n",
    "train = []\n",
    "test = []\n",
    "xtrain, ytrain,_, __, xtest, ytest = split_x_y(this_use_data, [-6, -5, -4, -3, -2, -1], 1, 90 * 24)\n",
    "modelfits = []\n",
    "models = []\n",
    "valid_regions = mask_target.sum()\n",
    "for i in range(target_data.shape[1]):\n",
    "    for j in range(target_data.shape[2]):\n",
    "        if mask_target[i][j]:\n",
    "            model = ARIMA(target_data[-((args.data_amount + 90) * 24): -90 * 24, i, j], order=(1, 1, 1))\n",
    "            model_fit = model.fit()\n",
    "            modelfits.append(model_fit)\n",
    "            models.append(model)\n",
    "        else:\n",
    "            models.append(ARIMA(target_data[-1:, i, j], order=(1, 1, 1)))\n",
    "            modelfits.append(ARIMA(target_data[-1:, i, j], order=(1, 1, 1)).fit())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae = []\n",
    "rmse = []\n",
    "mape = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "for i in range(target_data.shape[1]):\n",
    "    for j in range(target_data.shape[2]):\n",
    "\n",
    "        if mask_target[i][j]:\n",
    "            ae = 0\n",
    "            se = 0\n",
    "            pe = 0\n",
    "            for p in range(xtest.shape[0]):\n",
    "                forecast = modelfits[idx_2d_2_1d((i, j), (target_data.shape[1], target_data.shape[2]))].forecast(steps=1, exog=xtest[p, :, i, j].reshape(6,1))\n",
    "                ae = ae + (abs((forecast - ytest[p, :, i, j]).item()))\n",
    "                se = se + ((forecast - ytest[p, :, i, j]).item()) ** 2\n",
    "                with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                    ape = abs(forecast - ytest[p, :, i, j] / ytest[p, :, i, j])\n",
    "                    ape[~ np.isfinite(ape)] = 0  # 对 -inf, inf, NaN进行修正，置为0\n",
    "                    pe = pe + ape.item()\n",
    "            mae.append(ae)\n",
    "            rmse.append(se)\n",
    "            mape.append(pe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.02315646600854 1.1285795944237833 88.7105822914305\n"
     ]
    }
   ],
   "source": [
    "maes = 0\n",
    "rmses = 0\n",
    "mapes = 0\n",
    "for i in mae:\n",
    "    if math.isnan(i):\n",
    "        continue\n",
    "    maes = maes + i\n",
    "for i in rmse:\n",
    "    if math.isnan(i):\n",
    "        continue\n",
    "    rmses = rmses + i\n",
    "for i in mape:\n",
    "    if math.isnan(i):\n",
    "        continue\n",
    "    mapes = mapes + i\n",
    "\n",
    "print(maes / xtest.shape[0], rmses / xtest.shape[0], mapes / xtest.shape[0])\n",
    "best_test_rmse = rmses / xtest.shape[0]\n",
    "best_test_mae = maes / xtest.shape[0]\n",
    "best_test_mape = mapes / xtest.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log(\"Best test rmse %.4f, mae %.4f, mape %.4f\" % (best_test_rmse * (max_val - min_val), best_test_mae * (max_val - min_val), best_test_mape * (max_val - min_val)))\n",
    "\n",
    "if args.c != \"default\":\n",
    "    if args.need_remark == 1:\n",
    "        record.update(record_id, get_timestamp(),\n",
    "                      \"%.4f,%.4f,%.4f\" %\n",
    "                      (best_test_rmse * (max_val - min_val), best_test_mae * (max_val - min_val), best_test_mape * (max_val - min_val)),\n",
    "                      remark=\"{}C {} {} {} {} {} {} {} {} {}\".format(\"2\" if args.need_third == 0 else \"3\", args.cut_data, args.scity,\n",
    "                                                               args.scity2,\n",
    "                                                               args.scity3 if args.need_third == 1 else \"\", args.tcity,\n",
    "                                                               str(args.data_amount), args.dataname, args.datatype, args.machine_code))\n",
    "    else:\n",
    "        record.update(record_id, get_timestamp(),\n",
    "                      \"%.4f,%.4f, %.4f\" %\n",
    "                      (best_test_rmse * (max_val - min_val), best_test_mae * (max_val - min_val), best_test_mape * (max_val - min_val)),\n",
    "                      remark=\"{}\".format(args.machine_code))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
