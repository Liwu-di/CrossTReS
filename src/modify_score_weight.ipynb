{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/10/25 11:27\n",
    "# @Author  : 银尘\n",
    "# @FileName: multi_graph_merge_2.py\n",
    "# @Software: PyCharm\n",
    "# @Email   ：liwudi@liwudi.fun\n",
    "import argparse\n",
    "import ast\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PaperCrawlerUtil.common_util import *\n",
    "from PaperCrawlerUtil.constant import *\n",
    "from PaperCrawlerUtil.crawler_util import *\n",
    "from dgl.nn import GATConv\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import *\n",
    "from funcs import *\n",
    "from params_ipynb import *\n",
    "from utils import *\n",
    "from PaperCrawlerUtil.research_util import *\n",
    "\n",
    "\n",
    "basic_config(logs_style=LOG_STYLE_ALL)\n",
    "p_bar = process_bar(final_prompt=\"初始化准备完成\", unit=\"part\")\n",
    "\n",
    "args = params()\n",
    "# c = ast.literal_eval(args.c)\n",
    "# record = ResearchRecord(**c)\n",
    "# record_id = record.insert(__file__, get_timestamp(), args.__str__())\n",
    "p_bar.process(0, 1, 5)\n",
    "# This file implements the full version of using region embeddings to select good source data.\n",
    "# 设置训练设备\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)\n",
    "gpu_available = torch.cuda.is_available()\n",
    "if gpu_available:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "dataname = args.dataname\n",
    "scity = args.scity\n",
    "scity2 = args.scity2\n",
    "tcity = args.tcity\n",
    "datatype = args.datatype\n",
    "num_epochs = args.num_epochs\n",
    "num_tuine_epochs = args.num_tuine_epochs\n",
    "start_time = time.time()\n",
    "log(\"Running CrossTReS, from %s and %s to %s, %s %s experiments, with %d days of data, on %s model\" % \\\n",
    "    (scity, scity2, tcity, dataname, datatype, args.data_amount, args.model))\n",
    "p_bar.process(1, 1, 5)\n",
    "# Load spatio temporal data\n",
    "# (8784, 21, 20)\n",
    "# 8784 = 366 * 24\n",
    "target_data = np.load(\"../data/%s/%s%s_%s.npy\" % (tcity, dataname, tcity, datatype))\n",
    "# (21, 20) 经纬度分割\n",
    "lng_target, lat_target = target_data.shape[1], target_data.shape[2]\n",
    "# numpy.sum()，求和某一维度或者维度为none时，求和所有，减掉一个维度\n",
    "# 此处，target_data (8784, 21, 20) -> (21, 20)\n",
    "# 然后，通过对于每个元素判断是否大于0， 转成Bool向量\n",
    "mask_target = target_data.sum(0) > 0\n",
    "# reshape （21， 20） -》 （1， 21， 20）\n",
    "th_mask_target = torch.Tensor(mask_target.reshape(1, lng_target, lat_target)).to(device)\n",
    "log(\"%d valid regions in target\" % np.sum(mask_target))\n",
    "# (（21， 20）-> 420, （21， 20）-> 420)\n",
    "target_emb_label = masked_percentile_label(target_data.sum(0).reshape(-1), mask_target.reshape(-1))\n",
    "\n",
    "\n",
    "\n",
    "# (8784, 20, 23)\n",
    "source_data = np.load(\"../data/%s/%s%s_%s.npy\" % (scity, dataname, scity, datatype))\n",
    "log(source_data.shape)\n",
    "# (20, 23)\n",
    "lng_source, lat_source = source_data.shape[1], source_data.shape[2]\n",
    "mask_source = source_data.sum(0) > 0\n",
    "# mask -> th_mask = (20, 23) -> (1, 20, 23)\n",
    "th_mask_source = torch.Tensor(mask_source.reshape(1, lng_source, lat_source)).to(device)\n",
    "log(\"%d valid regions in source\" % np.sum(mask_source))\n",
    "\n",
    "source_data2 = np.load(\"../data/%s/%s%s_%s.npy\" % (scity2, dataname, scity2, datatype))\n",
    "log(source_data2.shape)\n",
    "lng_source2, lat_source2 = source_data2.shape[1], source_data2.shape[2]\n",
    "mask_source2 = source_data2.sum(0) > 0\n",
    "th_mask_source2 = torch.Tensor(mask_source2.reshape(1, lng_source2, lat_source2)).to(device)\n",
    "log(\"%d valid regions in source\" % np.sum(mask_source2))\n",
    "\n",
    "p_bar.process(2, 1, 5)\n",
    "# 按照百分比分配标签\n",
    "source_emb_label = masked_percentile_label(source_data.sum(0).reshape(-1), mask_source.reshape(-1))\n",
    "\n",
    "lag = [-6, -5, -4, -3, -2, -1]\n",
    "source_data, smax, smin = min_max_normalize(source_data)\n",
    "target_data, max_val, min_val = min_max_normalize(target_data)\n",
    "\n",
    "source_emb_label2 = masked_percentile_label(source_data2.sum(0).reshape(-1), mask_source2.reshape(-1))\n",
    "source_data2, smax2, smin2 = min_max_normalize(source_data2)\n",
    "\n",
    "\n",
    "# [(5898, 6, 20, 23), (5898, 1, 20, 23), (1440, 6, 20, 23), (1440, 1, 20, 23), (1440, 6, 20, 23), (1440, 1, 20, 23)]\n",
    "# 第一维是数量，第二维是每条数据中的数量\n",
    "source_train_x, source_train_y, source_val_x, source_val_y, source_test_x, source_test_y = split_x_y(source_data, lag)\n",
    "source_train_x2, source_train_y2, source_val_x2, source_val_y2, source_test_x2, source_test_y2 = split_x_y(source_data2,\n",
    "                                                                                                           lag)\n",
    "# we concatenate all source data\n",
    "# (8778, 6, 20, 23)\n",
    "source_x = np.concatenate([source_train_x, source_val_x, source_test_x], axis=0)\n",
    "# (8778, 1, 20, 23)\n",
    "source_y = np.concatenate([source_train_y, source_val_y, source_test_y], axis=0)\n",
    "source_x2 = np.concatenate([source_train_x2, source_val_x2, source_test_x2], axis=0)\n",
    "source_y2 = np.concatenate([source_train_y2, source_val_y2, source_test_y2], axis=0)\n",
    "target_train_x, target_train_y, target_val_x, target_val_y, target_test_x, target_test_y = split_x_y(target_data, lag)\n",
    "p_bar.process(3, 1, 5)\n",
    "\n",
    "\n",
    "if args.data_amount != 0:\n",
    "    # 负号表示从倒数方向数，\n",
    "    # i.e.\n",
    "    # a = [12, 3, 4, 5, 6, 7, 8]\n",
    "    # c, d = a[-2:], a[:-2]\n",
    "    # print(c)\n",
    "    # print(d)\n",
    "    # [7, 8]\n",
    "    # [12, 3, 4, 5, 6]\n",
    "    target_train_x = target_train_x[-args.data_amount * 24:, :, :, :]\n",
    "    target_train_y = target_train_y[-args.data_amount * 24:, :, :, :]\n",
    "log(\"Source split to: x %s, y %s\" % (str(source_x.shape), str(source_y.shape)))\n",
    "# log(\"val_x %s, val_y %s\" % (str(source_val_x.shape), str(source_val_y.shape)))\n",
    "# log(\"test_x %s, test_y %s\" % (str(source_test_x.shape), str(source_test_y.shape)))\n",
    "log(\"Source2 split to: x %s, y %s\" % (str(source_x2.shape), str(source_y2.shape)))\n",
    "log(\"Target split to: train_x %s, train_y %s\" % (str(target_train_x.shape), str(target_train_y.shape)))\n",
    "log(\"val_x %s, val_y %s\" % (str(target_val_x.shape), str(target_val_y.shape)))\n",
    "log(\"test_x %s, test_y %s\" % (str(target_test_x.shape), str(target_test_y.shape)))\n",
    "\n",
    "\n",
    "# 这些代码 numpy -> Tensor -> TensorDataset -> DataLoader\n",
    "target_train_dataset = TensorDataset(torch.Tensor(target_train_x), torch.Tensor(target_train_y))\n",
    "target_val_dataset = TensorDataset(torch.Tensor(target_val_x), torch.Tensor(target_val_y))\n",
    "target_test_dataset = TensorDataset(torch.Tensor(target_test_x), torch.Tensor(target_test_y))\n",
    "target_train_loader = DataLoader(target_train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "target_val_loader = DataLoader(target_val_dataset, batch_size=args.batch_size)\n",
    "target_test_loader = DataLoader(target_test_dataset, batch_size=args.batch_size)\n",
    "source_test_dataset = TensorDataset(torch.Tensor(source_test_x), torch.Tensor(source_test_y))\n",
    "source_test_loader = DataLoader(source_test_dataset, batch_size=args.batch_size)\n",
    "source_dataset = TensorDataset(torch.Tensor(source_x), torch.Tensor(source_y))\n",
    "source_loader = DataLoader(source_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "source_test_dataset2 = TensorDataset(torch.Tensor(source_test_x2), torch.Tensor(source_test_y2))\n",
    "source_test_loader2 = DataLoader(source_test_dataset2, batch_size=args.batch_size)\n",
    "source_dataset2 = TensorDataset(torch.Tensor(source_x2), torch.Tensor(source_y2))\n",
    "source_loader2 = DataLoader(source_dataset2, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Load auxiliary data: poi data\n",
    "# (20, 23, 14)\n",
    "source_poi = np.load(\"../data/%s/%s_poi.npy\" % (scity, scity))\n",
    "source_poi2 = np.load(\"../data/%s/%s_poi.npy\" % (scity2, scity2))\n",
    "target_poi = np.load(\"../data/%s/%s_poi.npy\" % (tcity, tcity))\n",
    "# (460, 14)\n",
    "source_poi = source_poi.reshape(lng_source * lat_source, -1)  # regions * classes\n",
    "source_poi2 = source_poi2.reshape(lng_source2 * lat_source2, -1)  # regions * classes\n",
    "target_poi = target_poi.reshape(lng_target * lat_target, -1)  # regions * classes\n",
    "transform = TfidfTransformer()\n",
    "# 规范正则化到（0，1）\n",
    "source_norm_poi = np.array(transform.fit_transform(source_poi).todense())\n",
    "transform = TfidfTransformer()\n",
    "# 规范正则化到（0，1）\n",
    "source_norm_poi2 = np.array(transform.fit_transform(source_poi2).todense())\n",
    "transform = TfidfTransformer()\n",
    "target_norm_poi = np.array(transform.fit_transform(target_poi).todense())\n",
    "\n",
    "\n",
    "\n",
    "# Build graphs\n",
    "# add_self_loop 增加一个自循环，对角线的值=1\n",
    "source_prox_adj = add_self_loop(build_prox_graph(lng_source, lat_source))\n",
    "source_prox_adj2 = add_self_loop(build_prox_graph(lng_source2, lat_source2))\n",
    "target_prox_adj = add_self_loop(build_prox_graph(lng_target, lat_target))\n",
    "source_road_adj = add_self_loop(build_road_graph(scity, lng_source, lat_source))\n",
    "source_road_adj2 = add_self_loop(build_road_graph(scity2, lng_source2, lat_source2))\n",
    "target_road_adj = add_self_loop(build_road_graph(tcity, lng_target, lat_target))\n",
    "source_poi_adj, source_poi_cos = build_poi_graph(source_norm_poi, args.topk)\n",
    "source_poi_adj2, source_poi_cos2 = build_poi_graph(source_norm_poi2, args.topk)\n",
    "target_poi_adj, target_poi_cos = build_poi_graph(target_norm_poi, args.topk)\n",
    "source_poi_adj = add_self_loop(source_poi_adj)\n",
    "source_poi_adj2 = add_self_loop(source_poi_adj2)\n",
    "target_poi_adj = add_self_loop(target_poi_adj)\n",
    "source_s_adj, source_d_adj, source_od_adj = build_source_dest_graph(scity, dataname, lng_source, lat_source, args.topk)\n",
    "source_s_adj2, source_d_adj2, source_od_adj2 = build_source_dest_graph(scity2, dataname, lng_source2, lat_source2,\n",
    "                                                                       args.topk)\n",
    "target_s_adj, target_d_adj, target_od_adj = build_source_dest_graph(tcity, dataname, lng_target, lat_target, args.topk)\n",
    "source_s_adj = add_self_loop(source_s_adj)\n",
    "source_s_adj2 = add_self_loop(source_s_adj2)\n",
    "source_t_adj = add_self_loop(source_d_adj)\n",
    "source_t_adj2 = add_self_loop(source_d_adj2)\n",
    "source_od_adj = add_self_loop(source_od_adj)\n",
    "source_od_adj2 = add_self_loop(source_od_adj2)\n",
    "target_s_adj = add_self_loop(target_s_adj)\n",
    "target_t_adj = add_self_loop(target_d_adj)\n",
    "target_od_adj = add_self_loop(target_od_adj)\n",
    "log(\"Source graphs: \")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (source_prox_adj.shape[0], np.sum(source_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (source_road_adj.shape[0], np.sum(source_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (source_poi_adj.shape[0], np.sum(source_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (source_s_adj.shape[0], np.sum(source_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (source_d_adj.shape[0], np.sum(source_d_adj > 0)))\n",
    "log()\n",
    "log(\"Source2 graphs: \")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (source_prox_adj2.shape[0], np.sum(source_prox_adj2)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (source_road_adj2.shape[0], np.sum(source_road_adj2 > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (source_poi_adj2.shape[0], np.sum(source_poi_adj2 > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (source_s_adj2.shape[0], np.sum(source_s_adj2 > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (source_d_adj2.shape[0], np.sum(source_d_adj2 > 0)))\n",
    "log()\n",
    "log(\"Target graphs:\")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (target_prox_adj.shape[0], np.sum(target_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (target_road_adj.shape[0], np.sum(target_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (target_poi_adj.shape[0], np.sum(target_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (target_s_adj.shape[0], np.sum(target_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (target_d_adj.shape[0], np.sum(target_d_adj > 0)))\n",
    "log()\n",
    "source_graphs = adjs_to_graphs([source_prox_adj, source_road_adj, source_poi_adj, source_s_adj, source_d_adj])\n",
    "source_graphs2 = adjs_to_graphs([source_prox_adj2, source_road_adj2, source_poi_adj2, source_s_adj2, source_d_adj2])\n",
    "target_graphs = adjs_to_graphs([target_prox_adj, target_road_adj, target_poi_adj, target_s_adj, target_d_adj])\n",
    "for i in range(len(source_graphs)):\n",
    "    source_graphs[i] = source_graphs[i].to(device)\n",
    "    source_graphs2[i] = source_graphs2[i].to(device)\n",
    "    target_graphs[i] = target_graphs[i].to(device)\n",
    "\n",
    "\n",
    "source_edges, source_edge_labels = graphs_to_edge_labels(source_graphs)\n",
    "source_edges2, source_edge_labels2 = graphs_to_edge_labels(source_graphs2)\n",
    "target_edges, target_edge_labels = graphs_to_edge_labels(target_graphs)\n",
    "p_bar.process(4, 1, 5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 评分模型\n",
    "class Scoring(nn.Module):\n",
    "    def __init__(self, emb_dim, source_mask, target_mask):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.score = nn.Sequential(nn.Linear(self.emb_dim, self.emb_dim // 2),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(self.emb_dim // 2, self.emb_dim // 2))\n",
    "        self.source_mask = source_mask\n",
    "        self.target_mask = target_mask\n",
    "\n",
    "    def forward(self, source_emb, target_emb):\n",
    "        \"\"\"\n",
    "        求源城市评分\n",
    "        注意这里求评分，是source的每一个区域对于目标城市整体\n",
    "        换句话说，是形参2的每一个区域，对于形参3整体\n",
    "        :param target_mask:\n",
    "        :param source_mask:\n",
    "        :param source_emb:\n",
    "        :param target_emb:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # target_context = tanh(self.score(target_emb[bool mask]).mean(0))\n",
    "        # 对于横向的进行求平均 460*64 -> 460*32 -> 207*32 -> 纵向求平均 1*32 代表所有目标城市\n",
    "        target_context = torch.tanh(self.score(target_emb[self.target_mask.view(-1).bool()]).mean(0))\n",
    "        source_trans_emb = self.score(source_emb)\n",
    "        # 460*32 * 1*32 = 462*32, 这里乘法表示1*32列表去乘460*32的每一行，逐元素\n",
    "        # i.e.\n",
    "        # tensor([[2, 2, 2],\n",
    "        #         [1, 2, 2],\n",
    "        #         [2, 2, 1]])\n",
    "        # tensor([[2, 2, 2]])\n",
    "        # tensor([[4, 4, 4],\n",
    "        #         [2, 4, 4],\n",
    "        #         [4, 4, 2]])\n",
    "        source_score = (source_trans_emb * target_context).sum(1)\n",
    "        # the following lines modify inner product similarity to cosine similarity\n",
    "        # target_norm = target_context.pow(2).sum().pow(1/2)\n",
    "        # source_norm = source_trans_emb.pow(2).sum(1).pow(1/2)\n",
    "        # source_score /= source_norm\n",
    "        # source_score /= target_norm\n",
    "        # log(source_score)\n",
    "        return F.relu(torch.tanh(source_score))[self.source_mask.view(-1).bool()]\n",
    "\n",
    "\n",
    "class Scoring2(nn.Module):\n",
    "    def __init__(self, emb_dim, source_mask, target_mask):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.score = nn.Sequential(nn.Linear(self.emb_dim, self.emb_dim // 2),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(self.emb_dim // 2, self.emb_dim // 2),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(self.emb_dim // 2, 1))\n",
    "        self.source_mask = source_mask\n",
    "        self.target_mask = target_mask\n",
    "\n",
    "    def forward(self, source_emb, target_emb):\n",
    "        \"\"\"\n",
    "        求源城市评分\n",
    "        注意这里求评分，是source的每一个区域对于目标城市整体\n",
    "        换句话说，是形参2的每一个区域，对于形参3整体\n",
    "        :param target_mask:\n",
    "        :param source_mask:\n",
    "        :param source_emb:\n",
    "        :param target_emb:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # target_context = tanh(self.score(target_emb[bool mask]).mean(0))\n",
    "        # 对于横向的进行求平均 460*64 -> 460*32 -> 207*32 -> 纵向求平均 1*32 代表所有目标城市\n",
    "        target_context = target_emb[self.target_mask.view(-1).bool()].mean(0)\n",
    "        target_context_stack = tuple(target_context.reshape((1, self.emb_dim)) for i in range(source_emb.shape[0]))\n",
    "        target_context_stack = torch.cat(target_context_stack, dim=0)\n",
    "        source_emb = source_emb - target_context_stack\n",
    "        return self.score(source_emb)[self.source_mask.view(-1).bool()]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mmd = MMD_loss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_gat_layers = 2\n",
    "in_dim = 14\n",
    "hidden_dim = 64\n",
    "emb_dim = 64\n",
    "num_heads = 2\n",
    "mmd_w = args.mmd_w\n",
    "et_w = args.et_w\n",
    "ma_param = args.ma_coef\n",
    "\n",
    "mvgat = MVGAT(len(source_graphs), num_gat_layers, in_dim, hidden_dim, emb_dim, num_heads, True).to(device)\n",
    "fusion = FusionModule(len(source_graphs), emb_dim, 0.8).to(device)\n",
    "scoring = Scoring(emb_dim, th_mask_source, th_mask_target).to(device)\n",
    "edge_disc = EdgeTypeDiscriminator(len(source_graphs), emb_dim).to(device)\n",
    "mmd = MMD_loss()\n",
    "# we still need a scoring model.\n",
    "# [NS, 64], [NT, 64] -> [NS]\n",
    "\n",
    "# build model\n",
    "if args.model == 'STResNet':\n",
    "    net = STResNet(len(lag), 1, 3).to(device)\n",
    "elif args.model == 'STNet_nobn':\n",
    "    net = STNet_nobn(1, 3, th_mask_target, sigmoid_out=True).to(device)\n",
    "    log(net)\n",
    "elif args.model == 'STNet':\n",
    "    net = STNet(1, 3, th_mask_target).to(device)\n",
    "    log(net)\n",
    "\n",
    "# net估计是预测网络\n",
    "pred_optimizer = optim.Adam(net.parameters(), lr=args.pred_lr, weight_decay=args.weight_decay)\n",
    "# 图卷积，融合，边类型分类器参数单独训练\n",
    "emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 元学习部分\n",
    "meta_optimizer = optim.Adam(scoring.parameters(), lr=args.outerlr, weight_decay=args.weight_decay)\n",
    "best_val_rmse = 999\n",
    "best_test_rmse = 999\n",
    "best_test_mae = 999\n",
    "p_bar.process(5, 1, 5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(net_, loader, spatial_mask):\n",
    "    \"\"\"\n",
    "    评估函数，spatial_mask去掉了一些无效数据\n",
    "    :param net_:\n",
    "    :param loader:\n",
    "    :param spatial_mask:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_.eval()\n",
    "    with torch.no_grad():\n",
    "        se = 0\n",
    "        ae = 0\n",
    "        valid_points = 0\n",
    "        losses = []\n",
    "        for it_ in loader:\n",
    "            if len(it_) == 2:\n",
    "                (x, y) = it_\n",
    "            elif len(it_) == 4:\n",
    "                _, _, x, y = it_\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            lng = x.shape[2]\n",
    "            lat = x.shape[3]\n",
    "            out = net_(x, spatial_mask=spatial_mask.bool())\n",
    "            valid_points += x.shape[0] * spatial_mask.sum().item()\n",
    "            if len(out.shape) == 4:  # STResNet\n",
    "                se += (((out - y) ** 2) * (spatial_mask.view(1, 1, lng, lat))).sum().item()\n",
    "                ae += ((out - y).abs() * (spatial_mask.view(1, 1, lng, lat))).sum().item()\n",
    "                eff_batch_size = y.shape[0]\n",
    "                loss = ((out - y) ** 2).view(eff_batch_size, 1, -1)[:, :, spatial_mask.view(-1).bool()]\n",
    "                losses.append(loss)\n",
    "            elif len(out.shape) == 3:  # STNet\n",
    "                batch_size = y.shape[0]\n",
    "                lag = y.shape[1]\n",
    "                y = y.view(batch_size, lag, -1)[:, :, spatial_mask.view(-1).bool()]\n",
    "                # log(\"out\", out.shape)\n",
    "                # log(\"y\", y.shape)\n",
    "                se += ((out - y) ** 2).sum().item()\n",
    "                ae += (out - y).abs().sum().item()\n",
    "                loss = ((out - y) ** 2)\n",
    "                losses.append(loss)\n",
    "    return np.sqrt(se / valid_points), ae / valid_points, losses\n",
    "\n",
    "\n",
    "def train_epoch(net_, loader_, optimizer_, weights=None, mask=None, num_iters=None):\n",
    "    \"\"\"\n",
    "    训练预测网络pred net网络，依据权重weights 修改loss，如\n",
    "    loss = ((out - y) ** 2)\n",
    "    loss = (loss * weights.view(1, 1, -1)).mean(0).sum()\n",
    "    再反向传播optimizer_\n",
    "    :param net_:\n",
    "    :param loader_:\n",
    "    :param optimizer_:\n",
    "    :param weights:\n",
    "    :param mask:\n",
    "    :param num_iters:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_.train()\n",
    "    epoch_loss = []\n",
    "    for i, (x, y) in enumerate(loader_):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = net_(x, spatial_mask=mask.bool())\n",
    "        if len(out.shape) == 4:  # STResNet\n",
    "            eff_batch_size = y.shape[0]\n",
    "            loss = ((out - y) ** 2).view(eff_batch_size, 1, -1)[:, :, mask.view(-1).bool()]\n",
    "            # log(\"loss\", loss.shape)\n",
    "            if weights is not None:\n",
    "                loss = (loss * weights)\n",
    "                # log(\"weights\", weights.shape)\n",
    "                # log(\"loss * weights\", loss.shape)\n",
    "                loss = loss.mean(0).sum()\n",
    "            else:\n",
    "                loss = loss.mean(0).sum()\n",
    "        elif len(out.shape) == 3:  # STNet\n",
    "            eff_batch_size = y.shape[0]\n",
    "            y = y.view(eff_batch_size, 1, -1)[:, :, mask.view(-1).bool()]\n",
    "            loss = ((out - y) ** 2)\n",
    "            if weights is not None:\n",
    "                # log(loss.shape)\n",
    "                # log(weights.shape)\n",
    "                loss = (loss * weights.view(1, 1, -1)).mean(0).sum()\n",
    "            else:\n",
    "                loss = loss.mean(0).sum()\n",
    "        optimizer_.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net_.parameters(), max_norm=2)\n",
    "        optimizer_.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        if num_iters is not None and num_iters == i:\n",
    "            break\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "# 这个代码还用不到，有报错，单独拿出来，不执行\n",
    "def train_rt_epoch(net_, loader_, optimizer_):\n",
    "    net_.train()\n",
    "    epoch_predloss = []\n",
    "    epoch_rtloss = []\n",
    "    epoch_loss = []\n",
    "    for i, (source_x, source_y, target_x, target_y) in enumerate(loader_):\n",
    "        source_x = source_x.to(device)\n",
    "        source_y = source_y.to(device)\n",
    "        target_x = target_x.to(device)\n",
    "        target_y = target_y.to(device)\n",
    "        source_feat, _ = net_(source_x, spatial_mask=th_mask_source.bool(), return_feat=True)\n",
    "        target_feat, target_out = net_(target_x, return_feat=True)\n",
    "        batch_size = target_y.shape[0]\n",
    "        lag = target_y.shape[1]\n",
    "        target_y = target_y.view(batch_size, lag, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "        loss_pred = ((target_out - target_y) ** 2).mean(0).sum()\n",
    "        matching_source_feat = source_feat[:, matching_indices, :]\n",
    "        loss_rt = (((target_feat - matching_source_feat) ** 2).sum(2) * matching_weight).sum(1).mean()\n",
    "        loss = loss_pred + args.rt_weight * loss_rt\n",
    "        optimizer_.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_.step()\n",
    "        epoch_predloss.append(loss_pred.item())\n",
    "        epoch_rtloss.append(loss_rt.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "    return np.mean(epoch_predloss), np.mean(epoch_rtloss), np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "def forward_emb(graphs_, in_feat_, od_adj_, poi_cos_):\n",
    "    \"\"\"\n",
    "    1. 图卷积提取图特征 mvgat\n",
    "    2. 融合多图特征 fusion\n",
    "    3. 对于多图中的s，d，poi进行预测，并计算损失函数\n",
    "    :param graphs_:\n",
    "    :param in_feat_:\n",
    "    :param od_adj_:\n",
    "    :param poi_cos_:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 图注意，注意这里用了小写，指的是forward方法\n",
    "    views = mvgat(graphs_, torch.Tensor(in_feat_).to(device))\n",
    "    fused_emb, embs = fusion(views)\n",
    "    # embs嵌入是5个图，以下找出start，destination， poi图\n",
    "    s_emb = embs[-2]\n",
    "    d_emb = embs[-1]\n",
    "    poi_emb = embs[-3]\n",
    "    # start和destination相乘求出记录预测s和d\n",
    "    recons_sd = torch.matmul(s_emb, d_emb.transpose(0, 1))\n",
    "    # 注意dim维度0和1分别求s和d\n",
    "    pred_d = torch.log(torch.softmax(recons_sd, dim=1) + 1e-5)\n",
    "    loss_d = (torch.Tensor(od_adj_).to(device) * pred_d).mean()\n",
    "    pred_s = torch.log(torch.softmax(recons_sd, dim=0) + 1e-5)\n",
    "    loss_s = (torch.Tensor(od_adj_).to(device) * pred_s).mean()\n",
    "    # poi预测求差，loss\n",
    "    poi_sim = torch.matmul(poi_emb, poi_emb.transpose(0, 1))\n",
    "    loss_poi = ((poi_sim - torch.Tensor(poi_cos_).to(device)) ** 2).mean()\n",
    "    loss = -loss_s - loss_d + loss_poi\n",
    "\n",
    "    return loss, fused_emb, embs\n",
    "\n",
    "\n",
    "def meta_train_epoch(s_embs, t_embs):\n",
    "    \"\"\"\n",
    "    0. 计算source_weights，通过scoring网络\n",
    "    1. 获取net 也就是预测网络的参数，分为两部分，一部分是命名参数，另一部分是非命名 fast_weights, bn_vars\n",
    "    2. 从源城市抽样，计算预测值，使用net网络，从输出格式判断使用的具体网络，计算损失\n",
    "    3. 通过torch.autograd.grad 计算loss对于fast_weights的梯度，并且更新fast_weights，注意2,3都是在更新net网络\n",
    "    4. 同理抽样目的城市，计算梯度，更新fast_weights\n",
    "    5. meta_loss = q_loss + weights_mean * args.weight_reg，计算meta loss\n",
    "    6. 根据meta loss 更新scoring meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "    7. 循环以上，则总体更新了scoring网络，net预测网络\n",
    "    :param s_embs:\n",
    "    :param t_embs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_query_losses = []\n",
    "    for meta_ep in range(args.outeriter):\n",
    "        fast_losses = []\n",
    "        fast_weights, bn_vars = get_weights_bn_vars(net)\n",
    "        source_weights = scoring(s_embs, t_embs)\n",
    "        # inner loop on source, pre-train with weights\n",
    "        for meta_it in range(args.sinneriter):\n",
    "            s_x, s_y = batch_sampler((torch.Tensor(source_x), torch.Tensor(source_y)), args.batch_size)\n",
    "            s_x = s_x.to(device)\n",
    "            s_y = s_y.to(device)\n",
    "            pred_source = net.functional_forward(s_x, th_mask_source.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_source.shape) == 4:  # STResNet\n",
    "                loss_source = ((pred_source - s_y) ** 2).view(args.batch_size, 1, -1)[:, :,\n",
    "                              th_mask_source.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_source = (loss_source * source_weights).mean(0).sum()\n",
    "            elif len(pred_source.shape) == 3:  # STNet\n",
    "                s_y = s_y.view(args.batch_size, 1, -1)[:, :, th_mask_source.view(-1).bool()]\n",
    "                loss_source = (((pred_source - s_y) ** 2) * source_weights.view(1, 1, -1))\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_source = loss_source.mean(0).sum()\n",
    "            # size = 1 基本可以认为是标量\n",
    "            fast_loss = loss_source\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            # 计算输出对于输入独立的梯度，\n",
    "            # fast_weights.values()。size = 22\n",
    "            # grad。size=22\n",
    "            # 此处对于fast_weights 进行梯度下降学习\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        # inner loop on target, simulate fine-tune\n",
    "        # 模拟微调和源训练都是在训练net预测网络，并没有提及权重和特征\n",
    "        for meta_it in range(args.tinneriter):\n",
    "            t_x, t_y = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            t_x = t_x.to(device)\n",
    "            t_y = t_y.to(device)\n",
    "            pred_t = net.functional_forward(t_x, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_t.shape) == 4:  # STResNet\n",
    "                loss_t = ((pred_t - t_y) ** 2).view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            elif len(pred_t.shape) == 3:  # STNet\n",
    "                t_y = t_y.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(t_y.shape)\n",
    "                loss_t = ((pred_t - t_y) ** 2)  # .view(1, 1, -1))\n",
    "                # log(loss_t.shape)\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            fast_loss = loss_t\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        q_losses = []\n",
    "        target_iter = max(args.sinneriter, args.tinneriter)\n",
    "        for k in range(3):\n",
    "            # query loss\n",
    "            x_q, y_q = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            x_q = x_q.to(device)\n",
    "            y_q = y_q.to(device)\n",
    "            pred_q = net.functional_forward(x_q, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_q.shape) == 4:  # STResNet\n",
    "                loss = (((pred_q - y_q) ** 2) * (th_mask_target.view(1, 1, lng_target, lat_target)))\n",
    "                loss = loss.mean(0).sum()\n",
    "            elif len(pred_q.shape) == 3:  # STNet\n",
    "                y_q = y_q.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                loss = ((pred_q - y_q) ** 2).mean(0).sum()\n",
    "            q_losses.append(loss)\n",
    "        q_loss = torch.stack(q_losses).mean()\n",
    "        # ** 乘方\n",
    "        weights_mean = (source_weights ** 2).mean()\n",
    "        # meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        # 这里对于权重开始了联系\n",
    "        # meta loss 只训练了scoring网络\n",
    "        meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        meta_optimizer.zero_grad()\n",
    "        meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "        torch.nn.utils.clip_grad_norm_(scoring.parameters(), max_norm=2)\n",
    "        meta_optimizer.step()\n",
    "        meta_query_losses.append(q_loss.item())\n",
    "    return np.mean(meta_query_losses)\n",
    "\n",
    "\n",
    "def train_emb_epoch2():\n",
    "    \"\"\"\n",
    "    训练图网络-特征网络，融合网络，边类型分类器\n",
    "    1. 通过forward_emb融合特征，计算损失，\n",
    "    2. 抽样边，标签，训练边缘分类器，抽样计算MMD误差\n",
    "    3. 反向传播计算\n",
    "    emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "    emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    训练特征网络 mvgat，fusion，边缘分类器，节点MMD，在训练的同时，对于mvgat和fusion的特征进行指导，特征重新对齐分布\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # loss， 460*64， 5*460*64\n",
    "    loss_source, fused_emb_s, embs_s = forward_emb(source_graphs, source_norm_poi, source_od_adj, source_poi_cos)\n",
    "    loss_source2, fused_emb_s2, embs_s2 = forward_emb(source_graphs2, source_norm_poi2, source_od_adj2, source_poi_cos2)\n",
    "    loss_target, fused_emb_t, embs_t = forward_emb(target_graphs, target_norm_poi, target_od_adj, target_poi_cos)\n",
    "\n",
    "    loss_emb = loss_source + loss_target + loss_source2\n",
    "    # compute domain adaptation loss\n",
    "    # 随机抽样128个，计算最大平均误差\n",
    "    source_ids = np.random.randint(0, np.sum(mask_source), size=(128,))\n",
    "    source_ids2 = np.random.randint(0, np.sum(mask_source2), size=(128,))\n",
    "    target_ids = np.random.randint(0, np.sum(mask_target), size=(128,))\n",
    "    # source1 & target\n",
    "    mmd_loss = mmd(fused_emb_s[th_mask_source.view(-1).bool()][source_ids, :],\n",
    "                   fused_emb_t[th_mask_target.view(-1).bool()][target_ids, :])\n",
    "    mmd_loss_source2_target = mmd(fused_emb_s2[th_mask_source2.view(-1).bool()][source_ids2, :],\n",
    "                                  fused_emb_t[th_mask_target.view(-1).bool()][target_ids, :])\n",
    "    mmd_loss_source2_source1 = mmd(fused_emb_s2[th_mask_source2.view(-1).bool()][source_ids2, :],\n",
    "                                   fused_emb_s[th_mask_source.view(-1).bool()][source_ids, :])\n",
    "    mmd_losses = mmd_loss + mmd_loss_source2_target + mmd_loss_source2_source1\n",
    "    # 随机抽样边256\n",
    "    source_batch_edges = np.random.randint(0, len(source_edges), size=(256,))\n",
    "    source_batch_edges2 = np.random.randint(0, len(source_edges2), size=(256,))\n",
    "    target_batch_edges = np.random.randint(0, len(target_edges), size=(256,))\n",
    "    source_batch_src = torch.Tensor(source_edges[source_batch_edges, 0]).long()\n",
    "    source_batch_dst = torch.Tensor(source_edges[source_batch_edges, 1]).long()\n",
    "    source_emb_src = fused_emb_s[source_batch_src, :]\n",
    "    source_emb_dst = fused_emb_s[source_batch_dst, :]\n",
    "    source_batch_src2 = torch.Tensor(source_edges2[source_batch_edges2, 0]).long()\n",
    "    source_batch_dst2 = torch.Tensor(source_edges2[source_batch_edges2, 1]).long()\n",
    "    source_emb_src2 = fused_emb_s2[source_batch_src2, :]\n",
    "    source_emb_dst2 = fused_emb_s2[source_batch_dst2, :]\n",
    "    target_batch_src = torch.Tensor(target_edges[target_batch_edges, 0]).long()\n",
    "    target_batch_dst = torch.Tensor(target_edges[target_batch_edges, 1]).long()\n",
    "    target_emb_src = fused_emb_t[target_batch_src, :]\n",
    "    target_emb_dst = fused_emb_t[target_batch_dst, :]\n",
    "    # 源城市目的城市使用同样的边分类器\n",
    "    pred_source = edge_disc.forward(source_emb_src, source_emb_dst)\n",
    "    pred_source2 = edge_disc.forward(source_emb_src2, source_emb_dst2)\n",
    "    pred_target = edge_disc.forward(target_emb_src, target_emb_dst)\n",
    "    source_batch_labels = torch.Tensor(source_edge_labels[source_batch_edges]).to(device)\n",
    "    source_batch_labels2 = torch.Tensor(source_edge_labels2[source_batch_edges2]).to(device)\n",
    "    target_batch_labels = torch.Tensor(target_edge_labels[target_batch_edges]).to(device)\n",
    "    # -（label*log(sigmod(pred)+0.000001)) + (1-label)*log(1-sigmod+0.000001) sum mean\n",
    "    loss_et_source = -((source_batch_labels * torch.log(torch.sigmoid(pred_source) + 1e-6)) + (\n",
    "            1 - source_batch_labels) * torch.log(1 - torch.sigmoid(pred_source) + 1e-6)).sum(1).mean()\n",
    "    loss_et_source2 = -((source_batch_labels2 * torch.log(torch.sigmoid(pred_source2) + 1e-6)) + (\n",
    "            1 - source_batch_labels2) * torch.log(1 - torch.sigmoid(pred_source2) + 1e-6)).sum(1).mean()\n",
    "    loss_et_target = -((target_batch_labels * torch.log(torch.sigmoid(pred_target) + 1e-6)) + (\n",
    "            1 - target_batch_labels) * torch.log(1 - torch.sigmoid(pred_target) + 1e-6)).sum(1).mean()\n",
    "    loss_et = loss_et_source + loss_et_target + loss_et_source2\n",
    "\n",
    "    emb_optimizer.zero_grad()\n",
    "    # 公式11\n",
    "    loss = loss_emb + mmd_w * mmd_losses + et_w * loss_et\n",
    "    loss.backward()\n",
    "    emb_optimizer.step()\n",
    "    return loss_emb.item(), mmd_losses.item(), loss_et.item()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emb_losses = []\n",
    "mmd_losses = []\n",
    "edge_losses = []\n",
    "pretrain_emb_epoch = 80\n",
    "# 预训练图数据嵌入，边类型分类，节点对齐 ——> 获得区域特征\n",
    "for emb_ep in range(pretrain_emb_epoch):\n",
    "    loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch2()\n",
    "    emb_losses.append(loss_emb_)\n",
    "    mmd_losses.append(loss_mmd_)\n",
    "    edge_losses.append(loss_et_)\n",
    "log(\"[%.2fs]Pretrain embeddings for %d epochs, average emb loss %.4f, mmd loss %.4f, edge loss %.4f\" % (\n",
    "    time.time() - start_time, pretrain_emb_epoch, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses)))\n",
    "with torch.no_grad():\n",
    "    views = mvgat(source_graphs, torch.Tensor(source_norm_poi).to(device))\n",
    "    # 融合模块指的是把多图的特征融合\n",
    "    fused_emb_s, _ = fusion(views)\n",
    "    views = mvgat(source_graphs2, torch.Tensor(source_norm_poi2).to(device))\n",
    "    fused_emb_s2, _ = fusion(views)\n",
    "    views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "    fused_emb_t, _ = fusion(views)\n",
    "# mask_source.reshape(-1) 返回的是一系列bool值，整行的含义是去除false对应的值\n",
    "# reshape(-1)的含义是，不指定变换之后有多少行，将原来的tensor变成一列（default）\n",
    "emb_s = fused_emb_s.cpu().numpy()[mask_source.reshape(-1)]\n",
    "emb_s2 = fused_emb_s2.cpu().numpy()[mask_source2.reshape(-1)]\n",
    "emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "cvscore_s = cross_validate(logreg, emb_s, source_emb_label)['test_score'].mean()\n",
    "cvscore_s2 = cross_validate(logreg, emb_s2, source_emb_label2)['test_score'].mean()\n",
    "cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "log(\"[%.2fs]Pretraining embedding, source cvscore %.4f, source2 cvscore %.4f, target cvscore %.4f\" % \\\n",
    "    (time.time() - start_time, cvscore_s, cvscore_s2, cvscore_t))\n",
    "log()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def score_of_two_city(s, t, smask, tmask):\n",
    "    \"\"\"\n",
    "    计算两个城市的分数，region of s vs whole t\n",
    "    :param tmask: 目标城市区域特征的的有效值向量\n",
    "    :param smask: 源城市区域特征的的有效值向量\n",
    "    :param s: 源城市区域特征\n",
    "    :param t: 目标城市区域特征\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    def AdjCosine_np(x, y):\n",
    "        \"\"\"\n",
    "        修正余弦相似度\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        avr = (x[0] + y[0]) / 2\n",
    "        d = np.linalg.norm(x-avr) * np.linalg.norm(y-avr)\n",
    "        return 0.5 + 0.5 * (np.dot(x-avr, y-avr) / d)\n",
    "    is_global_mean = True if args.mean == 0 else False\n",
    "    is_fix_cos = True if args.fix_cos == 0 else False\n",
    "    tt = None\n",
    "    res = None\n",
    "    if is_global_mean:\n",
    "        tt = t[tmask.view(-1).bool()].mean(0).reshape(1, 64)\n",
    "    else:\n",
    "        tt = torch.quantile(t[tmask.view(-1).bool()], torch.Tensor([i * 0.01 for i in range(0, 100, 5)]))\n",
    "    if is_fix_cos:\n",
    "        temp = []\n",
    "        for i in s:\n",
    "            temp.append(AdjCosine_np(i.cpu().numpy(), tt.cpu().numpy().reshape(64)))\n",
    "        return torch.from_numpy(np.array(temp))\n",
    "    else:\n",
    "        res = torch.cosine_similarity(s, tt)\n",
    "    return res\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    source_weights_s1_t = score_of_two_city(fused_emb_s, fused_emb_t, th_mask_source, th_mask_target)\n",
    "    source_weights_s2_t = score_of_two_city(fused_emb_s2, fused_emb_t, th_mask_source2, th_mask_target)\n",
    "    source_weights_s2_s1 = score_of_two_city(fused_emb_s2, fused_emb_s, th_mask_source2, th_mask_source)\n",
    "log(source_weights_s1_t.shape)\n",
    "log(source_weights_s2_t.shape)\n",
    "log(source_weights_s2_s1.shape)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "1.考虑去掉数据中除了八邻域的数据，其他地方全部设置为0，得到s2‘，组成一个图A'\n",
    "2.考虑不要邻域了，直接reshape，合并\n",
    "3.考虑直接在S1图的周围附加数据，（这样可能会影响S1）\n",
    "\"\"\"\n",
    "# res_score = torch.div(source_weights_s2_t, source_weights_s2_s1)\n",
    "res_score = source_weights_s2_t\n",
    "idx = source_weights_s2_t.argsort()\n",
    "idx = idx[mask_source2.reshape(-1)]\n",
    "log(res_score[idx[-args.topk_m:]])\n",
    "log(idx[-args.topk_m:])\n",
    "area_tuple = []\n",
    "include_8_nearist = []\n",
    "for i in idx[-args.topk_m:]:\n",
    "    area_tuple.append((idx_1d22d(i, (lng_source2, lat_source2))))\n",
    "log(area_tuple)\n",
    "\n",
    "\n",
    "def yield_8_near(i, ranges):\n",
    "    \"\"\"\n",
    "    产生i的8邻域，i，ranges都是元组或者可下标访问的元素，\n",
    "    :param i:\n",
    "    :param ranges:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for k in [-1, 0, 1]:\n",
    "        for p in [-1, 0, 1]:\n",
    "            if k == 0 and p == 0:\n",
    "                continue\n",
    "            elif 0 <= i[0] + k < ranges[0] and 0 <= i[1] + p < ranges[1]:\n",
    "                yield i[0] + k, i[1] + p\n",
    "\n",
    "\n",
    "is_near_8 = True if args.near == 0 else False\n",
    "if is_near_8:\n",
    "    for i in area_tuple:\n",
    "        include_8_nearist.extend(list(yield_8_near(i, (lng_source2, lat_source2))))\n",
    "else:\n",
    "    include_8_nearist = area_tuple\n",
    "include_8_nearist_2d = list(set(include_8_nearist))\n",
    "include_8_nearist_1d = []\n",
    "for i in include_8_nearist_2d:\n",
    "    include_8_nearist_1d.append(idx_2d_2_1d(i, (lng_source2, lat_source2)))\n",
    "log(include_8_nearist_2d)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "构建A*, 通过补零和reshape\n",
    "\"\"\"\n",
    "\n",
    "log(source_data.shape)\n",
    "log(source_data2.shape)\n",
    "log(len(include_8_nearist_2d))\n",
    "nearest_int = int(len(include_8_nearist_2d) / source_data.shape[2]) + 1\n",
    "log()\n",
    "wait_merge_data = []\n",
    "for i in source_data2:\n",
    "    temp = []\n",
    "    for j in include_8_nearist_2d:\n",
    "        temp.append(i[j[0]][j[1]])\n",
    "    wait_merge_data.append(temp)\n",
    "wait_merge_data = torch.from_numpy(np.array(wait_merge_data))\n",
    "zero_padding_right = torch.nn.ZeroPad2d((0, abs(nearest_int * source_data.shape[2] - wait_merge_data.shape[1]), 0, 0))\n",
    "wait_merge_data = zero_padding_right(wait_merge_data)\n",
    "wait_merge_data = wait_merge_data.reshape((wait_merge_data.shape[0], -1, source_data.shape[2]))\n",
    "log(wait_merge_data.shape)\n",
    "A_star = np.concatenate([source_data, wait_merge_data], axis=1)\n",
    "log(A_star.shape)\n",
    "\n",
    "\"\"\"\n",
    "构造A'的mask和th——mask\n",
    "\"\"\"\n",
    "A_star_mask = A_star.sum(0) > 0\n",
    "\n",
    "np.save(local_path_generate(\"..\\\\data\\\\mutlti\", \"Astar\", suffix=\"npz\"), A_star)\n",
    "np.save(local_path_generate(\"..\\\\data\\\\mutlti\", \"Astar_mask\", suffix=\"npz\"), A_star_mask)\n",
    "\n",
    "\n",
    "A_star_lng, A_star_lat = A_star.shape[1], A_star.shape[2]\n",
    "A_th_mask = torch.Tensor(A_star_mask.reshape(1, A_star_lng, A_star_lat)).to(device)\n",
    "log(\"%d valid regions in multi\" % np.sum(A_star_mask))\n",
    "# 按照百分比分配标签\n",
    "A_star_emb_label = masked_percentile_label(A_star.sum(0).reshape(-1), A_star_mask.reshape(-1))\n",
    "A_star, amax, amin = min_max_normalize(A_star)\n",
    "log((A_star.shape, amax, amin))\n",
    "A_star_train_x, A_star_train_y, A_star_val_x, A_star_val_y, A_star_test_x, A_star_test_y = split_x_y(A_star, lag)\n",
    "A_star_x = np.concatenate([A_star_train_x, A_star_val_x, A_star_test_x], axis=0)\n",
    "A_star_y = np.concatenate([A_star_train_y, A_star_val_y, A_star_test_y], axis=0)\n",
    "log(\"multi split to: x %s, y %s\" % (str(A_star_x.shape), str(A_star_y.shape)))\n",
    "A_star_test_dataset = TensorDataset(torch.Tensor(A_star_test_x), torch.Tensor(A_star_test_y))\n",
    "A_star_test_loader = DataLoader(A_star_test_dataset, batch_size=args.batch_size)\n",
    "A_star_dataset = TensorDataset(torch.Tensor(A_star_x), torch.Tensor(A_star_y))\n",
    "A_star_loader = DataLoader(A_star_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "log(source_poi.shape, source_poi2.shape)\n",
    "a = source_poi.reshape((lng_source, lat_source, 14))\n",
    "b = source_poi2.reshape((lng_source2, lat_source2, 14))\n",
    "log(a.shape)\n",
    "log(b.shape)\n",
    "wait_merge_data = []\n",
    "for i in range(b.shape[2]):\n",
    "    temp = []\n",
    "    j = b[:, :, i]\n",
    "    for p in include_8_nearist_2d:\n",
    "        temp.append(j[p[0]][p[1]])\n",
    "    wait_merge_data.append(temp)\n",
    "wait_merge_data = torch.from_numpy(np.array(wait_merge_data))\n",
    "wait_merge_data = wait_merge_data.reshape((wait_merge_data.shape[1], wait_merge_data.shape[0]))\n",
    "zero_padding_down = torch.nn.ZeroPad2d((0, 0, 0, abs(nearest_int * a.shape[1] - wait_merge_data.shape[0])))\n",
    "wait_merge_data = zero_padding_down(wait_merge_data)\n",
    "wait_merge_data = wait_merge_data.reshape((int(wait_merge_data.shape[0] / a.shape[1]), a.shape[1], a.shape[2]))\n",
    "log(wait_merge_data.shape)\n",
    "A_star_poi = np.concatenate([a, wait_merge_data], axis=0)\n",
    "log(A_star_poi.shape)\n",
    "transform = TfidfTransformer()\n",
    "A_star_poi = A_star_poi.reshape(A_star_lng * A_star_lat, -1)\n",
    "A_star_norm_poi = np.array(transform.fit_transform(A_star_poi).todense())\n",
    "log(A_star_norm_poi.shape)\n",
    "\n",
    "\n",
    "def merge_static_feature(s1, s2):\n",
    "    s1_size = (lat_source * lng_source)\n",
    "    zero_padding_s1_right = torch.nn.ZeroPad2d((0, ((A_star_lng * A_star_lat) - s1_size), 0, 0))\n",
    "    zero_padding_s1_down = torch.nn.ZeroPad2d((0, 0, 0, lat_source * nearest_int))\n",
    "    a = zero_padding_s1_right(torch.from_numpy(s1))\n",
    "    a = zero_padding_s1_down(a)\n",
    "    for i in range(len(include_8_nearist_1d)):\n",
    "        for j in range(len(include_8_nearist_1d)):\n",
    "            a[i + s1_size][j + s1_size] = s2[include_8_nearist_1d[i]][include_8_nearist_1d[j]]\n",
    "    log(a.shape)\n",
    "    if a[0:s1_size, s1_size:].sum() == 0 and a[s1_size:, 0: s1_size].sum() == 0 and a[s1_size + len(include_8_nearist_1d):  , s1_size + len(include_8_nearist_1d):].sum() == 0:\n",
    "        log(\"success\")\n",
    "    else:\n",
    "        log(\"failure\")\n",
    "    return a.numpy()\n",
    "\n",
    "\n",
    "A_star_prox_adj = add_self_loop(build_prox_graph(A_star_lng, A_star_lat))\n",
    "A_star_road_adj = merge_static_feature(source_road_adj, source_s_adj2)\n",
    "A_star_road_adj = add_self_loop(A_star_road_adj)\n",
    "A_star_poi_adj, A_star_poi_cos = build_poi_graph(A_star_norm_poi, args.topk)\n",
    "A_star_poi_adj = add_self_loop(A_star_poi_adj)\n",
    "# @todo 这里暂时也是合并成对角矩阵，之后可以试试先合成矩阵，再经过函数计算\n",
    "A_star_s_adj = merge_static_feature(source_s_adj, source_s_adj2)\n",
    "A_star_d_adj = merge_static_feature(source_d_adj, source_d_adj2)\n",
    "A_star_od_adj = merge_static_feature(source_od_adj, source_od_adj2)\n",
    "A_star_s_adj = add_self_loop(A_star_s_adj)\n",
    "A_star_d_adj = add_self_loop(A_star_d_adj)\n",
    "A_star_od_adj = add_self_loop(A_star_od_adj)\n",
    "\n",
    "log(\"A_star graphs: \")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (A_star_prox_adj.shape[0], np.sum(A_star_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (A_star_road_adj.shape[0], np.sum(A_star_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (A_star_poi_adj.shape[0], np.sum(A_star_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (A_star_s_adj.shape[0], np.sum(A_star_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (A_star_d_adj.shape[0], np.sum(A_star_d_adj > 0)))\n",
    "log()\n",
    "\n",
    "A_star_graphs = adjs_to_graphs([A_star_prox_adj, A_star_road_adj, A_star_poi_adj, A_star_s_adj, A_star_d_adj])\n",
    "target_graphs = adjs_to_graphs([target_prox_adj, target_road_adj, target_poi_adj, target_s_adj, target_d_adj])\n",
    "for i in range(len(source_graphs)):\n",
    "    A_star_graphs[i] = A_star_graphs[i].to(device)\n",
    "    target_graphs[i] = target_graphs[i].to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A_star_edges, A_star_edge_labels = graphs_to_edge_labels(A_star_graphs)\n",
    "num_gat_layers = 2\n",
    "in_dim = 14\n",
    "hidden_dim = 64\n",
    "emb_dim = 64\n",
    "num_heads = 2\n",
    "mmd_w = args.mmd_w\n",
    "et_w = args.et_w\n",
    "ma_param = args.ma_coef\n",
    "\n",
    "mvgat = MVGAT(len(A_star_graphs), num_gat_layers, in_dim, hidden_dim, emb_dim, num_heads, True).to(device)\n",
    "fusion = FusionModule(len(A_star_graphs), emb_dim, 0.8).to(device)\n",
    "scoring = Scoring(emb_dim, A_th_mask, th_mask_target).to(device)\n",
    "scoring2 = Scoring2(emb_dim, A_th_mask, th_mask_target).to(device)\n",
    "edge_disc = EdgeTypeDiscriminator(len(A_star_graphs), emb_dim).to(device)\n",
    "mmd = MMD_loss()\n",
    "# we still need a scoring model.\n",
    "# [NS, 64], [NT, 64] -> [NS]\n",
    "\n",
    "# build model\n",
    "if args.model == 'STResNet':\n",
    "    net = STResNet(len(lag), 1, 3).to(device)\n",
    "elif args.model == 'STNet_nobn':\n",
    "    net = STNet_nobn(1, 3, th_mask_target, sigmoid_out=True).to(device)\n",
    "    log(net)\n",
    "elif args.model == 'STNet':\n",
    "    net = STNet(1, 3, th_mask_target).to(device)\n",
    "    log(net)\n",
    "pred_optimizer = optim.Adam(net.parameters(), lr=args.pred_lr, weight_decay=args.weight_decay)\n",
    "# 图卷积，融合，边类型分类器参数单独训练\n",
    "emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 元学习部分\n",
    "meta_optimizer = optim.Adam(scoring.parameters(), lr=args.outerlr, weight_decay=args.weight_decay)\n",
    "meta_optimizer2 = optim.Adam(scoring2.parameters(), lr=args.outerlr, weight_decay=args.weight_decay)\n",
    "best_val_rmse = 999\n",
    "best_test_rmse = 999\n",
    "best_test_mae = 999\n",
    "p_bar.process(5, 1, 5)\n",
    "\n",
    "\"\"\"\n",
    "需要对meta_train_epoch修改一下，符合多城市要求\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def meta_train_epoch(s_embs, t_embs, th_mask_source, th_mask_target):\n",
    "    \"\"\"\n",
    "    0. 计算source_weights，通过scoring网络\n",
    "    1. 获取net 也就是预测网络的参数，分为两部分，一部分是命名参数，另一部分是非命名 fast_weights, bn_vars\n",
    "    2. 从源城市抽样，计算预测值，使用net网络，从输出格式判断使用的具体网络，计算损失\n",
    "    3. 通过torch.autograd.grad 计算loss对于fast_weights的梯度，并且更新fast_weights，注意2,3都是在更新net网络\n",
    "    4. 同理抽样目的城市，计算梯度，更新fast_weights\n",
    "    5. meta_loss = q_loss + weights_mean * args.weight_reg，计算meta loss\n",
    "    6. 根据meta loss 更新scoring meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "    7. 循环以上，则总体更新了scoring网络，net预测网络\n",
    "    :param s_embs:\n",
    "    :param t_embs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_query_losses = []\n",
    "    for meta_ep in range(args.outeriter):\n",
    "        fast_losses = []\n",
    "        fast_weights, bn_vars = get_weights_bn_vars(net)\n",
    "        source_weights = scoring2(s_embs, t_embs)\n",
    "        # inner loop on source, pre-train with weights\n",
    "        for meta_it in range(args.sinneriter):\n",
    "            s_x, s_y = batch_sampler((torch.Tensor(A_star_x), torch.Tensor(A_star_y)), args.batch_size)\n",
    "            s_x = s_x.to(device)\n",
    "            s_y = s_y.to(device)\n",
    "            pred_source = net.functional_forward(s_x, th_mask_source.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_source.shape) == 4:  # STResNet\n",
    "                loss_source = ((pred_source - s_y) ** 2).view(args.batch_size, 1, -1)[:, :,\n",
    "                              th_mask_source.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_source = (loss_source * source_weights).mean(0).sum()\n",
    "            elif len(pred_source.shape) == 3:  # STNet\n",
    "                s_y = s_y.view(args.batch_size, 1, -1)[:, :, th_mask_source.view(-1).bool()]\n",
    "                loss_source = (((pred_source - s_y) ** 2) * source_weights.view(1, 1, -1))\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_source = loss_source.mean(0).sum()\n",
    "            # size = 1 基本可以认为是标量\n",
    "            fast_loss = loss_source\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            # 计算输出对于输入独立的梯度，\n",
    "            # fast_weights.values()。size = 22\n",
    "            # grad。size=22\n",
    "            # 此处对于fast_weights 进行梯度下降学习\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        # inner loop on target, simulate fine-tune\n",
    "        # 模拟微调和源训练都是在训练net预测网络，并没有提及权重和特征\n",
    "        for meta_it in range(args.tinneriter):\n",
    "            t_x, t_y = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            t_x = t_x.to(device)\n",
    "            t_y = t_y.to(device)\n",
    "            pred_t = net.functional_forward(t_x, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_t.shape) == 4:  # STResNet\n",
    "                loss_t = ((pred_t - t_y) ** 2).view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            elif len(pred_t.shape) == 3:  # STNet\n",
    "                t_y = t_y.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(t_y.shape)\n",
    "                loss_t = ((pred_t - t_y) ** 2)  # .view(1, 1, -1))\n",
    "                # log(loss_t.shape)\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            fast_loss = loss_t\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        q_losses = []\n",
    "        target_iter = max(args.sinneriter, args.tinneriter)\n",
    "        for k in range(3):\n",
    "            # query loss\n",
    "            x_q, y_q = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            x_q = x_q.to(device)\n",
    "            y_q = y_q.to(device)\n",
    "            pred_q = net.functional_forward(x_q, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_q.shape) == 4:  # STResNet\n",
    "                loss = (((pred_q - y_q) ** 2) * (th_mask_target.view(1, 1, lng_target, lat_target)))\n",
    "                loss = loss.mean(0).sum()\n",
    "            elif len(pred_q.shape) == 3:  # STNet\n",
    "                y_q = y_q.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                loss = ((pred_q - y_q) ** 2).mean(0).sum()\n",
    "            q_losses.append(loss)\n",
    "        q_loss = torch.stack(q_losses).mean()\n",
    "        # ** 乘方\n",
    "        weights_mean = (source_weights ** 2).mean()\n",
    "        # meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        # 这里对于权重开始了联系\n",
    "        # meta loss 只训练了scoring网络\n",
    "        meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        meta_optimizer2.zero_grad()\n",
    "        meta_loss.backward(inputs=list(scoring2.parameters()))\n",
    "        torch.nn.utils.clip_grad_norm_(scoring2.parameters(), max_norm=2)\n",
    "        meta_optimizer2.step()\n",
    "        meta_query_losses.append(q_loss.item())\n",
    "    return np.mean(meta_query_losses)\n",
    "\n",
    "\n",
    "def train_emb_epoch(source_graphs, source_norm_poi, source_od_adj, source_poi_cos, target_graphs, target_norm_poi,\n",
    "                    target_od_adj, target_poi_cos):\n",
    "    \"\"\"\n",
    "    训练图网络-特征网络，融合网络，边类型分类器\n",
    "    1. 通过forward_emb融合特征，计算损失，\n",
    "    2. 抽样边，标签，训练边缘分类器，抽样计算MMD误差\n",
    "    3. 反向传播计算\n",
    "    emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "    emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    训练特征网络 mvgat，fusion，边缘分类器，节点MMD，在训练的同时，对于mvgat和fusion的特征进行指导，特征重新对齐分布\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # loss， 460*64， 5*460*64\n",
    "    loss_source, fused_emb_s, embs_s = forward_emb(source_graphs, source_norm_poi, source_od_adj, source_poi_cos)\n",
    "    loss_target, fused_emb_t, embs_t = forward_emb(target_graphs, target_norm_poi, target_od_adj, target_poi_cos)\n",
    "    loss_emb = loss_source + loss_target\n",
    "    # compute domain adaptation loss\n",
    "    # 随机抽样128个，计算最大平均误差\n",
    "    source_ids = np.random.randint(0, np.sum(A_star_mask), size=(128,))\n",
    "    target_ids = np.random.randint(0, np.sum(mask_target), size=(128,))\n",
    "    mmd_loss = mmd(fused_emb_s[A_th_mask.view(-1).bool()][source_ids, :],\n",
    "                   fused_emb_t[th_mask_target.view(-1).bool()][target_ids, :])\n",
    "    # 随机抽样边256\n",
    "    source_batch_edges = np.random.randint(0, len(source_edges), size=(256,))\n",
    "    target_batch_edges = np.random.randint(0, len(target_edges), size=(256,))\n",
    "    source_batch_src = torch.Tensor(source_edges[source_batch_edges, 0]).long()\n",
    "    source_batch_dst = torch.Tensor(source_edges[source_batch_edges, 1]).long()\n",
    "    source_emb_src = fused_emb_s[source_batch_src, :]\n",
    "    source_emb_dst = fused_emb_s[source_batch_dst, :]\n",
    "    target_batch_src = torch.Tensor(target_edges[target_batch_edges, 0]).long()\n",
    "    target_batch_dst = torch.Tensor(target_edges[target_batch_edges, 1]).long()\n",
    "    target_emb_src = fused_emb_t[target_batch_src, :]\n",
    "    target_emb_dst = fused_emb_t[target_batch_dst, :]\n",
    "    # 源城市目的城市使用同样的边分类器\n",
    "    pred_source = edge_disc.forward(source_emb_src, source_emb_dst)\n",
    "    pred_target = edge_disc.forward(target_emb_src, target_emb_dst)\n",
    "    source_batch_labels = torch.Tensor(source_edge_labels[source_batch_edges]).to(device)\n",
    "    target_batch_labels = torch.Tensor(target_edge_labels[target_batch_edges]).to(device)\n",
    "    # -（label*log(sigmod(pred)+0.000001)) + (1-label)*log(1-sigmod+0.000001) sum mean\n",
    "    loss_et_source = -((source_batch_labels * torch.log(torch.sigmoid(pred_source) + 1e-6)) + (\n",
    "            1 - source_batch_labels) * torch.log(1 - torch.sigmoid(pred_source) + 1e-6)).sum(1).mean()\n",
    "    loss_et_target = -((target_batch_labels * torch.log(torch.sigmoid(pred_target) + 1e-6)) + (\n",
    "            1 - target_batch_labels) * torch.log(1 - torch.sigmoid(pred_target) + 1e-6)).sum(1).mean()\n",
    "    loss_et = loss_et_source + loss_et_target\n",
    "\n",
    "    emb_optimizer.zero_grad()\n",
    "    # 公式11\n",
    "    loss = loss_emb + mmd_w * mmd_loss + et_w * loss_et\n",
    "    loss.backward()\n",
    "    emb_optimizer.step()\n",
    "    return loss_emb.item(), mmd_loss.item(), loss_et.item()\n",
    "\n",
    "\n",
    "emb_losses = []\n",
    "mmd_losses = []\n",
    "edge_losses = []\n",
    "pretrain_emb_epoch = 80\n",
    "# 预训练图数据嵌入，边类型分类，节点对齐 ——> 获得区域特征\n",
    "for emb_ep in range(pretrain_emb_epoch):\n",
    "    loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch(\n",
    "        source_graphs=A_star_graphs, source_norm_poi=A_star_norm_poi, source_od_adj=A_star_od_adj,\n",
    "        source_poi_cos=A_star_poi_cos,\n",
    "        target_graphs=target_graphs, target_norm_poi=target_norm_poi, target_od_adj=target_od_adj,\n",
    "        target_poi_cos=target_poi_cos\n",
    "    )\n",
    "    emb_losses.append(loss_emb_)\n",
    "    mmd_losses.append(loss_mmd_)\n",
    "    edge_losses.append(loss_et_)\n",
    "log(\"[%.2fs]Pretrain embeddings for %d epochs, average emb loss %.4f, mmd loss %.4f, edge loss %.4f\" % (\n",
    "    time.time() - start_time, pretrain_emb_epoch, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses)))\n",
    "with torch.no_grad():\n",
    "    views = mvgat(A_star_graphs, torch.Tensor(A_star_norm_poi).to(device))\n",
    "    # 融合模块指的是把多图的特征融合\n",
    "    fused_emb_A_star, _ = fusion(views)\n",
    "    views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "    fused_emb_t, _ = fusion(views)\n",
    "\n",
    "\n",
    "emb_s = fused_emb_A_star.cpu().numpy()[A_star_mask.reshape(-1)]\n",
    "emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "\"\"\"\n",
    "交叉验证，有时亦称循环估计[1] [2] [3]， 是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析，而其它子集则用来做后续对此分析的确认及验证。一开始的子集被称为训练集。而其它的子集则被称为验证集或测试集。\n",
    "交叉验证的目的，是用未用来给模型作训练的新数据，测试模型的性能，以便减少诸如过拟合和选择偏差等问题，并给出模型如何在一个独立的数据集上通用化（即，一个未知的数据集，如实际问题中的数据）。\n",
    "交叉验证的理论是由Seymour Geisser所开始的。它对于防范根据数据建议的测试假设是非常重要的，特别是当后续的样本是危险、成本过高或科学上不适合时去搜集。\n",
    "\"\"\"\n",
    "cvscore_s = cross_validate(logreg, emb_s, A_star_emb_label)['test_score'].mean()\n",
    "cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "log(\"[%.2fs]Pretraining embedding, source cvscore %.4f, target cvscore %.4f\" % \\\n",
    "    (time.time() - start_time, cvscore_s, cvscore_t))\n",
    "log()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 后期要用这个参数\n",
    "source_weights_ma_list = []\n",
    "source_weight_list = []\n",
    "p_bar = process_bar(final_prompt=\"训练完成\", unit=\"epoch\")\n",
    "p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "writer = SummaryWriter(\"log-{}-batch-{}-name-{}-type-{}-model-{}-amount-{}-topk-{}-time-{}\".\n",
    "                       format(\"多城市{} and {}-{}\".format(args.scity, args.scity2, args.tcity), args.batch_size,\n",
    "                              args.dataname,\n",
    "                              args.datatype, args.model, args.data_amount, args.topk, get_timestamp(split=\"-\")))\n",
    "for ep in range(num_epochs):\n",
    "    net.train()\n",
    "    mvgat.train()\n",
    "    fusion.train()\n",
    "    scoring.train()\n",
    "    scoring2.train()\n",
    "\n",
    "    # train embeddings\n",
    "    emb_losses = []\n",
    "    mmd_losses = []\n",
    "    edge_losses = []\n",
    "    for emb_ep in range(5):\n",
    "        loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch(\n",
    "            source_graphs=A_star_graphs, source_norm_poi=A_star_norm_poi, source_od_adj=A_star_od_adj,\n",
    "            source_poi_cos=A_star_poi_cos,\n",
    "            target_graphs=target_graphs, target_norm_poi=target_norm_poi, target_od_adj=target_od_adj,\n",
    "            target_poi_cos=target_poi_cos\n",
    "        )\n",
    "        emb_losses.append(loss_emb_)\n",
    "        mmd_losses.append(loss_mmd_)\n",
    "        edge_losses.append(loss_et_)\n",
    "    # evaluate embeddings\n",
    "    with torch.no_grad():\n",
    "        # mvgat 是把邻接矩阵转换成tensor，大小是城市的长宽之积 * 64（demb）也就是定义的区域特征向量的维度\n",
    "        views = mvgat(A_star_graphs, torch.Tensor(A_star_norm_poi).to(device))\n",
    "        fused_emb_s, _ = fusion(views)\n",
    "        views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "        fused_emb_t, _ = fusion(views)\n",
    "    if ep % 2 == 0:\n",
    "        \"\"\"\n",
    "        每两个epoch显示一些数据\n",
    "        \"\"\"\n",
    "        emb_s = fused_emb_s.cpu().numpy()[A_star_mask.reshape(-1)]\n",
    "        emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "        mix_embs = np.concatenate([emb_s, emb_t], axis=0)\n",
    "        mix_labels = np.concatenate([A_star_emb_label, target_emb_label])\n",
    "        logreg = LogisticRegression(max_iter=500)\n",
    "        cvscore_s = cross_validate(logreg, emb_s, A_star_emb_label)['test_score'].mean()\n",
    "        cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "        cvscore_mix = cross_validate(logreg, mix_embs, mix_labels)['test_score'].mean()\n",
    "        log(\n",
    "            \"[%.2fs]Epoch %d, embedding loss %.4f, mmd loss %.4f, edge loss %.4f, source cvscore %.4f, target cvscore %.4f, mixcvscore %.4f\" % \\\n",
    "            (time.time() - start_time, ep, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses), cvscore_s,\n",
    "             cvscore_t, cvscore_mix))\n",
    "    if ep == num_epochs - 1:\n",
    "        \"\"\"\n",
    "        最后一个epoch，\n",
    "        \"\"\"\n",
    "        emb_s = fused_emb_s.cpu().numpy()[A_star_mask.reshape(-1)]\n",
    "        emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "        # np.save(\"%s.npy\" % args.scity, arr = emb_s)\n",
    "        # np.save(\"%s.npy\" % args.tcity, arr = emb_t)\n",
    "        # with torch.no_grad():\n",
    "        #     trans_emb_s = scoring.score(fused_emb_s)\n",
    "        #     trans_emb_t = scoring.score(fused_emb_t)\n",
    "        # np.save(\"%s_trans.npy\" % args.scity, arr = trans_emb_s.cpu().numpy()[mask_source.reshape(-1)])\n",
    "        # np.save(\"%s_trans.npy\" % args.tcity, arr = trans_emb_t.cpu().numpy()[mask_target.reshape(-1)])\n",
    "\n",
    "    # meta train scorings\n",
    "    avg_q_loss = meta_train_epoch(fused_emb_s, fused_emb_t, th_mask_source=A_th_mask, th_mask_target=th_mask_target)\n",
    "    with torch.no_grad():\n",
    "        source_weights = scoring2(fused_emb_s, fused_emb_t)\n",
    "        source_weight_list.append(list(source_weights.cpu().numpy()))\n",
    "\n",
    "    # For debug: use fixed weightings.\n",
    "    # with torch.no_grad():\n",
    "    #     source_weights_ = scoring(fused_emb_s, fused_emb_t)\n",
    "    # avg_q_loss = 0\n",
    "    # source_weights = torch.ones_like(source_weights_)\n",
    "\n",
    "    # implement a moving average\n",
    "    if ep == 0:\n",
    "        source_weights_ma = torch.ones_like(source_weights, device=device, requires_grad=False)\n",
    "    source_weights_ma = ma_param * source_weights_ma + (1 - ma_param) * source_weights\n",
    "    source_weights_ma_list.append(list(source_weights_ma.cpu().numpy()))\n",
    "    # train network on source\n",
    "    # 有了参数lambda rs，训练net网络\n",
    "    source_loss = train_epoch(net, A_star_loader, pred_optimizer, weights=source_weights_ma, mask=A_th_mask,\n",
    "                              num_iters=args.pretrain_iter)\n",
    "    avg_source_loss = np.mean(source_loss)\n",
    "    avg_target_loss = evaluate(net, target_train_loader, spatial_mask=th_mask_target)[0]\n",
    "    log(\n",
    "        \"[%.2fs]Epoch %d, average meta query loss %.4f, source weight mean %.4f, var %.6f, source loss %.4f, target_loss %.4f\" % \\\n",
    "        (time.time() - start_time, ep, avg_q_loss, source_weights_ma.mean().item(), torch.var(source_weights_ma).item(),\n",
    "         avg_source_loss, avg_target_loss))\n",
    "    writer.add_scalar(\"average meta query loss\", avg_q_loss, ep)\n",
    "    writer.add_scalar(\"source weight mean\", source_weights_ma.mean().item(), ep)\n",
    "    writer.add_scalar(\"var\", torch.var(source_weights_ma).item(), ep)\n",
    "    writer.add_scalar(\"avg_source_loss\", avg_source_loss, ep)\n",
    "    writer.add_scalar(\"avg_target_loss\", avg_target_loss, ep)\n",
    "    log(torch.var(source_weights).item())\n",
    "    log(source_weights.mean().item())\n",
    "    if source_weights_ma.mean() < 0.005:\n",
    "        # stop pre-training\n",
    "        break\n",
    "    net.eval()\n",
    "    rmse_val, mae_val, target_val_losses = evaluate(net, target_val_loader, spatial_mask=th_mask_target)\n",
    "    rmse_s_val, mae_s_val, source_val_losses = evaluate(net, A_star_loader, spatial_mask=A_th_mask)\n",
    "    log(\n",
    "        \"Epoch %d, source validation rmse %.4f, mae %.4f\" % (ep, rmse_s_val * (smax - smin), mae_s_val * (smax - smin)))\n",
    "    log(\"Epoch %d, target validation rmse %.4f, mae %.4f\" % (\n",
    "        ep, rmse_val * (max_val - min_val), mae_val * (max_val - min_val)))\n",
    "    log()\n",
    "    writer.add_scalar(\"source validation rmse\", rmse_s_val * (smax - smin), ep)\n",
    "    writer.add_scalar(\"source validation mse\", mae_s_val * (smax - smin), ep)\n",
    "    writer.add_scalar(\"target validation rmse_val\", rmse_val * (max_val - min_val), ep)\n",
    "    writer.add_scalar(\"target validation mae_val\", mae_val * (max_val - min_val), ep)\n",
    "    sums = 0\n",
    "    for i in range(len(target_val_losses)):\n",
    "        sums = sums + target_val_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"train source val loss\", sums, ep)\n",
    "    sums = 0\n",
    "    for i in range(len(source_val_losses)):\n",
    "        sums = sums + source_val_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"train target val loss\", sums, ep)\n",
    "    p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "\"\"\"\n",
    "save_obj(source_weights_ma_list, path=\"source_weights_ma_list_{}.list\".format(scity))\n",
    "save_obj(source_weight_list, path=\"source_weight_list_{}.list\".format(scity))\n",
    "\"\"\"\n",
    "\n",
    "for ep in range(num_epochs, num_tuine_epochs + num_epochs):\n",
    "    # fine-tuning\n",
    "    net.train()\n",
    "    avg_loss = train_epoch(net, target_train_loader, pred_optimizer, mask=th_mask_target)\n",
    "    log('[%.2fs]Epoch %d, target pred loss %.4f' % (time.time() - start_time, ep, np.mean(avg_loss)))\n",
    "    writer.add_scalar(\"target pred loss\", np.mean(avg_loss), ep - num_epochs)\n",
    "    net.eval()\n",
    "    rmse_val, mae_val, val_losses = evaluate(net, target_val_loader, spatial_mask=th_mask_target)\n",
    "    rmse_test, mae_test, test_losses = evaluate(net, target_test_loader, spatial_mask=th_mask_target)\n",
    "    sums = 0\n",
    "    for i in range(len(val_losses)):\n",
    "        sums = sums + val_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"target train val loss\", sums, ep - num_epochs)\n",
    "    sums = 0\n",
    "    for i in range(len(test_losses)):\n",
    "        sums = sums + test_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"target train test loss\", sums, ep - num_epochs)\n",
    "    if rmse_val < best_val_rmse:\n",
    "        best_val_rmse = rmse_val\n",
    "        best_test_rmse = rmse_test\n",
    "        best_test_mae = mae_test\n",
    "        log(\"Update best test...\")\n",
    "    log(\"validation rmse %.4f, mae %.4f\" % (rmse_val * (max_val - min_val), mae_val * (max_val - min_val)))\n",
    "    log(\"test rmse %.4f, mae %.4f\" % (rmse_test * (max_val - min_val), mae_test * (max_val - min_val)))\n",
    "    writer.add_scalar(\"validation rmse\", rmse_val * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"validation mae\", mae_val * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"test rmse\", rmse_test * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"test mae\", mae_test * (max_val - min_val), ep - num_epochs)\n",
    "    log()\n",
    "    p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "\n",
    "log(\"Best test rmse %.4f, mae %.4f\" % (best_test_rmse * (max_val - min_val), best_test_mae * (max_val - min_val)))\n",
    "root_dir = local_path_generate(\n",
    "    \"./model/{}\".format(\n",
    "        \"{}-batch-{}-{}-{}-{}-amount-{}-topk-{}-time-{}\".format(\n",
    "            \"多城市{}and{}-{}\".format(args.scity, args.scity2, args.tcity),\n",
    "            args.batch_size, args.dataname, args.datatype, args.model, args.data_amount,\n",
    "            args.topk, get_timestamp(split=\"-\")\n",
    "        )\n",
    "    ), create_folder_only=True)\n",
    "torch.save(net, root_dir + \"/net.pth\")\n",
    "torch.save(mvgat, root_dir + \"/mvgat.pth\")\n",
    "torch.save(fusion, root_dir + \"/fusion.pth\")\n",
    "torch.save(scoring, root_dir + \"/scoring.pth\")\n",
    "torch.save(scoring2, root_dir + \"/scoring2.pth\")\n",
    "torch.save(edge_disc, root_dir + \"/edge_disc.pth\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
