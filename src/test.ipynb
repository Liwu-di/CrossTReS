{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PaperCrawlerUtil.common_util import *\n",
    "from PaperCrawlerUtil.constant import *\n",
    "from PaperCrawlerUtil.crawler_util import *\n",
    "from dgl.nn import GATConv\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import *\n",
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:09   Running CrossTReS, from NY and CHI to DC, Taxi pickup experiments, with 0 days of data, on STNet_nobn model\n",
      " 20%|██        | 1/5 [00:00<00:00, 18.93part/s]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_config(logs_style=LOG_STYLE_ALL)\n",
    "p_bar = process_bar(final_prompt=\"初始化准备完成\", unit=\"part\")\n",
    "p_bar.process(0, 1, 5)\n",
    "# This file implements the full version of using region embeddings to select good source data.\n",
    "parser = argparse.ArgumentParser()\n",
    "# 源城市\n",
    "parser.add_argument('--scity', type=str, default='NY')\n",
    "# 目标城市\n",
    "parser.add_argument('--tcity', type=str, default='DC')\n",
    "# 数据集名称\n",
    "parser.add_argument('--dataname', type=str, default='Taxi', help='Within [Bike, Taxi]')\n",
    "# 数据类型\n",
    "parser.add_argument('--datatype', type=str, default='pickup', help='Within [pickup, dropoff]')\n",
    "# 尝试减小，看显存能不能撑住 32 -> 16\n",
    "parser.add_argument('--batch_size', type=int, default=16)\n",
    "# 模型\n",
    "parser.add_argument(\"--model\", type=str, default='STNet_nobn', help='Within [STResNet, STNet, STNet_nobn]')\n",
    "# 学习率\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "# 权重\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5)\n",
    "# 100回合跑下来数据有问题，改成40epoch看看，论文也是这个\n",
    "parser.add_argument('--num_epochs', type=int, default=80, help='Number of source training epochs')\n",
    "parser.add_argument('--num_tuine_epochs', type=int, default=80, help='Number of fine tuine epochs')\n",
    "# gpu设备序号\n",
    "parser.add_argument('--gpu', type=int, default=0)\n",
    "# 随机种子 不知道是干嘛的\n",
    "parser.add_argument('--seed', type=int, default=-1, help='Random seed. -1 means do not manually set. ')\n",
    "# 数据量\n",
    "parser.add_argument('--data_amount', type=int, default=0, help='0: full data, 30/7/3 correspond to days of data')\n",
    "# 内循环 源训练数量\n",
    "parser.add_argument('--sinneriter', type=int, default=3, help='Number of inner iterations (source) for meta learning')\n",
    "# 内循环 微调数量\n",
    "parser.add_argument('--tinneriter', type=int, default=1, help='Number of inner iterations (target) for meta learning')\n",
    "# 内循环元学习学习率\n",
    "parser.add_argument('--innerlr', type=float, default=5e-5, help='Learning rate for inner loop of meta-learning')\n",
    "# 外循环数量\n",
    "parser.add_argument('--outeriter', type=int, default=20, help='Number of outer iterations for meta-learning')\n",
    "# 外循环学习率\n",
    "parser.add_argument('--outerlr', type=float, default=1e-4, help='Learning rate for the outer loop of meta-learning')\n",
    "# 前k个参数\n",
    "parser.add_argument('--topk', type=int, default=15)\n",
    "# 最大平均误差参数 ，也就是beta1\n",
    "parser.add_argument('--mmd_w', type=float, default=2, help='mmd weight')\n",
    "# 边缘分类器参数， beta2\n",
    "parser.add_argument('--et_w', type=float, default=2, help='edge classifier weight')\n",
    "# 源域权重的移动平均参数\n",
    "parser.add_argument(\"--ma_coef\", type=float, default=0.6, help='Moving average parameter for source domain weights')\n",
    "# 源域权重的正则化器。\n",
    "parser.add_argument(\"--weight_reg\", type=float, default=1e-3, help=\"Regularizer for the source domain weights.\")\n",
    "# 预训练回合数\n",
    "parser.add_argument(\"--pretrain_iter\", type=int, default=-1, help='Pre-training iterations per pre-training epoch. ')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.seed != -1:\n",
    "    # seed( ) 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed( )值，则每次生成的随即数都相同，\n",
    "    # 如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。\n",
    "    # random.seed(something)只能是一次有效\n",
    "    # seed( ) 用于指定随机数生成时所用算法开始的整数值。\n",
    "    # 1.如果使用相同的seed( )值，则每次生成的随即数都相同；\n",
    "    # 2.如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。\n",
    "    # 3.设置的seed()值仅一次有效\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "# 设置训练设备\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)\n",
    "gpu_available = torch.cuda.is_available()\n",
    "if gpu_available:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "p_bar.process(1, 1, 5)\n",
    "dataname = args.dataname\n",
    "scity = args.scity\n",
    "scity2 = \"CHI\"\n",
    "tcity = args.tcity\n",
    "datatype = args.datatype\n",
    "num_epochs = args.num_epochs\n",
    "num_tuine_epochs = args.num_tuine_epochs\n",
    "start_time = time.time()\n",
    "log(\"Running CrossTReS, from %s and %s to %s, %s %s experiments, with %d days of data, on %s model\" % \\\n",
    "    (scity, scity2, tcity, dataname, datatype, args.data_amount, args.model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:10   207 valid regions in target\n",
      " 40%|████      | 2/5 [00:00<00:00,  9.35part/s]"
     ]
    }
   ],
   "source": [
    "# Load spatio temporal data\n",
    "# (8784, 21, 20)\n",
    "# 8784 = 366 * 24\n",
    "target_data = np.load(\"../data/%s/%s%s_%s.npy\" % (tcity, dataname, tcity, datatype))\n",
    "# (21, 20) 经纬度分割\n",
    "lng_target, lat_target = target_data.shape[1], target_data.shape[2]\n",
    "# numpy.sum()，求和某一维度或者维度为none时，求和所有，减掉一个维度\n",
    "# 此处，target_data (8784, 21, 20) -> (21, 20)\n",
    "# 然后，通过对于每个元素判断是否大于0， 转成Bool向量\n",
    "mask_target = target_data.sum(0) > 0\n",
    "# reshape （21， 20） -》 （1， 21， 20）\n",
    "th_mask_target = torch.Tensor(mask_target.reshape(1, lng_target, lat_target)).to(device)\n",
    "log(\"%d valid regions in target\" % np.sum(mask_target))\n",
    "# (（21， 20）-> 420, （21， 20）-> 420)\n",
    "target_emb_label = masked_percentile_label(target_data.sum(0).reshape(-1), mask_target.reshape(-1))\n",
    "p_bar.process(2, 1, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:10   (8784, 20, 23)           \n",
      "2022-10-20 11:31:10   458 valid regions in source\n",
      "2022-10-20 11:31:10   (8784, 17, 28)           \n",
      "2022-10-20 11:31:10   270 valid regions in source\n",
      " 40%|████      | 2/5 [00:00<00:00,  9.35part/s]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (8784, 20, 23)\n",
    "source_data = np.load(\"../data/%s/%s%s_%s.npy\" % (scity, dataname, scity, datatype))\n",
    "log(source_data.shape)\n",
    "# (20, 23)\n",
    "lng_source, lat_source = source_data.shape[1], source_data.shape[2]\n",
    "mask_source = source_data.sum(0) > 0\n",
    "# mask -> th_mask = (20, 23) -> (1, 20, 23)\n",
    "th_mask_source = torch.Tensor(mask_source.reshape(1, lng_source, lat_source)).to(device)\n",
    "log(\"%d valid regions in source\" % np.sum(mask_source))\n",
    "\n",
    "source_data2 = np.load(\"../data/%s/%s%s_%s.npy\" % (scity2, dataname, scity2, datatype))\n",
    "log(source_data2.shape)\n",
    "lng_source2, lat_source2 = source_data2.shape[1], source_data2.shape[2]\n",
    "mask_source2 = source_data2.sum(0) > 0\n",
    "th_mask_source2 = torch.Tensor(mask_source2.reshape(1, lng_source2, lat_source2)).to(device)\n",
    "log(\"%d valid regions in source\" % np.sum(mask_source2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:00<00:00,  9.33part/s]"
     ]
    }
   ],
   "source": [
    "# 按照百分比分配标签\n",
    "source_emb_label = masked_percentile_label(source_data.sum(0).reshape(-1), mask_source.reshape(-1))\n",
    "p_bar.process(3, 1, 5)\n",
    "lag = [-6, -5, -4, -3, -2, -1]\n",
    "source_data, smax, smin = min_max_normalize(source_data)\n",
    "target_data, max_val, min_val = min_max_normalize(target_data)\n",
    "\n",
    "source_emb_label2 = masked_percentile_label(source_data2.sum(0).reshape(-1), mask_source2.reshape(-1))\n",
    "source_data2, smax2, smin2 = min_max_normalize(source_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# [(5898, 6, 20, 23), (5898, 1, 20, 23), (1440, 6, 20, 23), (1440, 1, 20, 23), (1440, 6, 20, 23), (1440, 1, 20, 23)]\n",
    "# 第一维是数量，第二维是每条数据中的数量\n",
    "source_train_x, source_train_y, source_val_x, source_val_y, source_test_x, source_test_y = split_x_y(source_data, lag)\n",
    "source_train_x2, source_train_y2, source_val_x2, source_val_y2, source_test_x2, source_test_y2 = split_x_y(source_data2, lag)\n",
    "# we concatenate all source data\n",
    "# (8778, 6, 20, 23)\n",
    "source_x = np.concatenate([source_train_x, source_val_x, source_test_x], axis=0)\n",
    "# (8778, 1, 20, 23)\n",
    "source_y = np.concatenate([source_train_y, source_val_y, source_test_y], axis=0)\n",
    "source_x2 = np.concatenate([source_train_x2, source_val_x2, source_test_x2], axis=0)\n",
    "source_y2 = np.concatenate([source_train_y2, source_val_y2, source_test_y2], axis=0)\n",
    "target_train_x, target_train_y, target_val_x, target_val_y, target_test_x, target_test_y = split_x_y(target_data, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:13   Source split to: x (8778, 6, 20, 23), y (8778, 1, 20, 23)\n",
      "2022-10-20 11:31:13   Source2 split to: x (8778, 6, 17, 28), y (8778, 1, 17, 28)\n",
      "2022-10-20 11:31:13   Target split to: train_x (5898, 6, 21, 20), train_y (5898, 1, 21, 20)\n",
      "2022-10-20 11:31:13   val_x (1440, 6, 21, 20), val_y (1440, 1, 21, 20)\n",
      "2022-10-20 11:31:13   test_x (1440, 6, 21, 20), test_y (1440, 1, 21, 20)\n",
      " 60%|██████    | 3/5 [00:03<00:00,  9.33part/s]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.data_amount != 0:\n",
    "    # 负号表示从倒数方向数，\n",
    "    # i.e.\n",
    "    # a = [12, 3, 4, 5, 6, 7, 8]\n",
    "    # c, d = a[-2:], a[:-2]\n",
    "    # print(c)\n",
    "    # print(d)\n",
    "    # [7, 8]\n",
    "    # [12, 3, 4, 5, 6]\n",
    "    target_train_x = target_train_x[-args.data_amount * 24:, :, :, :]\n",
    "    target_train_y = target_train_y[-args.data_amount * 24:, :, :, :]\n",
    "log(\"Source split to: x %s, y %s\" % (str(source_x.shape), str(source_y.shape)))\n",
    "# log(\"val_x %s, val_y %s\" % (str(source_val_x.shape), str(source_val_y.shape)))\n",
    "# log(\"test_x %s, test_y %s\" % (str(source_test_x.shape), str(source_test_y.shape)))\n",
    "log(\"Source2 split to: x %s, y %s\" % (str(source_x2.shape), str(source_y2.shape)))\n",
    "log(\"Target split to: train_x %s, train_y %s\" % (str(target_train_x.shape), str(target_train_y.shape)))\n",
    "log(\"val_x %s, val_y %s\" % (str(target_val_x.shape), str(target_val_y.shape)))\n",
    "log(\"test_x %s, test_y %s\" % (str(target_test_x.shape), str(target_test_y.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:03<00:01,  1.43s/part]"
     ]
    }
   ],
   "source": [
    "# 这些代码 numpy -> Tensor -> TensorDataset -> DataLoader\n",
    "target_train_dataset = TensorDataset(torch.Tensor(target_train_x), torch.Tensor(target_train_y))\n",
    "target_val_dataset = TensorDataset(torch.Tensor(target_val_x), torch.Tensor(target_val_y))\n",
    "target_test_dataset = TensorDataset(torch.Tensor(target_test_x), torch.Tensor(target_test_y))\n",
    "target_train_loader = DataLoader(target_train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "target_val_loader = DataLoader(target_val_dataset, batch_size=args.batch_size)\n",
    "target_test_loader = DataLoader(target_test_dataset, batch_size=args.batch_size)\n",
    "source_test_dataset = TensorDataset(torch.Tensor(source_test_x), torch.Tensor(source_test_y))\n",
    "source_test_loader = DataLoader(source_test_dataset, batch_size=args.batch_size)\n",
    "source_dataset = TensorDataset(torch.Tensor(source_x), torch.Tensor(source_y))\n",
    "source_loader = DataLoader(source_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "source_test_dataset2 = TensorDataset(torch.Tensor(source_test_x2), torch.Tensor(source_test_y2))\n",
    "source_test_loader2 = DataLoader(source_test_dataset2, batch_size=args.batch_size)\n",
    "source_dataset2 = TensorDataset(torch.Tensor(source_x2), torch.Tensor(source_y2))\n",
    "source_loader2 = DataLoader(source_dataset2, batch_size=args.batch_size, shuffle=True)\n",
    "p_bar.process(4, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load auxiliary data: poi data\n",
    "# (20, 23, 14)\n",
    "source_poi = np.load(\"../data/%s/%s_poi.npy\" % (scity, scity))\n",
    "source_poi2 = np.load(\"../data/%s/%s_poi.npy\" % (scity2, scity2))\n",
    "target_poi = np.load(\"../data/%s/%s_poi.npy\" % (tcity, tcity))\n",
    "# (460, 14)\n",
    "source_poi = source_poi.reshape(lng_source * lat_source, -1)  # regions * classes\n",
    "source_poi2 = source_poi2.reshape(lng_source2 * lat_source2, -1)  # regions * classes\n",
    "target_poi = target_poi.reshape(lng_target * lat_target, -1)  # regions * classes\n",
    "transform = TfidfTransformer()\n",
    "# 规范正则化到（0，1）\n",
    "source_norm_poi = np.array(transform.fit_transform(source_poi).todense())\n",
    "transform = TfidfTransformer()\n",
    "# 规范正则化到（0，1）\n",
    "source_norm_poi2 = np.array(transform.fit_transform(source_poi2).todense())\n",
    "transform = TfidfTransformer()\n",
    "target_norm_poi = np.array(transform.fit_transform(target_poi).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:17   Source graphs:           \n",
      "2022-10-20 11:31:17   prox_adj: 460 nodes, 3886 edges\n",
      "2022-10-20 11:31:17   road adj: 460 nodes, 3332 edges\n",
      "2022-10-20 11:31:17   poi_adj, 460 nodes, 3490 edges\n",
      "2022-10-20 11:31:17   s_adj, 460 nodes, 3508 edges\n",
      "2022-10-20 11:31:17   d_adj, 460 nodes, 3972 edges\n",
      "2022-10-20 11:31:17                            \n",
      "2022-10-20 11:31:17   Source2 graphs:          \n",
      "2022-10-20 11:31:17   prox_adj: 476 nodes, 4018 edges\n",
      "2022-10-20 11:31:17   road adj: 476 nodes, 2564 edges\n",
      "2022-10-20 11:31:17   poi_adj, 476 nodes, 2924 edges\n",
      "2022-10-20 11:31:17   s_adj, 476 nodes, 2308 edges\n",
      "2022-10-20 11:31:17   d_adj, 476 nodes, 2012 edges\n",
      "2022-10-20 11:31:17                            \n",
      "2022-10-20 11:31:17   Target graphs:           \n",
      "2022-10-20 11:31:17   prox_adj: 420 nodes, 3538 edges\n",
      "2022-10-20 11:31:17   road adj: 420 nodes, 2838 edges\n",
      "2022-10-20 11:31:17   poi_adj, 420 nodes, 3624 edges\n",
      "2022-10-20 11:31:17   s_adj, 420 nodes, 2114 edges\n",
      "2022-10-20 11:31:17   d_adj, 420 nodes, 1890 edges\n",
      "2022-10-20 11:31:17                            \n",
      " 80%|████████  | 4/5 [00:07<00:01,  1.43s/part]"
     ]
    }
   ],
   "source": [
    "# Build graphs\n",
    "# add_self_loop 增加一个自循环，对角线的值=1\n",
    "source_prox_adj = add_self_loop(build_prox_graph(lng_source, lat_source))\n",
    "source_prox_adj2 = add_self_loop(build_prox_graph(lng_source2, lat_source2))\n",
    "target_prox_adj = add_self_loop(build_prox_graph(lng_target, lat_target))\n",
    "source_road_adj = add_self_loop(build_road_graph(scity, lng_source, lat_source))\n",
    "source_road_adj2 = add_self_loop(build_road_graph(scity2, lng_source2, lat_source2))\n",
    "target_road_adj = add_self_loop(build_road_graph(tcity, lng_target, lat_target))\n",
    "source_poi_adj, source_poi_cos = build_poi_graph(source_norm_poi, args.topk)\n",
    "source_poi_adj2, source_poi_cos2 = build_poi_graph(source_norm_poi2, args.topk)\n",
    "target_poi_adj, target_poi_cos = build_poi_graph(target_norm_poi, args.topk)\n",
    "source_poi_adj = add_self_loop(source_poi_adj)\n",
    "source_poi_adj2 = add_self_loop(source_poi_adj2)\n",
    "target_poi_adj = add_self_loop(target_poi_adj)\n",
    "source_s_adj, source_d_adj, source_od_adj = build_source_dest_graph(scity, dataname, lng_source, lat_source, args.topk)\n",
    "source_s_adj2, source_d_adj2, source_od_adj2 = build_source_dest_graph(scity2, dataname, lng_source2, lat_source2, args.topk)\n",
    "target_s_adj, target_d_adj, target_od_adj = build_source_dest_graph(tcity, dataname, lng_target, lat_target, args.topk)\n",
    "source_s_adj = add_self_loop(source_s_adj)\n",
    "source_s_adj2 = add_self_loop(source_s_adj2)\n",
    "source_t_adj = add_self_loop(source_d_adj)\n",
    "source_t_adj2 = add_self_loop(source_d_adj2)\n",
    "source_od_adj = add_self_loop(source_od_adj)\n",
    "source_od_adj2 = add_self_loop(source_od_adj2)\n",
    "target_s_adj = add_self_loop(target_s_adj)\n",
    "target_t_adj = add_self_loop(target_d_adj)\n",
    "target_od_adj = add_self_loop(target_od_adj)\n",
    "log(\"Source graphs: \")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (source_prox_adj.shape[0], np.sum(source_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (source_road_adj.shape[0], np.sum(source_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (source_poi_adj.shape[0], np.sum(source_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (source_s_adj.shape[0], np.sum(source_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (source_d_adj.shape[0], np.sum(source_d_adj > 0)))\n",
    "log()\n",
    "log(\"Source2 graphs: \")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (source_prox_adj2.shape[0], np.sum(source_prox_adj2)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (source_road_adj2.shape[0], np.sum(source_road_adj2 > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (source_poi_adj2.shape[0], np.sum(source_poi_adj2 > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (source_s_adj2.shape[0], np.sum(source_s_adj2 > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (source_d_adj2.shape[0], np.sum(source_d_adj2 > 0)))\n",
    "log()\n",
    "log(\"Target graphs:\")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (target_prox_adj.shape[0], np.sum(target_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (target_road_adj.shape[0], np.sum(target_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (target_poi_adj.shape[0], np.sum(target_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (target_s_adj.shape[0], np.sum(target_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (target_d_adj.shape[0], np.sum(target_d_adj > 0)))\n",
    "log()\n",
    "source_graphs = adjs_to_graphs([source_prox_adj, source_road_adj, source_poi_adj, source_s_adj, source_d_adj])\n",
    "source_graphs2 = adjs_to_graphs([source_prox_adj2, source_road_adj2, source_poi_adj2, source_s_adj2, source_d_adj2])\n",
    "target_graphs = adjs_to_graphs([target_prox_adj, target_road_adj, target_poi_adj, target_s_adj, target_d_adj])\n",
    "for i in range(len(source_graphs)):\n",
    "    source_graphs[i] = source_graphs[i].to(device)\n",
    "    source_graphs2[i] = source_graphs2[i].to(device)\n",
    "    target_graphs[i] = target_graphs[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  4.24s/part, 初始化准备完成]"
     ]
    }
   ],
   "source": [
    "# This function is a preparation for the edge type discriminator\n",
    "def graphs_to_edge_labels(graphs):\n",
    "    \"\"\"\n",
    "    准备边缘分类器的训练材料， 边的表示（起点，终点），边的标识【0,0,0,0,0】\n",
    "    :param graphs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    edge_label_dict = {}\n",
    "    for i, graph in enumerate(graphs):\n",
    "        src, dst = graph.edges()\n",
    "        for s, d in zip(src, dst):\n",
    "            s = s.item()\n",
    "            d = d.item()\n",
    "            if (s, d) not in edge_label_dict:\n",
    "                edge_label_dict[(s, d)] = np.zeros(len(graphs))\n",
    "            edge_label_dict[(s, d)][i] = 1\n",
    "    edges = []\n",
    "    edge_labels = []\n",
    "    for k in edge_label_dict.keys():\n",
    "        edges.append(k)\n",
    "        edge_labels.append(edge_label_dict[k])\n",
    "    edges = np.array(edges)\n",
    "    edge_labels = np.array(edge_labels)\n",
    "    return edges, edge_labels\n",
    "\n",
    "\n",
    "source_edges, source_edge_labels = graphs_to_edge_labels(source_graphs)\n",
    "source_edges2, source_edge_labels2 = graphs_to_edge_labels(source_graphs2)\n",
    "target_edges, target_edge_labels = graphs_to_edge_labels(target_graphs)\n",
    "p_bar.process(5, 1, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:29   STNet_nobn(                              \n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (layers): ModuleList(\n",
      "    (0): ResUnit_nobn(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResUnit_nobn(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResUnit_nobn(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (lstm): LSTM(64, 128)\n",
      "  (linear1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "100%|██████████| 5/5 [00:19<00:00,  4.24s/part, 初始化准备完成]"
     ]
    }
   ],
   "source": [
    "# build models\n",
    "# we need one embedding model, one scoring model, one prediction model\n",
    "# 图注意力\n",
    "class MVGAT(nn.Module):\n",
    "    def __init__(self, num_graphs=3, num_gat_layer=2, in_dim=14, hidden_dim=64, emb_dim=32, num_heads=2, residual=True):\n",
    "        super().__init__()\n",
    "        self.num_graphs = num_graphs\n",
    "        self.num_gat_layer = num_gat_layer\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.residual = residual\n",
    "\n",
    "        self.multi_gats = nn.ModuleList()\n",
    "        for j in range(self.num_gat_layer):\n",
    "            gats = nn.ModuleList()\n",
    "            for i in range(self.num_graphs):\n",
    "                if j == 0:\n",
    "                    gats.append(GATConv(self.in_dim,\n",
    "                                        self.hidden_dim,\n",
    "                                        self.num_heads,\n",
    "                                        residual=self.residual,\n",
    "                                        allow_zero_in_degree=True))\n",
    "                elif j == self.num_gat_layer - 1:\n",
    "                    gats.append(GATConv(self.hidden_dim * self.num_heads,\n",
    "                                        self.emb_dim // self.num_heads,\n",
    "                                        self.num_heads,\n",
    "                                        residual=self.residual,\n",
    "                                        allow_zero_in_degree=True))\n",
    "                else:\n",
    "                    gats.append(GATConv(self.hidden_dim * self.num_heads,\n",
    "                                        self.hidden_dim,\n",
    "                                        self.num_heads,\n",
    "                                        residual=self.residual,\n",
    "                                        allow_zero_in_degree=True))\n",
    "            self.multi_gats.append(gats)\n",
    "\n",
    "    def forward(self, graphs, feat):\n",
    "        views = []\n",
    "        for i in range(self.num_graphs):\n",
    "            for j in range(self.num_gat_layer):\n",
    "                if j == 0:\n",
    "                    z = self.multi_gats[j][i](graphs[i], feat)\n",
    "                else:\n",
    "                    z = self.multi_gats[j][i](graphs[i], z)\n",
    "                if j != self.num_gat_layer - 1:\n",
    "                    z = F.relu(z)\n",
    "                z = z.flatten(1)\n",
    "            views.append(z)\n",
    "        return views\n",
    "\n",
    "\n",
    "# 融合模型\n",
    "class FusionModule(nn.Module):\n",
    "    \"\"\"\n",
    "    融合多图模型的特征，使用了注意力机制，用全连接实现\n",
    "    \"\"\"\n",
    "    def __init__(self, num_graphs, emb_dim, alpha):\n",
    "        super().__init__()\n",
    "        self.num_graphs = num_graphs\n",
    "        self.emb_dim = emb_dim\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.fusion_linear = nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        self.self_q = nn.ModuleList()\n",
    "        self.self_k = nn.ModuleList()\n",
    "        for i in range(self.num_graphs):\n",
    "            self.self_q.append(nn.Linear(self.emb_dim, self.emb_dim))\n",
    "            self.self_k.append(nn.Linear(self.emb_dim, self.emb_dim))\n",
    "\n",
    "    def forward(self, views):\n",
    "        \"\"\"\n",
    "        views -> cat_views cat_views = torch.stack(views, dim=0)\n",
    "        for 1 - 5\n",
    "            cat_views = 5*460*64\n",
    "            attn = torch.matmul(Q, K.transpose(1, 2))\n",
    "            output = torch.matmul(attn, cat_views)\n",
    "        average\n",
    "        views = self.alpha * self_attentions[i] + (1 - self.alpha) * views[i]\n",
    "        for 1 - 5\n",
    "            mv_outputs.append(torch.sigmoid(self.fusion_linear(views[i])) * views[i])\n",
    "        fused_outputs = sum(mv_outputs)\n",
    "        mv_outputs.append(torch.sigmoid(self.fusion_linear(views[i])) * views[i])\n",
    "        fused_outputs = sum(mv_outputs)\n",
    "        return fused_outputs, [(views[i] + fused_outputs) / 2 for i in range(self.num_graphs)]\n",
    "        :param views:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # run fusion by self attention\n",
    "        # 5个460*64 -> 5*460*64\n",
    "        cat_views = torch.stack(views, dim=0)\n",
    "        self_attentions = []\n",
    "        # 注意力分数计算\n",
    "        for i in range(self.num_graphs):\n",
    "            Q = self.self_q[i](cat_views)\n",
    "            K = self.self_k[i](cat_views)\n",
    "            # (3, num_nodes, 64)\n",
    "            attn = F.softmax(torch.matmul(Q, K.transpose(1, 2)) / np.sqrt(self.emb_dim), dim=-1)\n",
    "            # (3, num_nodes, num_nodes)\n",
    "            output = torch.matmul(attn, cat_views)\n",
    "            self_attentions.append(output)\n",
    "        self_attentions = sum(self_attentions) / self.num_graphs\n",
    "        # (3, num_nodes, 64 * 2)\n",
    "        for i in range(self.num_graphs):\n",
    "            views[i] = self.alpha * self_attentions[i] + (1 - self.alpha) * views[i]\n",
    "\n",
    "        # further run multi-view fusion\n",
    "        mv_outputs = []\n",
    "        for i in range(self.num_graphs):\n",
    "            mv_outputs.append(torch.sigmoid(self.fusion_linear(views[i])) * views[i])\n",
    "\n",
    "        fused_outputs = sum(mv_outputs)\n",
    "        # next_in = [(view + fused_outputs) / 2 for view in views]\n",
    "        return fused_outputs, [(views[i] + fused_outputs) / 2 for i in range(self.num_graphs)]\n",
    "\n",
    "\n",
    "# 评分模型\n",
    "class Scoring(nn.Module):\n",
    "    def __init__(self, emb_dim, source_mask, target_mask):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.score = nn.Sequential(nn.Linear(self.emb_dim, self.emb_dim // 2),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(self.emb_dim // 2, self.emb_dim // 2))\n",
    "        self.source_mask = source_mask\n",
    "        self.target_mask = target_mask\n",
    "\n",
    "    def forward(self, source_emb, target_emb):\n",
    "        \"\"\"\n",
    "        求源城市评分\n",
    "        注意这里求评分，是source的每一个区域对于目标城市整体\n",
    "        换句话说，是形参2的每一个区域，对于形参3整体\n",
    "        :param target_mask:\n",
    "        :param source_mask:\n",
    "        :param source_emb:\n",
    "        :param target_emb:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # target_context = tanh(self.score(target_emb[bool mask]).mean(0))\n",
    "        # 对于横向的进行求平均 460*64 -> 460*32 -> 207*32 -> 纵向求平均 1*32 代表所有目标城市\n",
    "        target_context = torch.tanh(\n",
    "            torch.quantile(\n",
    "                self.score(target_emb[self.target_mask.view(-1).bool()]),\n",
    "                torch.Tensor([0.1, 0.25, 0.5, 0.75, 0.9]).to(device), dim=0).mean(0)\n",
    "        )\n",
    "        source_trans_emb = self.score(source_emb)\n",
    "        # 460*32 * 1*32 = 462*32, 这里乘法表示1*32列表去乘460*32的每一行，逐元素\n",
    "        # i.e.\n",
    "        # tensor([[2, 2, 2],\n",
    "        #         [1, 2, 2],\n",
    "        #         [2, 2, 1]])\n",
    "        # tensor([[2, 2, 2]])\n",
    "        # tensor([[4, 4, 4],\n",
    "        #         [2, 4, 4],\n",
    "        #         [4, 4, 2]])\n",
    "        source_score = (source_trans_emb * target_context).sum(1)\n",
    "        # the following lines modify inner product similarity to cosine similarity\n",
    "        # target_norm = target_context.pow(2).sum().pow(1/2)\n",
    "        # source_norm = source_trans_emb.pow(2).sum(1).pow(1/2)\n",
    "        # source_score /= source_norm\n",
    "        # source_score /= target_norm\n",
    "        # log(source_score)\n",
    "        return F.relu(torch.tanh(source_score))[self.source_mask.view(-1).bool()]\n",
    "\n",
    "\n",
    "# 最大平均误差\n",
    "class MMD_loss(nn.Module):\n",
    "    def __init__(self, kernel_mul=2.0, kernel_num=5):\n",
    "        super(MMD_loss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = None\n",
    "\n",
    "    def gaussian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0 - total1) ** 2).sum(2)\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples ** 2 - n_samples)\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
    "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        batch_size = int(source.size()[0])\n",
    "        kernels = self.gaussian_kernel(source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num,\n",
    "                                       fix_sigma=self.fix_sigma)\n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        loss = torch.mean(XX + YY - XY - YX)\n",
    "        return loss\n",
    "\n",
    "\n",
    "mmd = MMD_loss()\n",
    "\n",
    "\n",
    "# 边类型分类器\n",
    "class EdgeTypeDiscriminator(nn.Module):\n",
    "    def __init__(self, num_graphs, emb_dim):\n",
    "        super().__init__()\n",
    "        self.num_graphs = num_graphs\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_network = nn.Sequential(nn.Linear(2 * self.emb_dim, self.emb_dim),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(self.emb_dim, self.num_graphs))\n",
    "\n",
    "    def forward(self, src_embs, dst_embs):\n",
    "        edge_vec = torch.cat([src_embs, dst_embs], dim=1)\n",
    "        return self.edge_network(edge_vec)\n",
    "\n",
    "\n",
    "num_gat_layers = 2\n",
    "in_dim = 14\n",
    "hidden_dim = 64\n",
    "emb_dim = 64\n",
    "num_heads = 2\n",
    "mmd_w = args.mmd_w\n",
    "et_w = args.et_w\n",
    "ma_param = args.ma_coef\n",
    "\n",
    "mvgat = MVGAT(len(source_graphs), num_gat_layers, in_dim, hidden_dim, emb_dim, num_heads, True).to(device)\n",
    "fusion = FusionModule(len(source_graphs), emb_dim, 0.8).to(device)\n",
    "scoring = Scoring(emb_dim, th_mask_source, th_mask_target).to(device)\n",
    "edge_disc = EdgeTypeDiscriminator(len(source_graphs), emb_dim).to(device)\n",
    "mmd = MMD_loss()\n",
    "# we still need a scoring model.\n",
    "# [NS, 64], [NT, 64] -> [NS]\n",
    "\n",
    "# build model\n",
    "if args.model == 'STResNet':\n",
    "    net = STResNet(len(lag), 1, 3).to(device)\n",
    "elif args.model == 'STNet_nobn':\n",
    "    net = STNet_nobn(1, 3, th_mask_target, sigmoid_out=True).to(device)\n",
    "    log(net)\n",
    "elif args.model == 'STNet':\n",
    "    net = STNet(1, 3, th_mask_target).to(device)\n",
    "    log(net)\n",
    "\n",
    "# net估计是预测网络\n",
    "pred_optimizer = optim.Adam(net.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 图卷积，融合，边类型分类器参数单独训练\n",
    "emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 元学习部分\n",
    "meta_optimizer = optim.Adam(scoring.parameters(), lr=args.outerlr, weight_decay=args.weight_decay)\n",
    "best_val_rmse = 999\n",
    "best_test_rmse = 999\n",
    "best_test_mae = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(net_, loader, spatial_mask):\n",
    "    \"\"\"\n",
    "    评估函数，spatial_mask去掉了一些无效数据\n",
    "    :param net_:\n",
    "    :param loader:\n",
    "    :param spatial_mask:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_.eval()\n",
    "    with torch.no_grad():\n",
    "        se = 0\n",
    "        ae = 0\n",
    "        valid_points = 0\n",
    "        losses = []\n",
    "        for it_ in loader:\n",
    "            if len(it_) == 2:\n",
    "                (x, y) = it_\n",
    "            elif len(it_) == 4:\n",
    "                _, _, x, y = it_\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            lng = x.shape[2]\n",
    "            lat = x.shape[3]\n",
    "            out = net_(x, spatial_mask=spatial_mask.bool())\n",
    "            valid_points += x.shape[0] * spatial_mask.sum().item()\n",
    "            if len(out.shape) == 4:  # STResNet\n",
    "                se += (((out - y) ** 2) * (spatial_mask.view(1, 1, lng, lat))).sum().item()\n",
    "                ae += ((out - y).abs() * (spatial_mask.view(1, 1, lng, lat))).sum().item()\n",
    "                eff_batch_size = y.shape[0]\n",
    "                loss = ((out - y) ** 2).view(eff_batch_size, 1, -1)[:, :, spatial_mask.view(-1).bool()]\n",
    "                losses.append(loss)\n",
    "            elif len(out.shape) == 3:  # STNet\n",
    "                batch_size = y.shape[0]\n",
    "                lag = y.shape[1]\n",
    "                y = y.view(batch_size, lag, -1)[:, :, spatial_mask.view(-1).bool()]\n",
    "                # log(\"out\", out.shape)\n",
    "                # log(\"y\", y.shape)\n",
    "                se += ((out - y) ** 2).sum().item()\n",
    "                ae += (out - y).abs().sum().item()\n",
    "                loss = ((out - y) ** 2)\n",
    "                losses.append(loss)\n",
    "    return np.sqrt(se / valid_points), ae / valid_points, losses\n",
    "\n",
    "\n",
    "def batch_sampler(tensor_list, batch_size):\n",
    "    \"\"\"\n",
    "    返回抽样数据\n",
    "    :param tensor_list: 元组或者list，随机抽取batchsize的数量\n",
    "    :param batch_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_samples = tensor_list[0].size(0)\n",
    "    idx = np.random.permutation(num_samples)[:batch_size]\n",
    "    return (x[idx] for x in tensor_list)\n",
    "\n",
    "\n",
    "def get_weights_bn_vars(module):\n",
    "    \"\"\"\n",
    "    获取未命名的参数名称,以及命名参数\n",
    "    :param module:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fast_weights = OrderedDict(module.named_parameters())\n",
    "    bn_vars = OrderedDict()\n",
    "    for k in module.state_dict():\n",
    "        if k not in fast_weights.keys():\n",
    "            bn_vars[k] = module.state_dict()[k]\n",
    "    return fast_weights, bn_vars\n",
    "\n",
    "\n",
    "def train_epoch(net_, loader_, optimizer_, weights=None, mask=None, num_iters=None):\n",
    "    \"\"\"\n",
    "    训练预测网络pred net网络，依据权重weights 修改loss，如\n",
    "    loss = ((out - y) ** 2)\n",
    "    loss = (loss * weights.view(1, 1, -1)).mean(0).sum()\n",
    "    再反向传播optimizer_\n",
    "    :param net_:\n",
    "    :param loader_:\n",
    "    :param optimizer_:\n",
    "    :param weights:\n",
    "    :param mask:\n",
    "    :param num_iters:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_.train()\n",
    "    epoch_loss = []\n",
    "    for i, (x, y) in enumerate(loader_):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = net_(x, spatial_mask=mask.bool())\n",
    "        if len(out.shape) == 4:  # STResNet\n",
    "            eff_batch_size = y.shape[0]\n",
    "            loss = ((out - y) ** 2).view(eff_batch_size, 1, -1)[:, :, mask.view(-1).bool()]\n",
    "            # log(\"loss\", loss.shape)\n",
    "            if weights is not None:\n",
    "                loss = (loss * weights)\n",
    "                # log(\"weights\", weights.shape)\n",
    "                # log(\"loss * weights\", loss.shape)\n",
    "                loss = loss.mean(0).sum()\n",
    "            else:\n",
    "                loss = loss.mean(0).sum()\n",
    "        elif len(out.shape) == 3:  # STNet\n",
    "            eff_batch_size = y.shape[0]\n",
    "            y = y.view(eff_batch_size, 1, -1)[:, :, mask.view(-1).bool()]\n",
    "            loss = ((out - y) ** 2)\n",
    "            if weights is not None:\n",
    "                # log(loss.shape)\n",
    "                # log(weights.shape)\n",
    "                loss = (loss * weights.view(1, 1, -1)).mean(0).sum()\n",
    "            else:\n",
    "                loss = loss.mean(0).sum()\n",
    "        optimizer_.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net_.parameters(), max_norm=2)\n",
    "        optimizer_.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        if num_iters is not None and num_iters == i:\n",
    "            break\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 这个代码还用不到，有报错，单独拿出来，不执行\n",
    "def train_rt_epoch(net_, loader_, optimizer_):\n",
    "    net_.train()\n",
    "    epoch_predloss = []\n",
    "    epoch_rtloss = []\n",
    "    epoch_loss = []\n",
    "    for i, (source_x, source_y, target_x, target_y) in enumerate(loader_):\n",
    "        source_x = source_x.to(device)\n",
    "        source_y = source_y.to(device)\n",
    "        target_x = target_x.to(device)\n",
    "        target_y = target_y.to(device)\n",
    "        source_feat, _ = net_(source_x, spatial_mask=th_mask_source.bool(), return_feat=True)\n",
    "        target_feat, target_out = net_(target_x, return_feat=True)\n",
    "        batch_size = target_y.shape[0]\n",
    "        lag = target_y.shape[1]\n",
    "        target_y = target_y.view(batch_size, lag, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "        loss_pred = ((target_out - target_y) ** 2).mean(0).sum()\n",
    "        matching_source_feat = source_feat[:, matching_indices, :]\n",
    "        loss_rt = (((target_feat - matching_source_feat) ** 2).sum(2) * matching_weight).sum(1).mean()\n",
    "        loss = loss_pred + args.rt_weight * loss_rt\n",
    "        optimizer_.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_.step()\n",
    "        epoch_predloss.append(loss_pred.item())\n",
    "        epoch_rtloss.append(loss_rt.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "    return np.mean(epoch_predloss), np.mean(epoch_rtloss), np.mean(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def forward_emb(graphs_, in_feat_, od_adj_, poi_cos_):\n",
    "    \"\"\"\n",
    "    1. 图卷积提取图特征 mvgat\n",
    "    2. 融合多图特征 fusion\n",
    "    3. 对于多图中的s，d，poi进行预测，并计算损失函数\n",
    "    :param graphs_:\n",
    "    :param in_feat_:\n",
    "    :param od_adj_:\n",
    "    :param poi_cos_:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 图注意，注意这里用了小写，指的是forward方法\n",
    "    views = mvgat(graphs_, torch.Tensor(in_feat_).to(device))\n",
    "    fused_emb, embs = fusion(views)\n",
    "    # embs嵌入是5个图，以下找出start，destination， poi图\n",
    "    s_emb = embs[-2]\n",
    "    d_emb = embs[-1]\n",
    "    poi_emb = embs[-3]\n",
    "    # start和destination相乘求出记录预测s和d\n",
    "    recons_sd = torch.matmul(s_emb, d_emb.transpose(0, 1))\n",
    "    # 注意dim维度0和1分别求s和d\n",
    "    pred_d = torch.log(torch.softmax(recons_sd, dim=1) + 1e-5)\n",
    "    loss_d = (torch.Tensor(od_adj_).to(device) * pred_d).mean()\n",
    "    pred_s = torch.log(torch.softmax(recons_sd, dim=0) + 1e-5)\n",
    "    loss_s = (torch.Tensor(od_adj_).to(device) * pred_s).mean()\n",
    "    # poi预测求差，loss\n",
    "    poi_sim = torch.matmul(poi_emb, poi_emb.transpose(0, 1))\n",
    "    loss_poi = ((poi_sim - torch.Tensor(poi_cos_).to(device)) ** 2).mean()\n",
    "    loss = -loss_s - loss_d + loss_poi\n",
    "\n",
    "    return loss, fused_emb, embs\n",
    "\n",
    "\n",
    "def meta_train_epoch(s_embs, t_embs):\n",
    "    \"\"\"\n",
    "    0. 计算source_weights，通过scoring网络\n",
    "    1. 获取net 也就是预测网络的参数，分为两部分，一部分是命名参数，另一部分是非命名 fast_weights, bn_vars\n",
    "    2. 从源城市抽样，计算预测值，使用net网络，从输出格式判断使用的具体网络，计算损失\n",
    "    3. 通过torch.autograd.grad 计算loss对于fast_weights的梯度，并且更新fast_weights，注意2,3都是在更新net网络\n",
    "    4. 同理抽样目的城市，计算梯度，更新fast_weights\n",
    "    5. meta_loss = q_loss + weights_mean * args.weight_reg，计算meta loss\n",
    "    6. 根据meta loss 更新scoring meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "    7. 循环以上，则总体更新了scoring网络，net预测网络\n",
    "    :param s_embs:\n",
    "    :param t_embs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_query_losses = []\n",
    "    for meta_ep in range(args.outeriter):\n",
    "        fast_losses = []\n",
    "        fast_weights, bn_vars = get_weights_bn_vars(net)\n",
    "        source_weights = scoring(s_embs, t_embs)\n",
    "        # inner loop on source, pre-train with weights\n",
    "        for meta_it in range(args.sinneriter):\n",
    "            s_x, s_y = batch_sampler((torch.Tensor(source_x), torch.Tensor(source_y)), args.batch_size)\n",
    "            s_x = s_x.to(device)\n",
    "            s_y = s_y.to(device)\n",
    "            pred_source = net.functional_forward(s_x, th_mask_source.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_source.shape) == 4:  # STResNet\n",
    "                loss_source = ((pred_source - s_y) ** 2).view(args.batch_size, 1, -1)[:, :,\n",
    "                              th_mask_source.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_source = (loss_source * source_weights).mean(0).sum()\n",
    "            elif len(pred_source.shape) == 3:  # STNet\n",
    "                s_y = s_y.view(args.batch_size, 1, -1)[:, :, th_mask_source.view(-1).bool()]\n",
    "                loss_source = (((pred_source - s_y) ** 2) * source_weights.view(1, 1, -1))\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_source = loss_source.mean(0).sum()\n",
    "            # size = 1 基本可以认为是标量\n",
    "            fast_loss = loss_source\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            # 计算输出对于输入独立的梯度，\n",
    "            # fast_weights.values()。size = 22\n",
    "            # grad。size=22\n",
    "            # 此处对于fast_weights 进行梯度下降学习\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        # inner loop on target, simulate fine-tune\n",
    "        # 模拟微调和源训练都是在训练net预测网络，并没有提及权重和特征\n",
    "        for meta_it in range(args.tinneriter):\n",
    "            t_x, t_y = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            t_x = t_x.to(device)\n",
    "            t_y = t_y.to(device)\n",
    "            pred_t = net.functional_forward(t_x, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_t.shape) == 4:  # STResNet\n",
    "                loss_t = ((pred_t - t_y) ** 2).view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            elif len(pred_t.shape) == 3:  # STNet\n",
    "                t_y = t_y.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(t_y.shape)\n",
    "                loss_t = ((pred_t - t_y) ** 2)  # .view(1, 1, -1))\n",
    "                # log(loss_t.shape)\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            fast_loss = loss_t\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        q_losses = []\n",
    "        target_iter = max(args.sinneriter, args.tinneriter)\n",
    "        for k in range(3):\n",
    "            # query loss\n",
    "            x_q, y_q = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            x_q = x_q.to(device)\n",
    "            y_q = y_q.to(device)\n",
    "            pred_q = net.functional_forward(x_q, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_q.shape) == 4:  # STResNet\n",
    "                loss = (((pred_q - y_q) ** 2) * (th_mask_target.view(1, 1, lng_target, lat_target)))\n",
    "                loss = loss.mean(0).sum()\n",
    "            elif len(pred_q.shape) == 3:  # STNet\n",
    "                y_q = y_q.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                loss = ((pred_q - y_q) ** 2).mean(0).sum()\n",
    "            q_losses.append(loss)\n",
    "        q_loss = torch.stack(q_losses).mean()\n",
    "        # ** 乘方\n",
    "        weights_mean = (source_weights ** 2).mean()\n",
    "        # meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        # 这里对于权重开始了联系\n",
    "        # meta loss 只训练了scoring网络\n",
    "        meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        meta_optimizer.zero_grad()\n",
    "        meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "        torch.nn.utils.clip_grad_norm_(scoring.parameters(), max_norm=2)\n",
    "        meta_optimizer.step()\n",
    "        meta_query_losses.append(q_loss.item())\n",
    "    return np.mean(meta_query_losses)\n",
    "\n",
    "\n",
    "def train_emb_epoch():\n",
    "    \"\"\"\n",
    "    训练图网络-特征网络，融合网络，边类型分类器\n",
    "    1. 通过forward_emb融合特征，计算损失，\n",
    "    2. 抽样边，标签，训练边缘分类器，抽样计算MMD误差\n",
    "    3. 反向传播计算\n",
    "    emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "    emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    训练特征网络 mvgat，fusion，边缘分类器，节点MMD，在训练的同时，对于mvgat和fusion的特征进行指导，特征重新对齐分布\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # loss， 460*64， 5*460*64\n",
    "    loss_source, fused_emb_s, embs_s = forward_emb(source_graphs, source_norm_poi, source_od_adj, source_poi_cos)\n",
    "    loss_source2, fused_emb_s2, embs_s2 = forward_emb(source_graphs2, source_norm_poi2, source_od_adj2, source_poi_cos2)\n",
    "    loss_target, fused_emb_t, embs_t = forward_emb(target_graphs, target_norm_poi, target_od_adj, target_poi_cos)\n",
    "\n",
    "    loss_emb = loss_source + loss_target + loss_source2\n",
    "    # compute domain adaptation loss\n",
    "    # 随机抽样128个，计算最大平均误差\n",
    "    source_ids = np.random.randint(0, np.sum(mask_source), size=(128,))\n",
    "    source_ids2 = np.random.randint(0, np.sum(mask_source2), size=(128,))\n",
    "    target_ids = np.random.randint(0, np.sum(mask_target), size=(128,))\n",
    "    # source1 & target\n",
    "    mmd_loss = mmd(fused_emb_s[th_mask_source.view(-1).bool()][source_ids, :],\n",
    "                   fused_emb_t[th_mask_target.view(-1).bool()][target_ids, :])\n",
    "    mmd_loss_source2_target = mmd(fused_emb_s2[th_mask_source2.view(-1).bool()][source_ids2, :],\n",
    "                                  fused_emb_t[th_mask_target.view(-1).bool()][target_ids, :])\n",
    "    mmd_loss_source2_source1 = mmd(fused_emb_s2[th_mask_source2.view(-1).bool()][source_ids2, :],\n",
    "                                   fused_emb_s[th_mask_source.view(-1).bool()][source_ids, :])\n",
    "    mmd_losses = mmd_loss + mmd_loss_source2_target + mmd_loss_source2_source1\n",
    "    # 随机抽样边256\n",
    "    source_batch_edges = np.random.randint(0, len(source_edges), size=(256,))\n",
    "    source_batch_edges2 = np.random.randint(0, len(source_edges2), size=(256,))\n",
    "    target_batch_edges = np.random.randint(0, len(target_edges), size=(256,))\n",
    "    source_batch_src = torch.Tensor(source_edges[source_batch_edges, 0]).long()\n",
    "    source_batch_dst = torch.Tensor(source_edges[source_batch_edges, 1]).long()\n",
    "    source_emb_src = fused_emb_s[source_batch_src, :]\n",
    "    source_emb_dst = fused_emb_s[source_batch_dst, :]\n",
    "    source_batch_src2 = torch.Tensor(source_edges2[source_batch_edges2, 0]).long()\n",
    "    source_batch_dst2 = torch.Tensor(source_edges2[source_batch_edges2, 1]).long()\n",
    "    source_emb_src2 = fused_emb_s2[source_batch_src2, :]\n",
    "    source_emb_dst2 = fused_emb_s2[source_batch_dst2, :]\n",
    "    target_batch_src = torch.Tensor(target_edges[target_batch_edges, 0]).long()\n",
    "    target_batch_dst = torch.Tensor(target_edges[target_batch_edges, 1]).long()\n",
    "    target_emb_src = fused_emb_t[target_batch_src, :]\n",
    "    target_emb_dst = fused_emb_t[target_batch_dst, :]\n",
    "    # 源城市目的城市使用同样的边分类器\n",
    "    pred_source = edge_disc.forward(source_emb_src, source_emb_dst)\n",
    "    pred_source2 = edge_disc.forward(source_emb_src2, source_emb_dst2)\n",
    "    pred_target = edge_disc.forward(target_emb_src, target_emb_dst)\n",
    "    source_batch_labels = torch.Tensor(source_edge_labels[source_batch_edges]).to(device)\n",
    "    source_batch_labels2 = torch.Tensor(source_edge_labels2[source_batch_edges2]).to(device)\n",
    "    target_batch_labels = torch.Tensor(target_edge_labels[target_batch_edges]).to(device)\n",
    "    # -（label*log(sigmod(pred)+0.000001)) + (1-label)*log(1-sigmod+0.000001) sum mean\n",
    "    loss_et_source = -((source_batch_labels * torch.log(torch.sigmoid(pred_source) + 1e-6)) + (\n",
    "            1 - source_batch_labels) * torch.log(1 - torch.sigmoid(pred_source) + 1e-6)).sum(1).mean()\n",
    "    loss_et_source2 = -((source_batch_labels2 * torch.log(torch.sigmoid(pred_source2) + 1e-6)) + (\n",
    "            1 - source_batch_labels2) * torch.log(1 - torch.sigmoid(pred_source2) + 1e-6)).sum(1).mean()\n",
    "    loss_et_target = -((target_batch_labels * torch.log(torch.sigmoid(pred_target) + 1e-6)) + (\n",
    "            1 - target_batch_labels) * torch.log(1 - torch.sigmoid(pred_target) + 1e-6)).sum(1).mean()\n",
    "    loss_et = loss_et_source + loss_et_target + loss_et_source2\n",
    "\n",
    "    emb_optimizer.zero_grad()\n",
    "    # 公式11\n",
    "    loss = loss_emb + mmd_w * mmd_losses + et_w * loss_et\n",
    "    loss.backward()\n",
    "    emb_optimizer.step()\n",
    "    return loss_emb.item(), mmd_losses.item(), loss_et.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:52   [42.29s]Pretrain embeddings for 80 epochs, average emb loss 6483.8566, mmd loss 4.7224, edge loss 9.7312\n",
      "2022-10-20 11:31:53   [43.13s]Pretraining embedding, source cvscore 0.6441, source2 cvscore 0.4963, target cvscore 0.6187\n",
      "2022-10-20 11:31:53                                            \n",
      "100%|██████████| 5/5 [00:43<00:00,  4.24s/part, 初始化准备完成]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_losses = []\n",
    "mmd_losses = []\n",
    "edge_losses = []\n",
    "pretrain_emb_epoch = 80\n",
    "# 预训练图数据嵌入，边类型分类，节点对齐 ——> 获得区域特征\n",
    "for emb_ep in range(pretrain_emb_epoch):\n",
    "    loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch()\n",
    "    emb_losses.append(loss_emb_)\n",
    "    mmd_losses.append(loss_mmd_)\n",
    "    edge_losses.append(loss_et_)\n",
    "log(\"[%.2fs]Pretrain embeddings for %d epochs, average emb loss %.4f, mmd loss %.4f, edge loss %.4f\" % (\n",
    "    time.time() - start_time, pretrain_emb_epoch, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses)))\n",
    "with torch.no_grad():\n",
    "    views = mvgat(source_graphs, torch.Tensor(source_norm_poi).to(device))\n",
    "    # 融合模块指的是把多图的特征融合\n",
    "    fused_emb_s, _ = fusion(views)\n",
    "    views = mvgat(source_graphs2, torch.Tensor(source_norm_poi2).to(device))\n",
    "    fused_emb_s2, _ = fusion(views)\n",
    "    views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "    fused_emb_t, _ = fusion(views)\n",
    "# mask_source.reshape(-1) 返回的是一系列bool值，整行的含义是去除false对应的值\n",
    "# reshape(-1)的含义是，不指定变换之后有多少行，将原来的tensor变成一列（default）\n",
    "emb_s = fused_emb_s.cpu().numpy()[mask_source.reshape(-1)]\n",
    "emb_s2 = fused_emb_s2.cpu().numpy()[mask_source2.reshape(-1)]\n",
    "emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "\"\"\"\n",
    "交叉验证，有时亦称循环估计[1] [2] [3]， 是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析，而其它子集则用来做后续对此分析的确认及验证。一开始的子集被称为训练集。而其它的子集则被称为验证集或测试集。\n",
    "交叉验证的目的，是用未用来给模型作训练的新数据，测试模型的性能，以便减少诸如过拟合和选择偏差等问题，并给出模型如何在一个独立的数据集上通用化（即，一个未知的数据集，如实际问题中的数据）。\n",
    "交叉验证的理论是由Seymour Geisser所开始的。它对于防范根据数据建议的测试假设是非常重要的，特别是当后续的样本是危险、成本过高或科学上不适合时去搜集。\n",
    "\"\"\"\n",
    "cvscore_s = cross_validate(logreg, emb_s, source_emb_label)['test_score'].mean()\n",
    "cvscore_s2 = cross_validate(logreg, emb_s2, source_emb_label2)['test_score'].mean()\n",
    "cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "log(\"[%.2fs]Pretraining embedding, source cvscore %.4f, source2 cvscore %.4f, target cvscore %.4f\" % \\\n",
    "    (time.time() - start_time, cvscore_s, cvscore_s2, cvscore_t))\n",
    "log()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:53   torch.Size([460])                        \n",
      "2022-10-20 11:31:53   torch.Size([476])                        \n",
      "2022-10-20 11:31:53   torch.Size([476])                        \n",
      "100%|██████████| 5/5 [00:43<00:00,  4.24s/part, 初始化准备完成]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def score_of_two_city(s, t, smask, tmask):\n",
    "    \"\"\"\n",
    "    计算两个城市的分数，region of s vs whole t\n",
    "    :param tmask: 目标城市区域特征的的有效值向量\n",
    "    :param smask: 源城市区域特征的的有效值向量\n",
    "    :param s: 源城市区域特征\n",
    "    :param t: 目标城市区域特征\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tt = t[tmask.view(-1).bool()].sum(0).reshape(1, 64)\n",
    "    res = torch.cosine_similarity(s, tt)\n",
    "    return res\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        source_weights_s1_t = score_of_two_city(fused_emb_s, fused_emb_t, th_mask_source, th_mask_target)\n",
    "        source_weights_s2_t = score_of_two_city(fused_emb_s2, fused_emb_t, th_mask_source2, th_mask_target)\n",
    "        source_weights_s2_s1 = score_of_two_city(fused_emb_s2, fused_emb_s, th_mask_source2, th_mask_source)\n",
    "log(source_weights_s1_t.shape)\n",
    "log(source_weights_s2_t.shape)\n",
    "log(source_weights_s2_s1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:53   tensor([0.9603, 0.9603, 0.9605, 0.9637, 0.9637, 0.9640, 0.9641, 0.9643, 0.9662,\n",
      "        0.9667, 0.9668, 0.9668, 0.9669, 0.9701, 0.9701], device='cuda:0')\n",
      "2022-10-20 11:31:53   tensor([121, 368, 127, 424,  48,  64, 190, 249, 151, 239,  86, 263, 159, 273,\n",
      "        216], device='cuda:0')\n",
      "100%|██████████| 5/5 [00:43<00:00,  4.24s/part, 初始化准备完成]E:\\git-code\\CrossTReS\\src\\utils.py:301: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  idx0d = int(idx // shape[1])\n",
      "2022-10-20 11:31:53   [(4, 9), (13, 4), (4, 15), (15, 4), (1, 20), (2, 8), (6, 22), (8, 25), (5, 11), (8, 15), (3, 2), (9, 11), (5, 19), (9, 21), (7, 20)]\n",
      "2022-10-20 11:31:53   [340, 186, 222, 150, 58, 278, 425, 179, 188, 114, 215, 99, 152, 235, 262, 161, 36, 300, 217, 92, 154, 264, 163, 367, 302, 47, 210, 219, 85, 94, 156, 130, 266, 369, 49, 76, 212, 395, 87, 149, 123, 158, 132, 268, 451, 244, 397, 98, 290, 35, 453, 246, 91, 100, 292, 37, 248, 301, 20, 339, 93, 120, 221, 57, 250, 277, 75, 178, 341, 187, 113, 122, 131, 234, 59, 160, 243, 77, 180, 396, 189, 115, 124, 236, 162, 452, 245, 272, 191, 218, 126, 155, 238, 291, 63, 274, 19, 211, 220, 128, 148, 240, 267, 65, 276, 21, 423]\n",
      "100%|██████████| 5/5 [00:43<00:00,  4.24s/part, 初始化准备完成]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1.考虑去掉数据中除了八邻域的数据，其他地方全部设置为0，得到s2‘，组成一个图A'\n",
    "2.考虑不要邻域了，直接reshape，合并\n",
    "3.考虑直接在S1图的周围附加数据，（这样可能会影响S1）\n",
    "\"\"\"\n",
    "# res_score = torch.div(source_weights_s2_t, source_weights_s2_s1)\n",
    "res_score = source_weights_s2_t\n",
    "idx = source_weights_s2_t.argsort()\n",
    "idx = idx[mask_source2.reshape(-1)]\n",
    "log(res_score[idx[-args.topk:]])\n",
    "log(idx[-args.topk:])\n",
    "area_tuple = []\n",
    "include_8_nearist = []\n",
    "for i in idx[-args.topk:]:\n",
    "    area_tuple.append((idx_1d22d(i, (lng_source2, lat_source2))))\n",
    "log(area_tuple)\n",
    "def yield_8_near(i, ranges):\n",
    "    \"\"\"\n",
    "    产生i的8邻域，i，ranges都是元组或者可下标访问的元素，\n",
    "    :param i:\n",
    "    :param ranges:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for k in [-1, 0, 1]:\n",
    "        for p in [-1, 0, 1]:\n",
    "            if k == 0 and p == 0:\n",
    "                continue\n",
    "            elif 0<= i[0] + k < ranges[0] and 0 <= i[1] + p < ranges[1]:\n",
    "                yield i[0] + k, i[1] + p\n",
    "for i in area_tuple:\n",
    "    include_8_nearist.extend(list(yield_8_near(i, (lng_source2, lat_source2))))\n",
    "include_8_nearist = list(set(include_8_nearist))\n",
    "include_8_nearist_1d = []\n",
    "for i in include_8_nearist:\n",
    "    include_8_nearist_1d.append(idx_2d_2_1d(i, (lng_source2, lat_source2)))\n",
    "log(include_8_nearist_1d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:53   (8784, 20, 23)                           \n",
      "2022-10-20 11:31:53   (8784, 17, 28)                           \n",
      "2022-10-20 11:31:53   (8784, 20, 23)                           \n",
      "2022-10-20 11:31:53   (8784, 17, 28)                           \n",
      "2022-10-20 11:31:54   torch.Size([8784, 20, 51])               \n",
      "2022-10-20 11:31:54   torch.Size([8784, 17, 51])               \n",
      "2022-10-20 11:31:54   (8784, 37, 51)                           \n",
      "2022-10-20 11:31:54   check:                                   \n",
      "2022-10-20 11:31:54   success check 100                        \n",
      "2022-10-20 11:31:54   (8784, 37, 51)                           \n",
      "2022-10-20 11:31:54                                            \n",
      "100%|██████████| 5/5 [00:44<00:00,  4.24s/part, 初始化准备完成]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "构建A‘, 通过对角添加方式[[S1][0][0][S2]]\n",
    "\"\"\"\n",
    "def merge_multi_source_into_diagonal_matrix(s1, s2, s1_shape, s2_shape, date_num, check_num=1):\n",
    "    \"\"\"\n",
    "    合并2个源城市数据到一个对角矩阵\n",
    "    :param s2_shape: 排除时间维度的形状，例如（20，23）\n",
    "    :param s1_shape:\n",
    "    :param date_num: 两个城市时间维上的数量，比如source_data和source_data2合并时，这个值就是8764\n",
    "    :param check_num:\n",
    "    :param s1:\n",
    "    :param s2:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    log(s1.shape)\n",
    "    log(s2.shape)\n",
    "    check_num = check_num if check_num < date_num else date_num\n",
    "    # s1 右边扩充s2的宽度，s2左边扩充s1宽度，然后对角线填充\n",
    "    zero_padding_s1_right = torch.nn.ZeroPad2d((0, abs(s2_shape[1]), 0, 0))\n",
    "    zero_padding_s2_left = torch.nn.ZeroPad2d((abs(s1_shape[1]), 0, 0, 0))\n",
    "    s1_zero_pad_list = []\n",
    "    s2_zero_pad_list = []\n",
    "    for i in range(date_num):\n",
    "        s1_zero_pad_list.append(zero_padding_s1_right(torch.from_numpy(s1[i])))\n",
    "        s2_zero_pad_list.append(zero_padding_s2_left(torch.from_numpy(s2[i])))\n",
    "    s1_zero_pad = torch.stack(s1_zero_pad_list)\n",
    "    s2_zero_pad = torch.stack(s2_zero_pad_list)\n",
    "    log(s1_zero_pad.shape)\n",
    "    log(s2_zero_pad.shape)\n",
    "    s1_zero_pad = s1_zero_pad.numpy()\n",
    "    s2_zero_pad = s2_zero_pad.numpy()\n",
    "    temp = np.concatenate((s1_zero_pad, s2_zero_pad), axis=1)\n",
    "    log(temp.shape)\n",
    "    log(\"check:\")\n",
    "    for i in range(check_num):\n",
    "        # log(\"left and up sum:{}\".format(str(temp[0, 0: s1.shape[1]-1, 0: s1.shape[2]-1].sum())))\n",
    "        # log(\"right and up sum:{}\".format(str(temp[0, 0: s1.shape[1], s1.shape[2]:].sum())))\n",
    "        # log(\"left and down sum:{}\".format(str(temp[0, s1.shape[1]:, 0: s1.shape[2]-1].sum())))\n",
    "        # log(\"left and up sum:{}\".format(str(temp[0, s1.shape[1]:, s1.shape[2]:].sum())))\n",
    "        if temp[0, 0: s1_shape[0], s1_shape[1]:].sum() == 0 and temp[0, s1_shape[0]:, 0: s1_shape[1]-1].sum() == 0:\n",
    "            pass\n",
    "        else:\n",
    "            log(\"failure:{}\".format(str(i)))\n",
    "            return None\n",
    "    log(\"success check {}\".format(str(check_num)))\n",
    "    return temp\n",
    "log(source_data.shape)\n",
    "log(source_data2.shape)\n",
    "A_star = merge_multi_source_into_diagonal_matrix(source_data, source_data2, s1_shape=(source_data.shape[1], source_data.shape[2]), s2_shape=(source_data2.shape[1], source_data2.shape[2]),date_num=source_data.shape[0], check_num=100)\n",
    "log(A_star.shape)\n",
    "log()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A_star' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [2], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m构造A'的mask和th——mask\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m A_star_mask \u001B[38;5;241m=\u001B[39m A_star\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m一下代码判断如下逻辑，\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03m已知区域列表L中的区域（属于S2-CHI）均满足与S1不相似但是与T（NY）相似，\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;124;03m然后又已知其8邻域列表L'\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m判断L'中与CHI城市时空数据求和大于0的区域列表(L-sum>0)的交集\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     11\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'A_star' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "构造A'的mask和th——mask\n",
    "\"\"\"\n",
    "A_star_mask = A_star.sum(0) > 0\n",
    "\"\"\"\n",
    "一下代码判断如下逻辑，\n",
    "已知区域列表L中的区域（属于S2-CHI）均满足与S1不相似但是与T（NY）相似，\n",
    "然后又已知其8邻域列表L'\n",
    "判断L'中与CHI城市时空数据求和大于0的区域列表(L-sum>0)的交集\n",
    "\"\"\"\n",
    "count = 0\n",
    "for i in include_8_nearist_1d:\n",
    "    if A_star_mask[20:, 23:].reshape(-1)[i]:\n",
    "        count += 1\n",
    "log(count)\n",
    "\"\"\"\n",
    "找出S2 mask，对于非8邻域数据置为False\n",
    "\"\"\"\n",
    "ks = []\n",
    "for i in range(source_data.shape[1], A_star_mask.shape[0]):\n",
    "    for j in range(source_data.shape[2], A_star_mask.shape[1]):\n",
    "        k = idx_2d_2_1d(((i - source_data.shape[1]), (j - source_data.shape[2])), (17, 28))\n",
    "        if k not in include_8_nearist_1d:\n",
    "            A_star_mask[i][j] = False\n",
    "log(A_star_mask[20:, 23:].shape)\n",
    "log(A_star_mask[20:, 23:].sum())\n",
    "\n",
    "log()\n",
    "log()\n",
    "np.save(local_path_generate(\"..\\\\data\\\\mutlti\", \"Astar\", suffix=\"npz\"), A_star)\n",
    "np.save(local_path_generate(\"..\\\\data\\\\mutlti\", \"Astar_mask\", suffix=\"npz\"), A_star_mask)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:55   536 valid regions in multi               \n",
      "2022-10-20 11:31:58   ((8784, 37, 51), 0.8679867986798679, 0)  \n",
      "2022-10-20 11:31:59   multi split to: x (8778, 6, 37, 51), y (8778, 1, 37, 51)\n",
      "100%|██████████| 5/5 [00:49<00:00,  4.24s/part, 初始化准备完成]"
     ]
    }
   ],
   "source": [
    "A_star_lng, A_star_lat = A_star.shape[1], A_star.shape[2]\n",
    "A_th_mask =  torch.Tensor(A_star_mask.reshape(1, A_star_lng, A_star_lat)).to(device)\n",
    "log(\"%d valid regions in multi\" % np.sum(A_star_mask))\n",
    "# 按照百分比分配标签\n",
    "A_star_emb_label = masked_percentile_label(A_star.sum(0).reshape(-1), A_star_mask.reshape(-1))\n",
    "A_star, amax, amin = min_max_normalize(A_star)\n",
    "log((A_star.shape, amax, amin))\n",
    "A_star_train_x, A_star_train_y, A_star_val_x, A_star_val_y, A_star_test_x, A_star_test_y = split_x_y(A_star, lag)\n",
    "A_star_x = np.concatenate([A_star_train_x, A_star_val_x, A_star_test_x], axis=0)\n",
    "A_star_y = np.concatenate([A_star_train_y, A_star_val_y, A_star_test_y], axis=0)\n",
    "log(\"multi split to: x %s, y %s\" % (str(A_star_x.shape), str(A_star_y.shape)))\n",
    "A_star_test_dataset = TensorDataset(torch.Tensor(A_star_test_x), torch.Tensor(A_star_test_y))\n",
    "A_star_test_loader = DataLoader(A_star_test_dataset, batch_size=args.batch_size)\n",
    "A_star_dataset = TensorDataset(torch.Tensor(A_star_x), torch.Tensor(A_star_y))\n",
    "A_star_loader = DataLoader(A_star_dataset, batch_size=args.batch_size, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:31:59   (20, 23, 14)                             \n",
      "2022-10-20 11:31:59   (17, 28, 14)                             \n",
      "2022-10-20 11:31:59   torch.Size([20, 51, 14])                 \n",
      "2022-10-20 11:31:59   torch.Size([17, 51, 14])                 \n",
      "2022-10-20 11:31:59   6440                                     \n",
      "2022-10-20 11:31:59   6664                                     \n",
      "2022-10-20 11:31:59   (37, 51, 14)                             \n",
      "2022-10-20 11:31:59   check:                                   \n",
      "2022-10-20 11:31:59   success check 14                         \n",
      "100%|██████████| 5/5 [00:50<00:00,  4.24s/part, 初始化准备完成]"
     ]
    }
   ],
   "source": [
    "a = source_poi.reshape((lng_source, lat_source, 14))\n",
    "b = source_poi2.reshape((lng_source2, lat_source2, 14))\n",
    "log(a.shape)\n",
    "log(b.shape)\n",
    "zero_padding_s1_right = torch.nn.ZeroPad2d((0, abs(b.shape[1]), 0, 0))\n",
    "zero_padding_s2_left = torch.nn.ZeroPad2d((abs(a.shape[1]), 0, 0, 0))\n",
    "s1_zero_pad_list = []\n",
    "s2_zero_pad_list = []\n",
    "for i in range(a.shape[2]):\n",
    "    s1_zero_pad_list.append(zero_padding_s1_right(torch.from_numpy(a[:, :, i])))\n",
    "    s2_zero_pad_list.append(zero_padding_s2_left(torch.from_numpy(b[:, :, i])))\n",
    "s1_zero_pad = torch.stack(s1_zero_pad_list, dim=2)\n",
    "s2_zero_pad = torch.stack(s2_zero_pad_list, dim=2)\n",
    "log(s1_zero_pad.shape)\n",
    "log(s2_zero_pad.shape)\n",
    "log((s1_zero_pad[:, 0: a.shape[1]].numpy() == a).sum())\n",
    "log((s2_zero_pad[:, a.shape[1]:].numpy() == b).sum())\n",
    "\n",
    "s1_zero_pad = s1_zero_pad.numpy()\n",
    "s2_zero_pad = s2_zero_pad.numpy()\n",
    "A_star_poi = np.concatenate((s1_zero_pad, s2_zero_pad), axis=0)\n",
    "log(A_star_poi.shape)\n",
    "log(\"check:\")\n",
    "for i in range(14):\n",
    "    # log(\"left and up sum:{}\".format(str(temp[0, 0: s1.shape[1]-1, 0: s1.shape[2]-1].sum())))\n",
    "    # log(\"right and up sum:{}\".format(str(temp[0, 0: s1.shape[1], s1.shape[2]:].sum())))\n",
    "    # log(\"left and down sum:{}\".format(str(temp[0, s1.shape[1]:, 0: s1.shape[2]-1].sum())))\n",
    "    # log(\"left and up sum:{}\".format(str(temp[0, s1.shape[1]:, s1.shape[2]:].sum())))\n",
    "    if A_star_poi[a.shape[0]:, 0:a.shape[1], i].sum() == 0 and A_star_poi[0: a.shape[0],a.shape[1]:, i].sum() == 0:\n",
    "        pass\n",
    "    else:\n",
    "        log(\"failure:{}\".format(str(i)))\n",
    "log(\"success check {}\".format(str(14)))\n",
    "transform = TfidfTransformer()\n",
    "A_star_poi = A_star_poi.reshape(((a.shape[0] + b.shape[0]) * (a.shape[1] + b.shape[1]), 14))\n",
    "# 规范正则化到（0，1）\n",
    "A_star_norm_poi = np.array(transform.fit_transform(A_star_poi).todense())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:32:00   (1887, 1887)                             \n",
      "2022-10-20 11:32:00   success                                  \n",
      "2022-10-20 11:32:00   (1887, 1887)                             \n",
      "2022-10-20 11:32:00   success                                  \n",
      "2022-10-20 11:32:00   (1887, 1887)                             \n",
      "2022-10-20 11:32:00   success                                  \n",
      "2022-10-20 11:32:00   (1887, 1887)                             \n",
      "2022-10-20 11:32:00   success                                  \n",
      "2022-10-20 11:32:00   A_star graphs:                           \n",
      "2022-10-20 11:32:00   prox_adj: 1887 nodes, 16459 edges        \n",
      "2022-10-20 11:32:00   road adj: 1887 nodes, 6591 edges         \n",
      "2022-10-20 11:32:00   poi_adj, 1887 nodes, 7423 edges          \n",
      "2022-10-20 11:32:00   s_adj, 1887 nodes, 6767 edges            \n",
      "2022-10-20 11:32:00   d_adj, 1887 nodes, 6935 edges            \n",
      "2022-10-20 11:32:00                                            \n",
      "100%|██████████| 5/5 [00:50<00:00,  4.24s/part, 初始化准备完成]"
     ]
    }
   ],
   "source": [
    "def merge_static_feature(s1, s2):\n",
    "    zero_padding_s1_right = torch.nn.ZeroPad2d((0, ((A_star_lng * A_star_lat) - (lat_source * lng_source)), 0, 0))\n",
    "    zero_padding_s1_right_down = torch.nn.ZeroPad2d((0, 0, 0, ((A_star_lng * A_star_lat) - (lat_source * lng_source) - (lat_source2 * lng_source2))))\n",
    "    zero_padding_s2_left = torch.nn.ZeroPad2d(((A_star_lng * A_star_lat) - (lat_source2 * lng_source2), 0, 0, 0))\n",
    "    a = zero_padding_s1_right(torch.from_numpy(s1))\n",
    "    a = zero_padding_s1_right_down(a)\n",
    "    b = zero_padding_s2_left(torch.from_numpy(s2))\n",
    "    temp = np.concatenate((a.numpy(), b.numpy()))\n",
    "    log(temp.shape)\n",
    "    if temp[0:(lat_source * lng_source), (lat_source * lng_source):].sum() == 0 and temp[(A_star_lng * A_star_lat) - (lat_source2 * lng_source2): , 0: (A_star_lng * A_star_lat) - (lat_source2 * lng_source2)].sum() == 0 and temp[(lat_source * lng_source) :  (A_star_lng * A_star_lat) - (lat_source2 * lng_source2), :].sum() == 0:\n",
    "        log(\"success\")\n",
    "    else:\n",
    "        log(\"failure\")\n",
    "    return temp\n",
    "A_star_prox_adj = add_self_loop(build_prox_graph(A_star_lng, A_star_lat))\n",
    "A_star_road_adj = merge_static_feature(source_road_adj, source_s_adj2)\n",
    "A_star_road_adj = add_self_loop(A_star_road_adj)\n",
    "A_star_poi_adj, A_star_poi_cos = build_poi_graph(A_star_norm_poi, args.topk)\n",
    "A_star_poi_adj = add_self_loop(A_star_poi_adj)\n",
    "# @todo 这里暂时也是合并成对角矩阵，之后可以试试先合成矩阵，再经过函数计算\n",
    "A_star_s_adj = merge_static_feature(source_s_adj, source_s_adj2)\n",
    "A_star_d_adj = merge_static_feature(source_d_adj, source_d_adj2)\n",
    "A_star_od_adj = merge_static_feature(source_od_adj, source_od_adj2)\n",
    "A_star_s_adj = add_self_loop(A_star_s_adj)\n",
    "A_star_d_adj = add_self_loop(A_star_d_adj)\n",
    "A_star_od_adj = add_self_loop(A_star_od_adj)\n",
    "\n",
    "log(\"A_star graphs: \")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (A_star_prox_adj.shape[0], np.sum(A_star_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (A_star_road_adj.shape[0], np.sum(A_star_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (A_star_poi_adj.shape[0], np.sum(A_star_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (A_star_s_adj.shape[0], np.sum(A_star_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (A_star_d_adj.shape[0], np.sum(A_star_d_adj > 0)))\n",
    "log()\n",
    "\n",
    "A_star_graphs = adjs_to_graphs([A_star_prox_adj, A_star_road_adj, A_star_poi_adj, A_star_s_adj, A_star_d_adj])\n",
    "target_graphs = adjs_to_graphs([target_prox_adj, target_road_adj, target_poi_adj, target_s_adj, target_d_adj])\n",
    "for i in range(len(source_graphs)):\n",
    "    A_star_graphs[i] = A_star_graphs[i].to(device)\n",
    "    target_graphs[i] = target_graphs[i].to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:32:04   STNet_nobn(                              \n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (layers): ModuleList(\n",
      "    (0): ResUnit_nobn(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResUnit_nobn(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResUnit_nobn(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (lstm): LSTM(64, 128)\n",
      "  (linear1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "100%|██████████| 5/5 [00:54<00:00,  4.24s/part, 初始化准备完成]"
     ]
    }
   ],
   "source": [
    "A_star_edges, A_star_edge_labels = graphs_to_edge_labels(A_star_graphs)\n",
    "num_gat_layers = 2\n",
    "in_dim = 14\n",
    "hidden_dim = 64\n",
    "emb_dim = 64\n",
    "num_heads = 2\n",
    "mmd_w = args.mmd_w\n",
    "et_w = args.et_w\n",
    "ma_param = args.ma_coef\n",
    "\n",
    "mvgat = MVGAT(len(A_star_graphs), num_gat_layers, in_dim, hidden_dim, emb_dim, num_heads, True).to(device)\n",
    "fusion = FusionModule(len(A_star_graphs), emb_dim, 0.8).to(device)\n",
    "scoring = Scoring(emb_dim, A_th_mask, th_mask_target).to(device)\n",
    "edge_disc = EdgeTypeDiscriminator(len(A_star_graphs), emb_dim).to(device)\n",
    "mmd = MMD_loss()\n",
    "# we still need a scoring model.\n",
    "# [NS, 64], [NT, 64] -> [NS]\n",
    "\n",
    "# build model\n",
    "if args.model == 'STResNet':\n",
    "    net = STResNet(len(lag), 1, 3).to(device)\n",
    "elif args.model == 'STNet_nobn':\n",
    "    net = STNet_nobn(1, 3, th_mask_target, sigmoid_out=True).to(device)\n",
    "    log(net)\n",
    "elif args.model == 'STNet':\n",
    "    net = STNet(1, 3, th_mask_target).to(device)\n",
    "    log(net)\n",
    "pred_optimizer = optim.Adam(net.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 图卷积，融合，边类型分类器参数单独训练\n",
    "emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 元学习部分\n",
    "meta_optimizer = optim.Adam(scoring.parameters(), lr=args.outerlr, weight_decay=args.weight_decay)\n",
    "best_val_rmse = 999\n",
    "best_test_rmse = 999\n",
    "best_test_mae = 999\n",
    "p_bar.process(5, 1, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:38:53   [463.78s]Pretrain embeddings for 80 epochs, average emb loss 791.2484, mmd loss 0.5206, edge loss 6.2487\n",
      "  0%|          | 0/160 [02:51<?, ?epoch/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "需要对meta_train_epoch修改一下，符合多城市要求\n",
    "\"\"\"\n",
    "def meta_train_epoch(s_embs, t_embs, th_mask_source, th_mask_target):\n",
    "    \"\"\"\n",
    "    0. 计算source_weights，通过scoring网络\n",
    "    1. 获取net 也就是预测网络的参数，分为两部分，一部分是命名参数，另一部分是非命名 fast_weights, bn_vars\n",
    "    2. 从源城市抽样，计算预测值，使用net网络，从输出格式判断使用的具体网络，计算损失\n",
    "    3. 通过torch.autograd.grad 计算loss对于fast_weights的梯度，并且更新fast_weights，注意2,3都是在更新net网络\n",
    "    4. 同理抽样目的城市，计算梯度，更新fast_weights\n",
    "    5. meta_loss = q_loss + weights_mean * args.weight_reg，计算meta loss\n",
    "    6. 根据meta loss 更新scoring meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "    7. 循环以上，则总体更新了scoring网络，net预测网络\n",
    "    :param s_embs:\n",
    "    :param t_embs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_query_losses = []\n",
    "    for meta_ep in range(args.outeriter):\n",
    "        fast_losses = []\n",
    "        fast_weights, bn_vars = get_weights_bn_vars(net)\n",
    "        source_weights = scoring(s_embs, t_embs)\n",
    "        # inner loop on source, pre-train with weights\n",
    "        for meta_it in range(args.sinneriter):\n",
    "            s_x, s_y = batch_sampler((torch.Tensor(A_star_x), torch.Tensor(A_star_y)), args.batch_size)\n",
    "            s_x = s_x.to(device)\n",
    "            s_y = s_y.to(device)\n",
    "            pred_source = net.functional_forward(s_x, th_mask_source.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_source.shape) == 4:  # STResNet\n",
    "                loss_source = ((pred_source - s_y) ** 2).view(args.batch_size, 1, -1)[:, :,\n",
    "                              th_mask_source.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_source = (loss_source * source_weights).mean(0).sum()\n",
    "            elif len(pred_source.shape) == 3:  # STNet\n",
    "                s_y = s_y.view(args.batch_size, 1, -1)[:, :, th_mask_source.view(-1).bool()]\n",
    "                loss_source = (((pred_source - s_y) ** 2) * source_weights.view(1, 1, -1))\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_source = loss_source.mean(0).sum()\n",
    "            # size = 1 基本可以认为是标量\n",
    "            fast_loss = loss_source\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            # 计算输出对于输入独立的梯度，\n",
    "            # fast_weights.values()。size = 22\n",
    "            # grad。size=22\n",
    "            # 此处对于fast_weights 进行梯度下降学习\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        # inner loop on target, simulate fine-tune\n",
    "        # 模拟微调和源训练都是在训练net预测网络，并没有提及权重和特征\n",
    "        for meta_it in range(args.tinneriter):\n",
    "            t_x, t_y = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            t_x = t_x.to(device)\n",
    "            t_y = t_y.to(device)\n",
    "            pred_t = net.functional_forward(t_x, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_t.shape) == 4:  # STResNet\n",
    "                loss_t = ((pred_t - t_y) ** 2).view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            elif len(pred_t.shape) == 3:  # STNet\n",
    "                t_y = t_y.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(t_y.shape)\n",
    "                loss_t = ((pred_t - t_y) ** 2)  # .view(1, 1, -1))\n",
    "                # log(loss_t.shape)\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            fast_loss = loss_t\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        q_losses = []\n",
    "        target_iter = max(args.sinneriter, args.tinneriter)\n",
    "        for k in range(3):\n",
    "            # query loss\n",
    "            x_q, y_q = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            x_q = x_q.to(device)\n",
    "            y_q = y_q.to(device)\n",
    "            pred_q = net.functional_forward(x_q, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_q.shape) == 4:  # STResNet\n",
    "                loss = (((pred_q - y_q) ** 2) * (th_mask_target.view(1, 1, lng_target, lat_target)))\n",
    "                loss = loss.mean(0).sum()\n",
    "            elif len(pred_q.shape) == 3:  # STNet\n",
    "                y_q = y_q.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                loss = ((pred_q - y_q) ** 2).mean(0).sum()\n",
    "            q_losses.append(loss)\n",
    "        q_loss = torch.stack(q_losses).mean()\n",
    "        # ** 乘方\n",
    "        weights_mean = (source_weights ** 2).mean()\n",
    "        # meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        # 这里对于权重开始了联系\n",
    "        # meta loss 只训练了scoring网络\n",
    "        meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        meta_optimizer.zero_grad()\n",
    "        meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "        torch.nn.utils.clip_grad_norm_(scoring.parameters(), max_norm=2)\n",
    "        meta_optimizer.step()\n",
    "        meta_query_losses.append(q_loss.item())\n",
    "    return np.mean(meta_query_losses)\n",
    "\n",
    "def train_emb_epoch(source_graphs, source_norm_poi, source_od_adj, source_poi_cos, target_graphs, target_norm_poi, target_od_adj, target_poi_cos):\n",
    "    \"\"\"\n",
    "    训练图网络-特征网络，融合网络，边类型分类器\n",
    "    1. 通过forward_emb融合特征，计算损失，\n",
    "    2. 抽样边，标签，训练边缘分类器，抽样计算MMD误差\n",
    "    3. 反向传播计算\n",
    "    emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "    emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    训练特征网络 mvgat，fusion，边缘分类器，节点MMD，在训练的同时，对于mvgat和fusion的特征进行指导，特征重新对齐分布\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # loss， 460*64， 5*460*64\n",
    "    loss_source, fused_emb_s, embs_s = forward_emb(source_graphs, source_norm_poi, source_od_adj, source_poi_cos)\n",
    "    loss_target, fused_emb_t, embs_t = forward_emb(target_graphs, target_norm_poi, target_od_adj, target_poi_cos)\n",
    "    loss_emb = loss_source + loss_target\n",
    "    # compute domain adaptation loss\n",
    "    # 随机抽样128个，计算最大平均误差\n",
    "    source_ids = np.random.randint(0, np.sum(A_star_mask), size=(128,))\n",
    "    target_ids = np.random.randint(0, np.sum(mask_target), size=(128,))\n",
    "    mmd_loss = mmd(fused_emb_s[A_th_mask.view(-1).bool()][source_ids, :],\n",
    "                   fused_emb_t[th_mask_target.view(-1).bool()][target_ids, :])\n",
    "    # 随机抽样边256\n",
    "    source_batch_edges = np.random.randint(0, len(source_edges), size=(256,))\n",
    "    target_batch_edges = np.random.randint(0, len(target_edges), size=(256,))\n",
    "    source_batch_src = torch.Tensor(source_edges[source_batch_edges, 0]).long()\n",
    "    source_batch_dst = torch.Tensor(source_edges[source_batch_edges, 1]).long()\n",
    "    source_emb_src = fused_emb_s[source_batch_src, :]\n",
    "    source_emb_dst = fused_emb_s[source_batch_dst, :]\n",
    "    target_batch_src = torch.Tensor(target_edges[target_batch_edges, 0]).long()\n",
    "    target_batch_dst = torch.Tensor(target_edges[target_batch_edges, 1]).long()\n",
    "    target_emb_src = fused_emb_t[target_batch_src, :]\n",
    "    target_emb_dst = fused_emb_t[target_batch_dst, :]\n",
    "    # 源城市目的城市使用同样的边分类器\n",
    "    pred_source = edge_disc.forward(source_emb_src, source_emb_dst)\n",
    "    pred_target = edge_disc.forward(target_emb_src, target_emb_dst)\n",
    "    source_batch_labels = torch.Tensor(source_edge_labels[source_batch_edges]).to(device)\n",
    "    target_batch_labels = torch.Tensor(target_edge_labels[target_batch_edges]).to(device)\n",
    "    # -（label*log(sigmod(pred)+0.000001)) + (1-label)*log(1-sigmod+0.000001) sum mean\n",
    "    loss_et_source = -((source_batch_labels * torch.log(torch.sigmoid(pred_source) + 1e-6)) + (\n",
    "            1 - source_batch_labels) * torch.log(1 - torch.sigmoid(pred_source) + 1e-6)).sum(1).mean()\n",
    "    loss_et_target = -((target_batch_labels * torch.log(torch.sigmoid(pred_target) + 1e-6)) + (\n",
    "            1 - target_batch_labels) * torch.log(1 - torch.sigmoid(pred_target) + 1e-6)).sum(1).mean()\n",
    "    loss_et = loss_et_source + loss_et_target\n",
    "\n",
    "    emb_optimizer.zero_grad()\n",
    "    # 公式11\n",
    "    loss = loss_emb + mmd_w * mmd_loss + et_w * loss_et\n",
    "    loss.backward()\n",
    "    emb_optimizer.step()\n",
    "    return loss_emb.item(), mmd_loss.item(), loss_et.item()\n",
    "emb_losses = []\n",
    "mmd_losses = []\n",
    "edge_losses = []\n",
    "pretrain_emb_epoch = 80\n",
    "# 预训练图数据嵌入，边类型分类，节点对齐 ——> 获得区域特征\n",
    "for emb_ep in range(pretrain_emb_epoch):\n",
    "    loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch(\n",
    "        source_graphs=A_star_graphs, source_norm_poi=A_star_norm_poi, source_od_adj=A_star_od_adj, source_poi_cos=A_star_poi_cos,\n",
    "        target_graphs=target_graphs, target_norm_poi=target_norm_poi, target_od_adj=target_od_adj, target_poi_cos=target_poi_cos\n",
    "    )\n",
    "    emb_losses.append(loss_emb_)\n",
    "    mmd_losses.append(loss_mmd_)\n",
    "    edge_losses.append(loss_et_)\n",
    "log(\"[%.2fs]Pretrain embeddings for %d epochs, average emb loss %.4f, mmd loss %.4f, edge loss %.4f\" % (\n",
    "    time.time() - start_time, pretrain_emb_epoch, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses)))\n",
    "with torch.no_grad():\n",
    "    views = mvgat(A_star_graphs, torch.Tensor(A_star_norm_poi).to(device))\n",
    "    # 融合模块指的是把多图的特征融合\n",
    "    fused_emb_A_star, _ = fusion(views)\n",
    "    views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "    fused_emb_t, _ = fusion(views)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 11:39:08   [478.37s]Pretraining embedding, source cvscore 0.4778, target cvscore 0.6042\n",
      "2022-10-20 11:39:08                       \n",
      "  0%|          | 0/160 [03:05<?, ?epoch/s]"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_s = fused_emb_A_star.cpu().numpy()[A_star_mask.reshape(-1)]\n",
    "emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "\"\"\"\n",
    "交叉验证，有时亦称循环估计[1] [2] [3]， 是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析，而其它子集则用来做后续对此分析的确认及验证。一开始的子集被称为训练集。而其它的子集则被称为验证集或测试集。\n",
    "交叉验证的目的，是用未用来给模型作训练的新数据，测试模型的性能，以便减少诸如过拟合和选择偏差等问题，并给出模型如何在一个独立的数据集上通用化（即，一个未知的数据集，如实际问题中的数据）。\n",
    "交叉验证的理论是由Seymour Geisser所开始的。它对于防范根据数据建议的测试假设是非常重要的，特别是当后续的样本是危险、成本过高或科学上不适合时去搜集。\n",
    "\"\"\"\n",
    "cvscore_s = cross_validate(logreg, emb_s, A_star_emb_label)['test_score'].mean()\n",
    "cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "log(\"[%.2fs]Pretraining embedding, source cvscore %.4f, target cvscore %.4f\" % \\\n",
    "    (time.time() - start_time, cvscore_s, cvscore_t))\n",
    "log()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/160 [03:13<?, ?epoch/s]\n",
      "2022-10-20 11:39:21   [491.49s]Epoch 0, embedding loss 739.0485, mmd loss 0.4580, edge loss 6.0580, source cvscore 0.4778, target cvscore 0.6089, mixcvscore 0.4871\n",
      "  0%|          | 0/160 [00:05<?, ?epoch/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 6.00 GiB total capacity; 4.46 GiB already allocated; 0 bytes free; 4.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [32], line 63\u001B[0m\n\u001B[0;32m     58\u001B[0m         trans_emb_t \u001B[38;5;241m=\u001B[39m scoring\u001B[38;5;241m.\u001B[39mscore(fused_emb_t)\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# np.save(\"%s_trans.npy\" % args.scity, arr = trans_emb_s.cpu().numpy()[mask_source.reshape(-1)])\u001B[39;00m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;66;03m# np.save(\"%s_trans.npy\" % args.tcity, arr = trans_emb_t.cpu().numpy()[mask_target.reshape(-1)])\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# meta train scorings\u001B[39;00m\n\u001B[1;32m---> 63\u001B[0m avg_q_loss \u001B[38;5;241m=\u001B[39m meta_train_epoch(fused_emb_s, fused_emb_t, th_mask_source\u001B[38;5;241m=\u001B[39mA_th_mask, th_mask_target\u001B[38;5;241m=\u001B[39mth_mask_target)\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     65\u001B[0m     source_weights \u001B[38;5;241m=\u001B[39m scoring(fused_emb_s, fused_emb_t)\n",
      "Cell \u001B[1;32mIn [30], line 47\u001B[0m, in \u001B[0;36mmeta_train_epoch\u001B[1;34m(s_embs, t_embs, th_mask_source, th_mask_target)\u001B[0m\n\u001B[0;32m     42\u001B[0m fast_losses\u001B[38;5;241m.\u001B[39mappend(fast_loss\u001B[38;5;241m.\u001B[39mitem())  \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# 计算输出对于输入独立的梯度，\u001B[39;00m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m# fast_weights.values()。size = 22\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# grad。size=22\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# 此处对于fast_weights 进行梯度下降学习\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfast_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfast_weights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, grad \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(fast_weights\u001B[38;5;241m.\u001B[39mkeys(), grads):\n\u001B[0;32m     49\u001B[0m     fast_weights[name] \u001B[38;5;241m=\u001B[39m fast_weights[name] \u001B[38;5;241m-\u001B[39m args\u001B[38;5;241m.\u001B[39minnerlr \u001B[38;5;241m*\u001B[39m grad\n",
      "File \u001B[1;32mD:\\Anaconda\\install\\envs\\CTRS\\lib\\site-packages\\torch\\autograd\\__init__.py:276\u001B[0m, in \u001B[0;36mgrad\u001B[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001B[0m\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(grad_outputs_)\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 6.00 GiB total capacity; 4.46 GiB already allocated; 0 bytes free; 4.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 后期要用这个参数\n",
    "source_weights_ma_list = []\n",
    "source_weight_list = []\n",
    "p_bar = process_bar(final_prompt=\"训练完成\", unit=\"epoch\")\n",
    "p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "writer = SummaryWriter(\"log_{}\".format(get_timestamp(split=\"-\")))\n",
    "for ep in range(num_epochs):\n",
    "    net.train()\n",
    "    mvgat.train()\n",
    "    fusion.train()\n",
    "    scoring.train()\n",
    "\n",
    "    # train embeddings\n",
    "    emb_losses = []\n",
    "    mmd_losses = []\n",
    "    edge_losses = []\n",
    "    for emb_ep in range(5):\n",
    "        loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch(\n",
    "        source_graphs=A_star_graphs, source_norm_poi=A_star_norm_poi, source_od_adj=A_star_od_adj, source_poi_cos=A_star_poi_cos,\n",
    "        target_graphs=target_graphs, target_norm_poi=target_norm_poi, target_od_adj=target_od_adj, target_poi_cos=target_poi_cos\n",
    "    )\n",
    "        emb_losses.append(loss_emb_)\n",
    "        mmd_losses.append(loss_mmd_)\n",
    "        edge_losses.append(loss_et_)\n",
    "    # evaluate embeddings\n",
    "    with torch.no_grad():\n",
    "        # mvgat 是把邻接矩阵转换成tensor，大小是城市的长宽之积 * 64（demb）也就是定义的区域特征向量的维度\n",
    "        views = mvgat(A_star_graphs, torch.Tensor(A_star_norm_poi).to(device))\n",
    "        fused_emb_s, _ = fusion(views)\n",
    "        views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "        fused_emb_t, _ = fusion(views)\n",
    "    if ep % 2 == 0:\n",
    "        \"\"\"\n",
    "        每两个epoch显示一些数据\n",
    "        \"\"\"\n",
    "        emb_s = fused_emb_s.cpu().numpy()[A_star_mask.reshape(-1)]\n",
    "        emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "        mix_embs = np.concatenate([emb_s, emb_t], axis=0)\n",
    "        mix_labels = np.concatenate([A_star_emb_label, target_emb_label])\n",
    "        logreg = LogisticRegression(max_iter=500)\n",
    "        cvscore_s = cross_validate(logreg, emb_s, A_star_emb_label)['test_score'].mean()\n",
    "        cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "        cvscore_mix = cross_validate(logreg, mix_embs, mix_labels)['test_score'].mean()\n",
    "        log(\n",
    "            \"[%.2fs]Epoch %d, embedding loss %.4f, mmd loss %.4f, edge loss %.4f, source cvscore %.4f, target cvscore %.4f, mixcvscore %.4f\" % \\\n",
    "            (time.time() - start_time, ep, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses), cvscore_s,\n",
    "             cvscore_t, cvscore_mix))\n",
    "    if ep == num_epochs - 1:\n",
    "        \"\"\"\n",
    "        最后一个epoch，\n",
    "        \"\"\"\n",
    "        emb_s = fused_emb_s.cpu().numpy()[mask_source.reshape(-1)]\n",
    "        emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "        # np.save(\"%s.npy\" % args.scity, arr = emb_s)\n",
    "        # np.save(\"%s.npy\" % args.tcity, arr = emb_t)\n",
    "        with torch.no_grad():\n",
    "            trans_emb_s = scoring.score(fused_emb_s)\n",
    "            trans_emb_t = scoring.score(fused_emb_t)\n",
    "        # np.save(\"%s_trans.npy\" % args.scity, arr = trans_emb_s.cpu().numpy()[mask_source.reshape(-1)])\n",
    "        # np.save(\"%s_trans.npy\" % args.tcity, arr = trans_emb_t.cpu().numpy()[mask_target.reshape(-1)])\n",
    "\n",
    "    # meta train scorings\n",
    "    avg_q_loss = meta_train_epoch(fused_emb_s, fused_emb_t, th_mask_source=A_th_mask, th_mask_target=th_mask_target)\n",
    "    with torch.no_grad():\n",
    "        source_weights = scoring(fused_emb_s, fused_emb_t)\n",
    "        source_weight_list.append(list(source_weights.cpu().numpy()))\n",
    "\n",
    "    # For debug: use fixed weightings.\n",
    "    # with torch.no_grad():\n",
    "    #     source_weights_ = scoring(fused_emb_s, fused_emb_t)\n",
    "    # avg_q_loss = 0\n",
    "    # source_weights = torch.ones_like(source_weights_)\n",
    "\n",
    "    # implement a moving average\n",
    "    if ep == 0:\n",
    "        source_weights_ma = torch.ones_like(source_weights, device=device, requires_grad=False)\n",
    "    source_weights_ma = ma_param * source_weights_ma + (1 - ma_param) * source_weights\n",
    "    source_weights_ma_list.append(list(source_weights_ma.cpu().numpy()))\n",
    "    # train network on source\n",
    "    # 有了参数lambda rs，训练net网络\n",
    "    source_loss = train_epoch(net, A_star_loader, pred_optimizer, weights=source_weights_ma, mask=A_th_mask,\n",
    "                              num_iters=args.pretrain_iter)\n",
    "    avg_source_loss = np.mean(source_loss)\n",
    "    avg_target_loss = evaluate(net, target_train_loader, spatial_mask=th_mask_target)[0]\n",
    "    log(\n",
    "        \"[%.2fs]Epoch %d, average meta query loss %.4f, source weight mean %.4f, var %.6f, source loss %.4f, target_loss %.4f\" % \\\n",
    "        (time.time() - start_time, ep, avg_q_loss, source_weights_ma.mean().item(), torch.var(source_weights_ma).item(),\n",
    "         avg_source_loss, avg_target_loss))\n",
    "    writer.add_scalar(\"average meta query loss\", avg_q_loss, ep)\n",
    "    writer.add_scalar(\"source weight mean\", source_weights_ma.mean().item(), ep)\n",
    "    writer.add_scalar(\"var\", torch.var(source_weights_ma).item(), ep)\n",
    "    writer.add_scalar(\"avg_source_loss\", avg_source_loss, ep)\n",
    "    writer.add_scalar(\"avg_target_loss\", avg_target_loss, ep)\n",
    "    log(torch.var(source_weights).item())\n",
    "    log(source_weights.mean().item())\n",
    "    if source_weights_ma.mean() < 0.005:\n",
    "        # stop pre-training\n",
    "        break\n",
    "    net.eval()\n",
    "    rmse_val, mae_val, val_losses = evaluate(net, target_val_loader, spatial_mask=th_mask_target)\n",
    "    rmse_s_val, mae_s_val, test_losses = evaluate(net, A_star_loader, spatial_mask=A_th_mask)\n",
    "    log(\n",
    "        \"Epoch %d, source validation rmse %.4f, mae %.4f\" % (ep, rmse_s_val * (smax - smin), mae_s_val * (smax - smin)))\n",
    "    log(\"Epoch %d, target validation rmse %.4f, mae %.4f\" % (\n",
    "        ep, rmse_val * (max_val - min_val), mae_val * (max_val - min_val)))\n",
    "    log()\n",
    "    writer.add_scalar(\"source validation rmse\", rmse_s_val * (smax - smin), ep)\n",
    "    writer.add_scalar(\"source validation mse\", mae_s_val * (smax - smin), ep)\n",
    "    writer.add_scalar(\"target validation rmse_val\", rmse_val * (max_val - min_val), ep)\n",
    "    writer.add_scalar(\"target validation mae_val\", mae_val * (max_val - min_val), ep)\n",
    "    sums = 0\n",
    "    for i in range(len(val_losses)):\n",
    "        sums = sums + val_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"source train val loss\", sums, ep)\n",
    "    sums = 0\n",
    "    for i in range(len(test_losses)):\n",
    "        sums = sums + test_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"source train test loss\", sums, ep)\n",
    "    p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "save_obj(source_weights_ma_list, path=\"source_weights_ma_list_{}.list\".format(scity))\n",
    "save_obj(source_weight_list, path=\"source_weight_list_{}.list\".format(scity))\n",
    "for ep in range(num_epochs, num_tuine_epochs + num_epochs):\n",
    "    # fine-tuning\n",
    "    net.train()\n",
    "    avg_loss = train_epoch(net, target_train_loader, pred_optimizer, mask=th_mask_target)\n",
    "    log('[%.2fs]Epoch %d, target pred loss %.4f' % (time.time() - start_time, ep, np.mean(avg_loss)))\n",
    "    writer.add_scalar(\"target pred loss\", np.mean(avg_loss), ep - num_epochs)\n",
    "    net.eval()\n",
    "    rmse_val, mae_val, val_losses = evaluate(net, target_val_loader, spatial_mask=th_mask_target)\n",
    "    rmse_test, mae_test, test_losses = evaluate(net, target_test_loader, spatial_mask=th_mask_target)\n",
    "    sums = 0\n",
    "    for i in range(len(val_losses)):\n",
    "        sums = sums + val_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"target train val loss\", sums, ep)\n",
    "    sums = 0\n",
    "    for i in range(len(test_losses)):\n",
    "        sums = sums + test_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"target train test loss\", sums, ep)\n",
    "    if rmse_val < best_val_rmse:\n",
    "        best_val_rmse = rmse_val\n",
    "        best_test_rmse = rmse_test\n",
    "        best_test_mae = mae_test\n",
    "        log(\"Update best test...\")\n",
    "    log(\"validation rmse %.4f, mae %.4f\" % (rmse_val * (max_val - min_val), mae_val * (max_val - min_val)))\n",
    "    log(\"test rmse %.4f, mae %.4f\" % (rmse_test * (max_val - min_val), mae_test * (max_val - min_val)))\n",
    "    writer.add_scalar(\"validation rmse\", rmse_val * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"validation mae\", mae_val * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"test rmse\", rmse_test * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"test mae\", mae_test * (max_val - min_val), ep - num_epochs)\n",
    "    log()\n",
    "    p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "\n",
    "log(\"Best test rmse %.4f, mae %.4f\" % (best_test_rmse * (max_val - min_val), best_test_mae * (max_val - min_val)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}