{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PaperCrawlerUtil.common_util import *\n",
    "from PaperCrawlerUtil.constant import *\n",
    "from PaperCrawlerUtil.crawler_util import *\n",
    "from dgl.nn import GATConv\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "basic_config(logs_style=LOG_STYLE_ALL)\n",
    "p_bar = process_bar(final_prompt=\"初始化准备完成\", unit=\"part\")\n",
    "p_bar.process(0, 1, 5)\n",
    "# This file implements the full version of using region embeddings to select good source data.\n",
    "parser = argparse.ArgumentParser()\n",
    "# 源城市\n",
    "parser.add_argument('--scity', type=str, default='NY')\n",
    "# 目标城市\n",
    "parser.add_argument('--tcity', type=str, default='DC')\n",
    "# 数据集名称\n",
    "parser.add_argument('--dataname', type=str, default='Taxi', help='Within [Bike, Taxi]')\n",
    "# 数据类型\n",
    "parser.add_argument('--datatype', type=str, default='pickup', help='Within [pickup, dropoff]')\n",
    "# 尝试减小，看显存能不能撑住 32 -> 16\n",
    "parser.add_argument('--batch_size', type=int, default=16)\n",
    "# 模型\n",
    "parser.add_argument(\"--model\", type=str, default='STNet_nobn', help='Within [STResNet, STNet, STNet_nobn]')\n",
    "# 学习率\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "# 权重\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5)\n",
    "# 100回合跑下来数据有问题，改成40epoch看看，论文也是这个\n",
    "parser.add_argument('--num_epochs', type=int, default=80, help='Number of source training epochs')\n",
    "parser.add_argument('--num_tuine_epochs', type=int, default=80, help='Number of fine tuine epochs')\n",
    "# gpu设备序号\n",
    "parser.add_argument('--gpu', type=int, default=0)\n",
    "# 随机种子 不知道是干嘛的\n",
    "parser.add_argument('--seed', type=int, default=-1, help='Random seed. -1 means do not manually set. ')\n",
    "# 数据量\n",
    "parser.add_argument('--data_amount', type=int, default=0, help='0: full data, 30/7/3 correspond to days of data')\n",
    "# 内循环 源训练数量\n",
    "parser.add_argument('--sinneriter', type=int, default=3, help='Number of inner iterations (source) for meta learning')\n",
    "# 内循环 微调数量\n",
    "parser.add_argument('--tinneriter', type=int, default=1, help='Number of inner iterations (target) for meta learning')\n",
    "# 内循环元学习学习率\n",
    "parser.add_argument('--innerlr', type=float, default=5e-5, help='Learning rate for inner loop of meta-learning')\n",
    "# 外循环数量\n",
    "parser.add_argument('--outeriter', type=int, default=20, help='Number of outer iterations for meta-learning')\n",
    "# 外循环学习率\n",
    "parser.add_argument('--outerlr', type=float, default=1e-4, help='Learning rate for the outer loop of meta-learning')\n",
    "# 前k个参数\n",
    "parser.add_argument('--topk', type=int, default=15)\n",
    "# 最大平均误差参数 ，也就是beta1\n",
    "parser.add_argument('--mmd_w', type=float, default=2, help='mmd weight')\n",
    "# 边缘分类器参数， beta2\n",
    "parser.add_argument('--et_w', type=float, default=2, help='edge classifier weight')\n",
    "# 源域权重的移动平均参数\n",
    "parser.add_argument(\"--ma_coef\", type=float, default=0.6, help='Moving average parameter for source domain weights')\n",
    "# 源域权重的正则化器。\n",
    "parser.add_argument(\"--weight_reg\", type=float, default=1e-3, help=\"Regularizer for the source domain weights.\")\n",
    "# 预训练回合数\n",
    "parser.add_argument(\"--pretrain_iter\", type=int, default=-1, help='Pre-training iterations per pre-training epoch. ')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.seed != -1:\n",
    "    # seed( ) 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed( )值，则每次生成的随即数都相同，\n",
    "    # 如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。\n",
    "    # random.seed(something)只能是一次有效\n",
    "    # seed( ) 用于指定随机数生成时所用算法开始的整数值。\n",
    "    # 1.如果使用相同的seed( )值，则每次生成的随即数都相同；\n",
    "    # 2.如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。\n",
    "    # 3.设置的seed()值仅一次有效\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "# 设置训练设备\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)\n",
    "gpu_available = torch.cuda.is_available()\n",
    "if gpu_available:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "p_bar.process(1, 1, 5)\n",
    "dataname = args.dataname\n",
    "scity = args.scity\n",
    "tcity = args.tcity\n",
    "datatype = args.datatype\n",
    "num_epochs = args.num_epochs\n",
    "num_tuine_epochs = args.num_tuine_epochs\n",
    "start_time = time.time()\n",
    "log(\"Running CrossTReS, from %s to %s, %s %s experiments, with %d days of data, on %s model\" % \\\n",
    "    (scity, tcity, dataname, datatype, args.data_amount, args.model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load spatio temporal data\n",
    "# (8784, 21, 20)\n",
    "# 8784 = 366 * 24\n",
    "target_data = np.load(\"../data/%s/%s%s_%s.npy\" % (tcity, dataname, tcity, datatype))\n",
    "# (21, 20) 经纬度分割\n",
    "lng_target, lat_target = target_data.shape[1], target_data.shape[2]\n",
    "# numpy.sum()，求和某一维度或者维度为none时，求和所有，减掉一个维度\n",
    "# 此处，target_data (8784, 21, 20) -> (21, 20)\n",
    "# 然后，通过对于每个元素判断是否大于0， 转成Bool向量\n",
    "mask_target = target_data.sum(0) > 0\n",
    "# reshape （21， 20） -》 （1， 21， 20）\n",
    "th_mask_target = torch.Tensor(mask_target.reshape(1, lng_target, lat_target)).to(device)\n",
    "log(\"%d valid regions in target\" % np.sum(mask_target))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (（21， 20）-> 420, （21， 20）-> 420)\n",
    "target_emb_label = masked_percentile_label(target_data.sum(0).reshape(-1), mask_target.reshape(-1))\n",
    "p_bar.process(2, 1, 5)\n",
    "# (8784, 20, 23)\n",
    "source_data = np.load(\"../data/%s/%s%s_%s.npy\" % (scity, dataname, scity, datatype))\n",
    "# (20, 23)\n",
    "lng_source, lat_source = source_data.shape[1], source_data.shape[2]\n",
    "mask_source = source_data.sum(0) > 0\n",
    "# mask -> th_mask = (20, 23) -> (1, 20, 23)\n",
    "th_mask_source = torch.Tensor(mask_source.reshape(1, lng_source, lat_source)).to(device)\n",
    "log(\"%d valid regions in source\" % np.sum(mask_source))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 按照百分比分配标签\n",
    "source_emb_label = masked_percentile_label(source_data.sum(0).reshape(-1), mask_source.reshape(-1))\n",
    "p_bar.process(3, 1, 5)\n",
    "lag = [-6, -5, -4, -3, -2, -1]\n",
    "source_data, smax, smin = min_max_normalize(source_data)\n",
    "target_data, max_val, min_val = min_max_normalize(target_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [(5898, 6, 20, 23), (5898, 1, 20, 23), (1440, 6, 20, 23), (1440, 1, 20, 23), (1440, 6, 20, 23), (1440, 1, 20, 23)]\n",
    "# 第一维是数量，第二维是每条数据中的数量\n",
    "source_train_x, source_train_y, source_val_x, source_val_y, source_test_x, source_test_y = split_x_y(source_data, lag)\n",
    "# we concatenate all source data\n",
    "# (8778, 6, 20, 23)\n",
    "source_x = np.concatenate([source_train_x, source_val_x, source_test_x], axis=0)\n",
    "# (8778, 1, 20, 23)\n",
    "source_y = np.concatenate([source_train_y, source_val_y, source_test_y], axis=0)\n",
    "target_train_x, target_train_y, target_val_x, target_val_y, target_test_x, target_test_y = split_x_y(target_data, lag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if args.data_amount != 0:\n",
    "    # 负号表示从倒数方向数，\n",
    "    # i.e.\n",
    "    # a = [12, 3, 4, 5, 6, 7, 8]\n",
    "    # c, d = a[-2:], a[:-2]\n",
    "    # print(c)\n",
    "    # print(d)\n",
    "    # [7, 8]\n",
    "    # [12, 3, 4, 5, 6]\n",
    "    target_train_x = target_train_x[-args.data_amount * 24:, :, :, :]\n",
    "    target_train_y = target_train_y[-args.data_amount * 24:, :, :, :]\n",
    "log(\"Source split to: x %s, y %s\" % (str(source_x.shape), str(source_y.shape)))\n",
    "# log(\"val_x %s, val_y %s\" % (str(source_val_x.shape), str(source_val_y.shape)))\n",
    "# log(\"test_x %s, test_y %s\" % (str(source_test_x.shape), str(source_test_y.shape)))\n",
    "\n",
    "log(\"Target split to: train_x %s, train_y %s\" % (str(target_train_x.shape), str(target_train_y.shape)))\n",
    "log(\"val_x %s, val_y %s\" % (str(target_val_x.shape), str(target_val_y.shape)))\n",
    "log(\"test_x %s, test_y %s\" % (str(target_test_x.shape), str(target_test_y.shape)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 这些代码 numpy -> Tensor -> TensorDataset -> DataLoader\n",
    "target_train_dataset = TensorDataset(torch.Tensor(target_train_x), torch.Tensor(target_train_y))\n",
    "target_val_dataset = TensorDataset(torch.Tensor(target_val_x), torch.Tensor(target_val_y))\n",
    "target_test_dataset = TensorDataset(torch.Tensor(target_test_x), torch.Tensor(target_test_y))\n",
    "target_train_loader = DataLoader(target_train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "target_val_loader = DataLoader(target_val_dataset, batch_size=args.batch_size)\n",
    "target_test_loader = DataLoader(target_test_dataset, batch_size=args.batch_size)\n",
    "source_test_dataset = TensorDataset(torch.Tensor(source_test_x), torch.Tensor(source_test_y))\n",
    "source_test_loader = DataLoader(source_test_dataset, batch_size=args.batch_size)\n",
    "source_dataset = TensorDataset(torch.Tensor(source_x), torch.Tensor(source_y))\n",
    "source_loader = DataLoader(source_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "p_bar.process(4, 1, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load auxiliary data: poi data\n",
    "# (20, 23, 14)\n",
    "source_poi = np.load(\"../data/%s/%s_poi.npy\" % (scity, scity))\n",
    "target_poi = np.load(\"../data/%s/%s_poi.npy\" % (tcity, tcity))\n",
    "# (460, 14)\n",
    "source_poi = source_poi.reshape(lng_source * lat_source, -1)  # regions * classes\n",
    "target_poi = target_poi.reshape(lng_target * lat_target, -1)  # regions * classes\n",
    "transform = TfidfTransformer()\n",
    "# 规范正则化到（0，1）\n",
    "source_norm_poi = np.array(transform.fit_transform(source_poi).todense())\n",
    "transform = TfidfTransformer()\n",
    "target_norm_poi = np.array(transform.fit_transform(target_poi).todense())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build graphs\n",
    "# add_self_loop 增加一个自循环，对角线的值=1\n",
    "source_prox_adj = add_self_loop(build_prox_graph(lng_source, lat_source))\n",
    "target_prox_adj = add_self_loop(build_prox_graph(lng_target, lat_target))\n",
    "source_road_adj = add_self_loop(build_road_graph(scity, lng_source, lat_source))\n",
    "target_road_adj = add_self_loop(build_road_graph(tcity, lng_target, lat_target))\n",
    "source_poi_adj, source_poi_cos = build_poi_graph(source_norm_poi, args.topk)\n",
    "target_poi_adj, target_poi_cos = build_poi_graph(target_norm_poi, args.topk)\n",
    "source_poi_adj = add_self_loop(source_poi_adj)\n",
    "target_poi_adj = add_self_loop(target_poi_adj)\n",
    "source_s_adj, source_d_adj, source_od_adj = build_source_dest_graph(scity, dataname, lng_source, lat_source, args.topk)\n",
    "target_s_adj, target_d_adj, target_od_adj = build_source_dest_graph(tcity, dataname, lng_target, lat_target, args.topk)\n",
    "source_s_adj = add_self_loop(source_s_adj)\n",
    "source_t_adj = add_self_loop(source_d_adj)\n",
    "source_od_adj = add_self_loop(source_od_adj)\n",
    "target_s_adj = add_self_loop(target_s_adj)\n",
    "target_t_adj = add_self_loop(target_d_adj)\n",
    "target_od_adj = add_self_loop(target_od_adj)\n",
    "log(\"Source graphs: \")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (source_prox_adj.shape[0], np.sum(source_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (source_road_adj.shape[0], np.sum(source_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (source_poi_adj.shape[0], np.sum(source_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (source_s_adj.shape[0], np.sum(source_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (source_d_adj.shape[0], np.sum(source_d_adj > 0)))\n",
    "log()\n",
    "log(\"Target graphs:\")\n",
    "log(\"prox_adj: %d nodes, %d edges\" % (target_prox_adj.shape[0], np.sum(target_prox_adj)))\n",
    "log(\"road adj: %d nodes, %d edges\" % (target_road_adj.shape[0], np.sum(target_road_adj > 0)))\n",
    "log(\"poi_adj, %d nodes, %d edges\" % (target_poi_adj.shape[0], np.sum(target_poi_adj > 0)))\n",
    "log(\"s_adj, %d nodes, %d edges\" % (target_s_adj.shape[0], np.sum(target_s_adj > 0)))\n",
    "log(\"d_adj, %d nodes, %d edges\" % (target_d_adj.shape[0], np.sum(target_d_adj > 0)))\n",
    "log()\n",
    "source_graphs = adjs_to_graphs([source_prox_adj, source_road_adj, source_poi_adj, source_s_adj, source_d_adj])\n",
    "target_graphs = adjs_to_graphs([target_prox_adj, target_road_adj, target_poi_adj, target_s_adj, target_d_adj])\n",
    "for i in range(len(source_graphs)):\n",
    "    source_graphs[i] = source_graphs[i].to(device)\n",
    "    target_graphs[i] = target_graphs[i].to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This function is a preparation for the edge type discriminator\n",
    "def graphs_to_edge_labels(graphs):\n",
    "    \"\"\"\n",
    "    准备边缘分类器的训练材料， 边的表示（起点，终点），边的标识【0,0,0,0,0】\n",
    "    :param graphs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    edge_label_dict = {}\n",
    "    for i, graph in enumerate(graphs):\n",
    "        src, dst = graph.edges()\n",
    "        for s, d in zip(src, dst):\n",
    "            s = s.item()\n",
    "            d = d.item()\n",
    "            if (s, d) not in edge_label_dict:\n",
    "                edge_label_dict[(s, d)] = np.zeros(len(graphs))\n",
    "            edge_label_dict[(s, d)][i] = 1\n",
    "    edges = []\n",
    "    edge_labels = []\n",
    "    for k in edge_label_dict.keys():\n",
    "        edges.append(k)\n",
    "        edge_labels.append(edge_label_dict[k])\n",
    "    edges = np.array(edges)\n",
    "    edge_labels = np.array(edge_labels)\n",
    "    return edges, edge_labels\n",
    "\n",
    "\n",
    "source_edges, source_edge_labels = graphs_to_edge_labels(source_graphs)\n",
    "target_edges, target_edge_labels = graphs_to_edge_labels(target_graphs)\n",
    "p_bar.process(5, 1, 5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build models\n",
    "# we need one embedding model, one scoring model, one prediction model\n",
    "# 图注意力\n",
    "class MVGAT(nn.Module):\n",
    "    def __init__(self, num_graphs=3, num_gat_layer=2, in_dim=14, hidden_dim=64, emb_dim=32, num_heads=2, residual=True):\n",
    "        super().__init__()\n",
    "        self.num_graphs = num_graphs\n",
    "        self.num_gat_layer = num_gat_layer\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.residual = residual\n",
    "\n",
    "        self.multi_gats = nn.ModuleList()\n",
    "        for j in range(self.num_gat_layer):\n",
    "            gats = nn.ModuleList()\n",
    "            for i in range(self.num_graphs):\n",
    "                if j == 0:\n",
    "                    gats.append(GATConv(self.in_dim,\n",
    "                                        self.hidden_dim,\n",
    "                                        self.num_heads,\n",
    "                                        residual=self.residual,\n",
    "                                        allow_zero_in_degree=True))\n",
    "                elif j == self.num_gat_layer - 1:\n",
    "                    gats.append(GATConv(self.hidden_dim * self.num_heads,\n",
    "                                        self.emb_dim // self.num_heads,\n",
    "                                        self.num_heads,\n",
    "                                        residual=self.residual,\n",
    "                                        allow_zero_in_degree=True))\n",
    "                else:\n",
    "                    gats.append(GATConv(self.hidden_dim * self.num_heads,\n",
    "                                        self.hidden_dim,\n",
    "                                        self.num_heads,\n",
    "                                        residual=self.residual,\n",
    "                                        allow_zero_in_degree=True))\n",
    "            self.multi_gats.append(gats)\n",
    "\n",
    "    def forward(self, graphs, feat):\n",
    "        views = []\n",
    "        for i in range(self.num_graphs):\n",
    "            for j in range(self.num_gat_layer):\n",
    "                if j == 0:\n",
    "                    z = self.multi_gats[j][i](graphs[i], feat)\n",
    "                else:\n",
    "                    z = self.multi_gats[j][i](graphs[i], z)\n",
    "                if j != self.num_gat_layer - 1:\n",
    "                    z = F.relu(z)\n",
    "                z = z.flatten(1)\n",
    "            views.append(z)\n",
    "        return views\n",
    "\n",
    "\n",
    "# 融合模型\n",
    "class FusionModule(nn.Module):\n",
    "    \"\"\"\n",
    "    融合多图模型的特征，使用了注意力机制，用全连接实现\n",
    "    \"\"\"\n",
    "    def __init__(self, num_graphs, emb_dim, alpha):\n",
    "        super().__init__()\n",
    "        self.num_graphs = num_graphs\n",
    "        self.emb_dim = emb_dim\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.fusion_linear = nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        self.self_q = nn.ModuleList()\n",
    "        self.self_k = nn.ModuleList()\n",
    "        for i in range(self.num_graphs):\n",
    "            self.self_q.append(nn.Linear(self.emb_dim, self.emb_dim))\n",
    "            self.self_k.append(nn.Linear(self.emb_dim, self.emb_dim))\n",
    "\n",
    "    def forward(self, views):\n",
    "        \"\"\"\n",
    "        views -> cat_views cat_views = torch.stack(views, dim=0)\n",
    "        for 1 - 5\n",
    "            cat_views = 5*460*64\n",
    "            attn = torch.matmul(Q, K.transpose(1, 2))\n",
    "            output = torch.matmul(attn, cat_views)\n",
    "        average\n",
    "        views = self.alpha * self_attentions[i] + (1 - self.alpha) * views[i]\n",
    "        for 1 - 5\n",
    "            mv_outputs.append(torch.sigmoid(self.fusion_linear(views[i])) * views[i])\n",
    "        fused_outputs = sum(mv_outputs)\n",
    "        mv_outputs.append(torch.sigmoid(self.fusion_linear(views[i])) * views[i])\n",
    "        fused_outputs = sum(mv_outputs)\n",
    "        return fused_outputs, [(views[i] + fused_outputs) / 2 for i in range(self.num_graphs)]\n",
    "        :param views:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # run fusion by self attention\n",
    "        # 5个460*64 -> 5*460*64\n",
    "        cat_views = torch.stack(views, dim=0)\n",
    "        self_attentions = []\n",
    "        # 注意力分数计算\n",
    "        for i in range(self.num_graphs):\n",
    "            Q = self.self_q[i](cat_views)\n",
    "            K = self.self_k[i](cat_views)\n",
    "            # (3, num_nodes, 64)\n",
    "            attn = F.softmax(torch.matmul(Q, K.transpose(1, 2)) / np.sqrt(self.emb_dim), dim=-1)\n",
    "            # (3, num_nodes, num_nodes)\n",
    "            output = torch.matmul(attn, cat_views)\n",
    "            self_attentions.append(output)\n",
    "        self_attentions = sum(self_attentions) / self.num_graphs\n",
    "        # (3, num_nodes, 64 * 2)\n",
    "        for i in range(self.num_graphs):\n",
    "            views[i] = self.alpha * self_attentions[i] + (1 - self.alpha) * views[i]\n",
    "\n",
    "        # further run multi-view fusion\n",
    "        mv_outputs = []\n",
    "        for i in range(self.num_graphs):\n",
    "            mv_outputs.append(torch.sigmoid(self.fusion_linear(views[i])) * views[i])\n",
    "\n",
    "        fused_outputs = sum(mv_outputs)\n",
    "        # next_in = [(view + fused_outputs) / 2 for view in views]\n",
    "        return fused_outputs, [(views[i] + fused_outputs) / 2 for i in range(self.num_graphs)]\n",
    "\n",
    "\n",
    "# 评分模型\n",
    "class Scoring(nn.Module):\n",
    "    def __init__(self, emb_dim, source_mask, target_mask):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.score = nn.Sequential(nn.Linear(self.emb_dim, self.emb_dim // 2),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(self.emb_dim // 2, self.emb_dim // 2))\n",
    "        self.source_mask = source_mask\n",
    "        self.target_mask = target_mask\n",
    "\n",
    "    def forward(self, source_emb, target_emb):\n",
    "        \"\"\"\n",
    "        求源城市评分\n",
    "        :param source_emb:\n",
    "        :param target_emb:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # target_context = tanh(self.score(target_emb[bool mask]).mean(0))\n",
    "        # 对于横向的进行求平均 460*64 -> 460*32 -> 207*32 -> 纵向求平均 1*32 代表所有目标城市\n",
    "        target_context = torch.tanh(\n",
    "            torch.quantile(\n",
    "                self.score(target_emb[self.target_mask.view(-1).bool()]),\n",
    "                torch.Tensor([0.1, 0.25, 0.5, 0.75, 0.9]).to(device), dim=0).mean(0)\n",
    "        )\n",
    "        source_trans_emb = self.score(source_emb)\n",
    "        # 460*32 * 1*32 = 462*32, 这里乘法表示1*32列表去乘460*32的每一行，逐元素\n",
    "        # i.e.\n",
    "        # tensor([[2, 2, 2],\n",
    "        #         [1, 2, 2],\n",
    "        #         [2, 2, 1]])\n",
    "        # tensor([[2, 2, 2]])\n",
    "        # tensor([[4, 4, 4],\n",
    "        #         [2, 4, 4],\n",
    "        #         [4, 4, 2]])\n",
    "        source_score = (source_trans_emb * target_context).sum(1)\n",
    "        # the following lines modify inner product similarity to cosine similarity\n",
    "        # target_norm = target_context.pow(2).sum().pow(1/2)\n",
    "        # source_norm = source_trans_emb.pow(2).sum(1).pow(1/2)\n",
    "        # source_score /= source_norm\n",
    "        # source_score /= target_norm\n",
    "        # log(source_score)\n",
    "        return F.relu(torch.tanh(source_score))[self.source_mask.view(-1).bool()]\n",
    "\n",
    "\n",
    "# 最大平均误差\n",
    "class MMD_loss(nn.Module):\n",
    "    def __init__(self, kernel_mul=2.0, kernel_num=5):\n",
    "        super(MMD_loss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = None\n",
    "\n",
    "    def gaussian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0 - total1) ** 2).sum(2)\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples ** 2 - n_samples)\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
    "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        batch_size = int(source.size()[0])\n",
    "        kernels = self.gaussian_kernel(source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num,\n",
    "                                       fix_sigma=self.fix_sigma)\n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        loss = torch.mean(XX + YY - XY - YX)\n",
    "        return loss\n",
    "\n",
    "\n",
    "mmd = MMD_loss()\n",
    "\n",
    "\n",
    "# 边类型分类器\n",
    "class EdgeTypeDiscriminator(nn.Module):\n",
    "    def __init__(self, num_graphs, emb_dim):\n",
    "        super().__init__()\n",
    "        self.num_graphs = num_graphs\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_network = nn.Sequential(nn.Linear(2 * self.emb_dim, self.emb_dim),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(self.emb_dim, self.num_graphs))\n",
    "\n",
    "    def forward(self, src_embs, dst_embs):\n",
    "        edge_vec = torch.cat([src_embs, dst_embs], dim=1)\n",
    "        return self.edge_network(edge_vec)\n",
    "\n",
    "\n",
    "num_gat_layers = 2\n",
    "in_dim = 14\n",
    "hidden_dim = 64\n",
    "emb_dim = 64\n",
    "num_heads = 2\n",
    "mmd_w = args.mmd_w\n",
    "et_w = args.et_w\n",
    "ma_param = args.ma_coef\n",
    "\n",
    "mvgat = MVGAT(len(source_graphs), num_gat_layers, in_dim, hidden_dim, emb_dim, num_heads, True).to(device)\n",
    "fusion = FusionModule(len(source_graphs), emb_dim, 0.8).to(device)\n",
    "scoring = Scoring(emb_dim, th_mask_source, th_mask_target).to(device)\n",
    "edge_disc = EdgeTypeDiscriminator(len(source_graphs), emb_dim).to(device)\n",
    "mmd = MMD_loss()\n",
    "# we still need a scoring model.\n",
    "# [NS, 64], [NT, 64] -> [NS]\n",
    "\n",
    "# build model\n",
    "if args.model == 'STResNet':\n",
    "    net = STResNet(len(lag), 1, 3).to(device)\n",
    "elif args.model == 'STNet_nobn':\n",
    "    net = STNet_nobn(1, 3, th_mask_target, sigmoid_out=True).to(device)\n",
    "    log(net)\n",
    "elif args.model == 'STNet':\n",
    "    net = STNet(1, 3, th_mask_target).to(device)\n",
    "    log(net)\n",
    "\n",
    "# net估计是预测网络\n",
    "pred_optimizer = optim.Adam(net.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 图卷积，融合，边类型分类器参数单独训练\n",
    "emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# 元学习部分\n",
    "meta_optimizer = optim.Adam(scoring.parameters(), lr=args.outerlr, weight_decay=args.weight_decay)\n",
    "best_val_rmse = 999\n",
    "best_test_rmse = 999\n",
    "best_test_mae = 999"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(net_, loader, spatial_mask):\n",
    "    \"\"\"\n",
    "    评估函数，spatial_mask去掉了一些无效数据\n",
    "    :param net_:\n",
    "    :param loader:\n",
    "    :param spatial_mask:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_.eval()\n",
    "    with torch.no_grad():\n",
    "        se = 0\n",
    "        ae = 0\n",
    "        valid_points = 0\n",
    "        losses = []\n",
    "        for it_ in loader:\n",
    "            if len(it_) == 2:\n",
    "                (x, y) = it_\n",
    "            elif len(it_) == 4:\n",
    "                _, _, x, y = it_\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            lng = x.shape[2]\n",
    "            lat = x.shape[3]\n",
    "            out = net_(x, spatial_mask=spatial_mask.bool())\n",
    "            valid_points += x.shape[0] * spatial_mask.sum().item()\n",
    "            if len(out.shape) == 4:  # STResNet\n",
    "                se += (((out - y) ** 2) * (spatial_mask.view(1, 1, lng, lat))).sum().item()\n",
    "                ae += ((out - y).abs() * (spatial_mask.view(1, 1, lng, lat))).sum().item()\n",
    "                eff_batch_size = y.shape[0]\n",
    "                loss = ((out - y) ** 2).view(eff_batch_size, 1, -1)[:, :, spatial_mask.view(-1).bool()]\n",
    "                losses.append(loss)\n",
    "            elif len(out.shape) == 3:  # STNet\n",
    "                batch_size = y.shape[0]\n",
    "                lag = y.shape[1]\n",
    "                y = y.view(batch_size, lag, -1)[:, :, spatial_mask.view(-1).bool()]\n",
    "                # log(\"out\", out.shape)\n",
    "                # log(\"y\", y.shape)\n",
    "                se += ((out - y) ** 2).sum().item()\n",
    "                ae += (out - y).abs().sum().item()\n",
    "                loss = ((out - y) ** 2)\n",
    "                losses.append(loss)\n",
    "    return np.sqrt(se / valid_points), ae / valid_points, losses\n",
    "\n",
    "\n",
    "def batch_sampler(tensor_list, batch_size):\n",
    "    \"\"\"\n",
    "    返回抽样数据\n",
    "    :param tensor_list: 元组或者list，随机抽取batchsize的数量\n",
    "    :param batch_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_samples = tensor_list[0].size(0)\n",
    "    idx = np.random.permutation(num_samples)[:batch_size]\n",
    "    return (x[idx] for x in tensor_list)\n",
    "\n",
    "\n",
    "def get_weights_bn_vars(module):\n",
    "    \"\"\"\n",
    "    获取未命名的参数名称,以及命名参数\n",
    "    :param module:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fast_weights = OrderedDict(module.named_parameters())\n",
    "    bn_vars = OrderedDict()\n",
    "    for k in module.state_dict():\n",
    "        if k not in fast_weights.keys():\n",
    "            bn_vars[k] = module.state_dict()[k]\n",
    "    return fast_weights, bn_vars\n",
    "\n",
    "\n",
    "def train_epoch(net_, loader_, optimizer_, weights=None, mask=None, num_iters=None):\n",
    "    \"\"\"\n",
    "    训练预测网络pred net网络，依据权重weights 修改loss，如\n",
    "    loss = ((out - y) ** 2)\n",
    "    loss = (loss * weights.view(1, 1, -1)).mean(0).sum()\n",
    "    再反向传播optimizer_\n",
    "    :param net_:\n",
    "    :param loader_:\n",
    "    :param optimizer_:\n",
    "    :param weights:\n",
    "    :param mask:\n",
    "    :param num_iters:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_.train()\n",
    "    epoch_loss = []\n",
    "    for i, (x, y) in enumerate(loader_):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = net_(x, spatial_mask=mask.bool())\n",
    "        if len(out.shape) == 4:  # STResNet\n",
    "            eff_batch_size = y.shape[0]\n",
    "            loss = ((out - y) ** 2).view(eff_batch_size, 1, -1)[:, :, mask.view(-1).bool()]\n",
    "            # log(\"loss\", loss.shape)\n",
    "            if weights is not None:\n",
    "                loss = (loss * weights)\n",
    "                # log(\"weights\", weights.shape)\n",
    "                # log(\"loss * weights\", loss.shape)\n",
    "                loss = loss.mean(0).sum()\n",
    "            else:\n",
    "                loss = loss.mean(0).sum()\n",
    "        elif len(out.shape) == 3:  # STNet\n",
    "            eff_batch_size = y.shape[0]\n",
    "            y = y.view(eff_batch_size, 1, -1)[:, :, mask.view(-1).bool()]\n",
    "            loss = ((out - y) ** 2)\n",
    "            if weights is not None:\n",
    "                # log(loss.shape)\n",
    "                # log(weights.shape)\n",
    "                loss = (loss * weights.view(1, 1, -1)).mean(0).sum()\n",
    "            else:\n",
    "                loss = loss.mean(0).sum()\n",
    "        optimizer_.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net_.parameters(), max_norm=2)\n",
    "        optimizer_.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        if num_iters is not None and num_iters == i:\n",
    "            break\n",
    "    return epoch_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 这个代码还用不到，有报错，单独拿出来，不执行\n",
    "def train_rt_epoch(net_, loader_, optimizer_):\n",
    "    net_.train()\n",
    "    epoch_predloss = []\n",
    "    epoch_rtloss = []\n",
    "    epoch_loss = []\n",
    "    for i, (source_x, source_y, target_x, target_y) in enumerate(loader_):\n",
    "        source_x = source_x.to(device)\n",
    "        source_y = source_y.to(device)\n",
    "        target_x = target_x.to(device)\n",
    "        target_y = target_y.to(device)\n",
    "        source_feat, _ = net_(source_x, spatial_mask=th_mask_source.bool(), return_feat=True)\n",
    "        target_feat, target_out = net_(target_x, return_feat=True)\n",
    "        batch_size = target_y.shape[0]\n",
    "        lag = target_y.shape[1]\n",
    "        target_y = target_y.view(batch_size, lag, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "        loss_pred = ((target_out - target_y) ** 2).mean(0).sum()\n",
    "        matching_source_feat = source_feat[:, matching_indices, :]\n",
    "        loss_rt = (((target_feat - matching_source_feat) ** 2).sum(2) * matching_weight).sum(1).mean()\n",
    "        loss = loss_pred + args.rt_weight * loss_rt\n",
    "        optimizer_.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_.step()\n",
    "        epoch_predloss.append(loss_pred.item())\n",
    "        epoch_rtloss.append(loss_rt.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "    return np.mean(epoch_predloss), np.mean(epoch_rtloss), np.mean(epoch_loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward_emb(graphs_, in_feat_, od_adj_, poi_cos_):\n",
    "    \"\"\"\n",
    "    1. 图卷积提取图特征 mvgat\n",
    "    2. 融合多图特征 fusion\n",
    "    3. 对于多图中的s，d，poi进行预测，并计算损失函数\n",
    "    :param graphs_:\n",
    "    :param in_feat_:\n",
    "    :param od_adj_:\n",
    "    :param poi_cos_:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 图注意，注意这里用了小写，指的是forward方法\n",
    "    views = mvgat(graphs_, torch.Tensor(in_feat_).to(device))\n",
    "    fused_emb, embs = fusion(views)\n",
    "    # embs嵌入是5个图，以下找出start，destination， poi图\n",
    "    s_emb = embs[-2]\n",
    "    d_emb = embs[-1]\n",
    "    poi_emb = embs[-3]\n",
    "    # start和destination相乘求出记录预测s和d\n",
    "    recons_sd = torch.matmul(s_emb, d_emb.transpose(0, 1))\n",
    "    # 注意dim维度0和1分别求s和d\n",
    "    pred_d = torch.log(torch.softmax(recons_sd, dim=1) + 1e-5)\n",
    "    loss_d = (torch.Tensor(od_adj_).to(device) * pred_d).mean()\n",
    "    pred_s = torch.log(torch.softmax(recons_sd, dim=0) + 1e-5)\n",
    "    loss_s = (torch.Tensor(od_adj_).to(device) * pred_s).mean()\n",
    "    # poi预测求差，loss\n",
    "    poi_sim = torch.matmul(poi_emb, poi_emb.transpose(0, 1))\n",
    "    loss_poi = ((poi_sim - torch.Tensor(poi_cos_).to(device)) ** 2).mean()\n",
    "    loss = -loss_s - loss_d + loss_poi\n",
    "\n",
    "    return loss, fused_emb, embs\n",
    "\n",
    "\n",
    "def meta_train_epoch(s_embs, t_embs):\n",
    "    \"\"\"\n",
    "    0. 计算source_weights，通过scoring网络\n",
    "    1. 获取net 也就是预测网络的参数，分为两部分，一部分是命名参数，另一部分是非命名 fast_weights, bn_vars\n",
    "    2. 从源城市抽样，计算预测值，使用net网络，从输出格式判断使用的具体网络，计算损失\n",
    "    3. 通过torch.autograd.grad 计算loss对于fast_weights的梯度，并且更新fast_weights，注意2,3都是在更新net网络\n",
    "    4. 同理抽样目的城市，计算梯度，更新fast_weights\n",
    "    5. meta_loss = q_loss + weights_mean * args.weight_reg，计算meta loss\n",
    "    6. 根据meta loss 更新scoring meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "    7. 循环以上，则总体更新了scoring网络，net预测网络\n",
    "    :param s_embs:\n",
    "    :param t_embs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_query_losses = []\n",
    "    for meta_ep in range(args.outeriter):\n",
    "        fast_losses = []\n",
    "        fast_weights, bn_vars = get_weights_bn_vars(net)\n",
    "        source_weights = scoring(s_embs, t_embs)\n",
    "        # inner loop on source, pre-train with weights\n",
    "        for meta_it in range(args.sinneriter):\n",
    "            s_x, s_y = batch_sampler((torch.Tensor(source_x), torch.Tensor(source_y)), args.batch_size)\n",
    "            s_x = s_x.to(device)\n",
    "            s_y = s_y.to(device)\n",
    "            pred_source = net.functional_forward(s_x, th_mask_source.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_source.shape) == 4:  # STResNet\n",
    "                loss_source = ((pred_source - s_y) ** 2).view(args.batch_size, 1, -1)[:, :,\n",
    "                              th_mask_source.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_source = (loss_source * source_weights).mean(0).sum()\n",
    "            elif len(pred_source.shape) == 3:  # STNet\n",
    "                s_y = s_y.view(args.batch_size, 1, -1)[:, :, th_mask_source.view(-1).bool()]\n",
    "                loss_source = (((pred_source - s_y) ** 2) * source_weights.view(1, 1, -1))\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_source = loss_source.mean(0).sum()\n",
    "            # size = 1 基本可以认为是标量\n",
    "            fast_loss = loss_source\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            # 计算输出对于输入独立的梯度，\n",
    "            # fast_weights.values()。size = 22\n",
    "            # grad。size=22\n",
    "            # 此处对于fast_weights 进行梯度下降学习\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        # inner loop on target, simulate fine-tune\n",
    "        # 模拟微调和源训练都是在训练net预测网络，并没有提及权重和特征\n",
    "        for meta_it in range(args.tinneriter):\n",
    "            t_x, t_y = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            t_x = t_x.to(device)\n",
    "            t_y = t_y.to(device)\n",
    "            pred_t = net.functional_forward(t_x, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_t.shape) == 4:  # STResNet\n",
    "                loss_t = ((pred_t - t_y) ** 2).view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(loss_source.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            elif len(pred_t.shape) == 3:  # STNet\n",
    "                t_y = t_y.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                # log(t_y.shape)\n",
    "                loss_t = ((pred_t - t_y) ** 2)  # .view(1, 1, -1))\n",
    "                # log(loss_t.shape)\n",
    "                # log(loss_source.shape)\n",
    "                # log(source_weights.shape)\n",
    "                loss_t = loss_t.mean(0).sum()\n",
    "            fast_loss = loss_t\n",
    "            fast_losses.append(fast_loss.item())  #\n",
    "            grads = torch.autograd.grad(fast_loss, fast_weights.values(), create_graph=True)\n",
    "            for name, grad in zip(fast_weights.keys(), grads):\n",
    "                fast_weights[name] = fast_weights[name] - args.innerlr * grad\n",
    "                # fast_weights[name].add_(grad, alpha = -args.innerlr)\n",
    "\n",
    "        q_losses = []\n",
    "        target_iter = max(args.sinneriter, args.tinneriter)\n",
    "        for k in range(3):\n",
    "            # query loss\n",
    "            x_q, y_q = batch_sampler((torch.Tensor(target_train_x), torch.Tensor(target_train_y)), args.batch_size)\n",
    "            x_q = x_q.to(device)\n",
    "            y_q = y_q.to(device)\n",
    "            pred_q = net.functional_forward(x_q, th_mask_target.bool(), fast_weights, bn_vars, bn_training=True)\n",
    "            if len(pred_q.shape) == 4:  # STResNet\n",
    "                loss = (((pred_q - y_q) ** 2) * (th_mask_target.view(1, 1, lng_target, lat_target)))\n",
    "                loss = loss.mean(0).sum()\n",
    "            elif len(pred_q.shape) == 3:  # STNet\n",
    "                y_q = y_q.view(args.batch_size, 1, -1)[:, :, th_mask_target.view(-1).bool()]\n",
    "                loss = ((pred_q - y_q) ** 2).mean(0).sum()\n",
    "            q_losses.append(loss)\n",
    "        q_loss = torch.stack(q_losses).mean()\n",
    "        # ** 乘方\n",
    "        weights_mean = (source_weights ** 2).mean()\n",
    "        # meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        # 这里对于权重开始了联系\n",
    "        # meta loss 只训练了scoring网络\n",
    "        meta_loss = q_loss + weights_mean * args.weight_reg\n",
    "        meta_optimizer.zero_grad()\n",
    "        meta_loss.backward(inputs=list(scoring.parameters()))\n",
    "        torch.nn.utils.clip_grad_norm_(scoring.parameters(), max_norm=2)\n",
    "        meta_optimizer.step()\n",
    "        meta_query_losses.append(q_loss.item())\n",
    "    return np.mean(meta_query_losses)\n",
    "\n",
    "\n",
    "def train_emb_epoch():\n",
    "    \"\"\"\n",
    "    训练图网络-特征网络，融合网络，边类型分类器\n",
    "    1. 通过forward_emb融合特征，计算损失，\n",
    "    2. 抽样边，标签，训练边缘分类器，抽样计算MMD误差\n",
    "    3. 反向传播计算\n",
    "    emb_param_list = list(mvgat.parameters()) + list(fusion.parameters()) + list(edge_disc.parameters())\n",
    "    emb_optimizer = optim.Adam(emb_param_list, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    训练特征网络 mvgat，fusion，边缘分类器，节点MMD，在训练的同时，对于mvgat和fusion的特征进行指导，特征重新对齐分布\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # loss， 460*64， 5*460*64\n",
    "    loss_source, fused_emb_s, embs_s = forward_emb(source_graphs, source_norm_poi, source_od_adj, source_poi_cos)\n",
    "    loss_target, fused_emb_t, embs_t = forward_emb(target_graphs, target_norm_poi, target_od_adj, target_poi_cos)\n",
    "    loss_emb = loss_source + loss_target\n",
    "    # compute domain adaptation loss\n",
    "    # 随机抽样128个，计算最大平均误差\n",
    "    source_ids = np.random.randint(0, np.sum(mask_source), size=(128,))\n",
    "    target_ids = np.random.randint(0, np.sum(mask_target), size=(128,))\n",
    "    mmd_loss = mmd(fused_emb_s[th_mask_source.view(-1).bool()][source_ids, :],\n",
    "                   fused_emb_t[th_mask_target.view(-1).bool()][target_ids, :])\n",
    "    # 随机抽样边256\n",
    "    source_batch_edges = np.random.randint(0, len(source_edges), size=(256,))\n",
    "    target_batch_edges = np.random.randint(0, len(target_edges), size=(256,))\n",
    "    source_batch_src = torch.Tensor(source_edges[source_batch_edges, 0]).long()\n",
    "    source_batch_dst = torch.Tensor(source_edges[source_batch_edges, 1]).long()\n",
    "    source_emb_src = fused_emb_s[source_batch_src, :]\n",
    "    source_emb_dst = fused_emb_s[source_batch_dst, :]\n",
    "    target_batch_src = torch.Tensor(target_edges[target_batch_edges, 0]).long()\n",
    "    target_batch_dst = torch.Tensor(target_edges[target_batch_edges, 1]).long()\n",
    "    target_emb_src = fused_emb_t[target_batch_src, :]\n",
    "    target_emb_dst = fused_emb_t[target_batch_dst, :]\n",
    "    # 源城市目的城市使用同样的边分类器\n",
    "    pred_source = edge_disc.forward(source_emb_src, source_emb_dst)\n",
    "    pred_target = edge_disc.forward(target_emb_src, target_emb_dst)\n",
    "    source_batch_labels = torch.Tensor(source_edge_labels[source_batch_edges]).to(device)\n",
    "    target_batch_labels = torch.Tensor(target_edge_labels[target_batch_edges]).to(device)\n",
    "    # -（label*log(sigmod(pred)+0.000001)) + (1-label)*log(1-sigmod+0.000001) sum mean\n",
    "    loss_et_source = -((source_batch_labels * torch.log(torch.sigmoid(pred_source) + 1e-6)) + (\n",
    "            1 - source_batch_labels) * torch.log(1 - torch.sigmoid(pred_source) + 1e-6)).sum(1).mean()\n",
    "    loss_et_target = -((target_batch_labels * torch.log(torch.sigmoid(pred_target) + 1e-6)) + (\n",
    "            1 - target_batch_labels) * torch.log(1 - torch.sigmoid(pred_target) + 1e-6)).sum(1).mean()\n",
    "    loss_et = loss_et_source + loss_et_target\n",
    "\n",
    "    emb_optimizer.zero_grad()\n",
    "    # 公式11\n",
    "    loss = loss_emb + mmd_w * mmd_loss + et_w * loss_et\n",
    "    loss.backward()\n",
    "    emb_optimizer.step()\n",
    "    return loss_emb.item(), mmd_loss.item(), loss_et.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emb_losses = []\n",
    "mmd_losses = []\n",
    "edge_losses = []\n",
    "pretrain_emb_epoch = 80\n",
    "# 预训练图数据嵌入，边类型分类，节点对齐 ——> 获得区域特征\n",
    "for emb_ep in range(pretrain_emb_epoch):\n",
    "    loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch()\n",
    "    emb_losses.append(loss_emb_)\n",
    "    mmd_losses.append(loss_mmd_)\n",
    "    edge_losses.append(loss_et_)\n",
    "log(\"[%.2fs]Pretrain embeddings for %d epochs, average emb loss %.4f, mmd loss %.4f, edge loss %.4f\" % (\n",
    "    time.time() - start_time, pretrain_emb_epoch, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses)))\n",
    "with torch.no_grad():\n",
    "    views = mvgat(source_graphs, torch.Tensor(source_norm_poi).to(device))\n",
    "    # 融合模块指的是把多图的特征融合\n",
    "    fused_emb_s, _ = fusion(views)\n",
    "    views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "    fused_emb_t, _ = fusion(views)\n",
    "# mask_source.reshape(-1) 返回的是一系列bool值，整行的含义是去除false对应的值\n",
    "# reshape(-1)的含义是，不指定变换之后有多少行，将原来的tensor变成一列（default）\n",
    "emb_s = fused_emb_s.cpu().numpy()[mask_source.reshape(-1)]\n",
    "emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "\"\"\"\n",
    "交叉验证，有时亦称循环估计[1] [2] [3]， 是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析，而其它子集则用来做后续对此分析的确认及验证。一开始的子集被称为训练集。而其它的子集则被称为验证集或测试集。\n",
    "交叉验证的目的，是用未用来给模型作训练的新数据，测试模型的性能，以便减少诸如过拟合和选择偏差等问题，并给出模型如何在一个独立的数据集上通用化（即，一个未知的数据集，如实际问题中的数据）。\n",
    "交叉验证的理论是由Seymour Geisser所开始的。它对于防范根据数据建议的测试假设是非常重要的，特别是当后续的样本是危险、成本过高或科学上不适合时去搜集。\n",
    "\"\"\"\n",
    "cvscore_s = cross_validate(logreg, emb_s, source_emb_label)['test_score'].mean()\n",
    "cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "log(\"[%.2fs]Pretraining embedding, source cvscore %.4f, target cvscore %.4f\" % \\\n",
    "    (time.time() - start_time, cvscore_s, cvscore_t))\n",
    "log()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 后期要用这个参数\n",
    "source_weights_ma_list = []\n",
    "source_weight_list = []\n",
    "p_bar = process_bar(final_prompt=\"训练完成\", unit=\"epoch\")\n",
    "p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "writer = SummaryWriter(\"log_{}\".format(get_timestamp(split=\"-\")))\n",
    "for ep in range(num_epochs):\n",
    "    net.train()\n",
    "    mvgat.train()\n",
    "    fusion.train()\n",
    "    scoring.train()\n",
    "\n",
    "    # train embeddings\n",
    "    emb_losses = []\n",
    "    mmd_losses = []\n",
    "    edge_losses = []\n",
    "    for emb_ep in range(5):\n",
    "        loss_emb_, loss_mmd_, loss_et_ = train_emb_epoch()\n",
    "        emb_losses.append(loss_emb_)\n",
    "        mmd_losses.append(loss_mmd_)\n",
    "        edge_losses.append(loss_et_)\n",
    "    # evaluate embeddings\n",
    "    with torch.no_grad():\n",
    "        # mvgat 是把邻接矩阵转换成tensor，大小是城市的长宽之积 * 64（demb）也就是定义的区域特征向量的维度\n",
    "        views = mvgat(source_graphs, torch.Tensor(source_norm_poi).to(device))\n",
    "        fused_emb_s, _ = fusion(views)\n",
    "        views = mvgat(target_graphs, torch.Tensor(target_norm_poi).to(device))\n",
    "        fused_emb_t, _ = fusion(views)\n",
    "    if ep % 2 == 0:\n",
    "        \"\"\"\n",
    "        每两个epoch显示一些数据\n",
    "        \"\"\"\n",
    "        emb_s = fused_emb_s.cpu().numpy()[mask_source.reshape(-1)]\n",
    "        emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "        mix_embs = np.concatenate([emb_s, emb_t], axis=0)\n",
    "        mix_labels = np.concatenate([source_emb_label, target_emb_label])\n",
    "        logreg = LogisticRegression(max_iter=500)\n",
    "        cvscore_s = cross_validate(logreg, emb_s, source_emb_label)['test_score'].mean()\n",
    "        cvscore_t = cross_validate(logreg, emb_t, target_emb_label)['test_score'].mean()\n",
    "        cvscore_mix = cross_validate(logreg, mix_embs, mix_labels)['test_score'].mean()\n",
    "        log(\n",
    "            \"[%.2fs]Epoch %d, embedding loss %.4f, mmd loss %.4f, edge loss %.4f, source cvscore %.4f, target cvscore %.4f, mixcvscore %.4f\" % \\\n",
    "            (time.time() - start_time, ep, np.mean(emb_losses), np.mean(mmd_losses), np.mean(edge_losses), cvscore_s,\n",
    "             cvscore_t, cvscore_mix))\n",
    "    if ep == num_epochs - 1:\n",
    "        \"\"\"\n",
    "        最后一个epoch，\n",
    "        \"\"\"\n",
    "        emb_s = fused_emb_s.cpu().numpy()[mask_source.reshape(-1)]\n",
    "        emb_t = fused_emb_t.cpu().numpy()[mask_target.reshape(-1)]\n",
    "        # np.save(\"%s.npy\" % args.scity, arr = emb_s)\n",
    "        # np.save(\"%s.npy\" % args.tcity, arr = emb_t)\n",
    "        with torch.no_grad():\n",
    "            trans_emb_s = scoring.score(fused_emb_s)\n",
    "            trans_emb_t = scoring.score(fused_emb_t)\n",
    "        # np.save(\"%s_trans.npy\" % args.scity, arr = trans_emb_s.cpu().numpy()[mask_source.reshape(-1)])\n",
    "        # np.save(\"%s_trans.npy\" % args.tcity, arr = trans_emb_t.cpu().numpy()[mask_target.reshape(-1)])\n",
    "\n",
    "    # meta train scorings\n",
    "    avg_q_loss = meta_train_epoch(fused_emb_s, fused_emb_t)\n",
    "    with torch.no_grad():\n",
    "        source_weights = scoring(fused_emb_s, fused_emb_t)\n",
    "        source_weight_list.append(list(source_weights.cpu().numpy()))\n",
    "\n",
    "    # For debug: use fixed weightings.\n",
    "    # with torch.no_grad():\n",
    "    #     source_weights_ = scoring(fused_emb_s, fused_emb_t)\n",
    "    # avg_q_loss = 0\n",
    "    # source_weights = torch.ones_like(source_weights_)\n",
    "\n",
    "    # implement a moving average\n",
    "    if ep == 0:\n",
    "        source_weights_ma = torch.ones_like(source_weights, device=device, requires_grad=False)\n",
    "    source_weights_ma = ma_param * source_weights_ma + (1 - ma_param) * source_weights\n",
    "    source_weights_ma_list.append(list(source_weights_ma.cpu().numpy()))\n",
    "    # train network on source\n",
    "    # 有了参数lambda rs，训练net网络\n",
    "    source_loss = train_epoch(net, source_loader, pred_optimizer, weights=source_weights_ma, mask=th_mask_source,\n",
    "                              num_iters=args.pretrain_iter)\n",
    "    avg_source_loss = np.mean(source_loss)\n",
    "    avg_target_loss = evaluate(net, target_train_loader, spatial_mask=th_mask_target)[0]\n",
    "    log(\n",
    "        \"[%.2fs]Epoch %d, average meta query loss %.4f, source weight mean %.4f, var %.6f, source loss %.4f, target_loss %.4f\" % \\\n",
    "        (time.time() - start_time, ep, avg_q_loss, source_weights_ma.mean().item(), torch.var(source_weights_ma).item(),\n",
    "         avg_source_loss, avg_target_loss))\n",
    "    writer.add_scalar(\"average meta query loss\", avg_q_loss, ep)\n",
    "    writer.add_scalar(\"source weight mean\", source_weights_ma.mean().item(), ep)\n",
    "    writer.add_scalar(\"var\", torch.var(source_weights_ma).item(), ep)\n",
    "    writer.add_scalar(\"avg_source_loss\", avg_source_loss, ep)\n",
    "    writer.add_scalar(\"avg_target_loss\", avg_target_loss, ep)\n",
    "    log(torch.var(source_weights).item())\n",
    "    log(source_weights.mean().item())\n",
    "    if source_weights_ma.mean() < 0.005:\n",
    "        # stop pre-training\n",
    "        break\n",
    "    net.eval()\n",
    "    rmse_val, mae_val, val_losses = evaluate(net, target_val_loader, spatial_mask=th_mask_target)\n",
    "    rmse_s_val, mae_s_val, test_losses = evaluate(net, source_loader, spatial_mask=th_mask_source)\n",
    "    log(\n",
    "        \"Epoch %d, source validation rmse %.4f, mae %.4f\" % (ep, rmse_s_val * (smax - smin), mae_s_val * (smax - smin)))\n",
    "    log(\"Epoch %d, target validation rmse %.4f, mae %.4f\" % (\n",
    "        ep, rmse_val * (max_val - min_val), mae_val * (max_val - min_val)))\n",
    "    log()\n",
    "    writer.add_scalar(\"source validation rmse\", rmse_s_val * (smax - smin), ep)\n",
    "    writer.add_scalar(\"source validation mse\", mae_s_val * (smax - smin), ep)\n",
    "    writer.add_scalar(\"target validation rmse_val\", rmse_val * (max_val - min_val), ep)\n",
    "    writer.add_scalar(\"target validation mae_val\", mae_val * (max_val - min_val), ep)\n",
    "    sums = 0\n",
    "    for i in range(len(val_losses)):\n",
    "        sums = sums + val_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"source train val loss\", sums, ep)\n",
    "    sums = 0\n",
    "    for i in range(len(test_losses)):\n",
    "        sums = sums + test_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"source train test loss\", sums, ep)\n",
    "    p_bar.process(0, 1, num_epochs + num_tuine_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ep in range(num_epochs, num_tuine_epochs + num_epochs):\n",
    "    # fine-tuning\n",
    "    net.train()\n",
    "    avg_loss = train_epoch(net, target_train_loader, pred_optimizer, mask=th_mask_target)\n",
    "    log('[%.2fs]Epoch %d, target pred loss %.4f' % (time.time() - start_time, ep, np.mean(avg_loss)))\n",
    "    writer.add_scalar(\"target pred loss\", np.mean(avg_loss), ep - num_epochs)\n",
    "    net.eval()\n",
    "    rmse_val, mae_val, val_losses = evaluate(net, target_val_loader, spatial_mask=th_mask_target)\n",
    "    rmse_test, mae_test, test_losses = evaluate(net, target_test_loader, spatial_mask=th_mask_target)\n",
    "    sums = 0\n",
    "    for i in range(len(val_losses)):\n",
    "        sums = sums + val_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"target train val loss\", sums, ep)\n",
    "    sums = 0\n",
    "    for i in range(len(test_losses)):\n",
    "        sums = sums + test_losses[i].mean(0).sum().item()\n",
    "    writer.add_scalar(\"target train test loss\", sums, ep)\n",
    "    if rmse_val < best_val_rmse:\n",
    "        best_val_rmse = rmse_val\n",
    "        best_test_rmse = rmse_test\n",
    "        best_test_mae = mae_test\n",
    "        log(\"Update best test...\")\n",
    "    log(\"validation rmse %.4f, mae %.4f\" % (rmse_val * (max_val - min_val), mae_val * (max_val - min_val)))\n",
    "    log(\"test rmse %.4f, mae %.4f\" % (rmse_test * (max_val - min_val), mae_test * (max_val - min_val)))\n",
    "    writer.add_scalar(\"validation rmse\", rmse_val * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"validation mae\", mae_val * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"test rmse\", rmse_test * (max_val - min_val), ep - num_epochs)\n",
    "    writer.add_scalar(\"test mae\", mae_test * (max_val - min_val), ep - num_epochs)\n",
    "    log()\n",
    "    p_bar.process(0, 1, num_epochs + num_tuine_epochs)\n",
    "\n",
    "log(\"Best test rmse %.4f, mae %.4f\" % (best_test_rmse * (max_val - min_val), best_test_mae * (max_val - min_val)))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}